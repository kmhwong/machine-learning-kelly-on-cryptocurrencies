{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_predicted_price_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Btk9kBZNQt41",
        "6XbSq0oGQ3U4",
        "r9iZUIC6S6-B",
        "rYOApVofTCpI",
        "TvnaOt8sTtZ8",
        "q43Ht3kqT5N4",
        "tPA-qNOrUef8",
        "p8qPHsjGUpTh",
        "oyLlq5yuVDiS",
        "carzQ_t-VUM3",
        "YsYgtb_LVe16",
        "1ARTquwSVrHm",
        "TvuXKijgcDaI",
        "juzndgzSMUAS",
        "JNjNrCB0Mju0",
        "bS3w74fmMjzA",
        "eD13sk6nMj3S",
        "I-3IDlzvMj8D",
        "mcN2EOpFNVM1",
        "Er9baQYWNWDw",
        "ERLnINGQNWSg",
        "mUU-eVTjNWfB",
        "JWybrT6SNWrH",
        "gIVtUj4guQNg",
        "N7FJtO_TuaA5",
        "JagZYVoiuhym",
        "EBKbu8RMuoAc",
        "5lIDC94Kuswf",
        "91SH15zVhvzh",
        "Za-wShv4Xv9s",
        "_tr1YWqIXv9t",
        "b2lO7Ze2Xv9t",
        "UzyTfi1UXv9u"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mdgcXA96OO_"
      },
      "source": [
        "# Import All Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-e1q38xWOnp",
        "outputId": "3419b95a-d02c-49f0-abe4-3808665c4ef8"
      },
      "source": [
        "from os import path\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Dropout\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.linear_model import LinearRegression \n",
        "\n",
        "#from time_series_conversion import build_timeseries, convert_price\n",
        "\n",
        "# Connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWihgLyUFpCahFTw_b0O1G5cRBem6hmLiTdzJi9viwHJiY8FJRefEKU\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKLavaL3mLt2"
      },
      "source": [
        "# Price Generator\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5WS0LFmWdkS"
      },
      "source": [
        "TIME_STEPS = 24 # How far in the past you want to use past data as features\n",
        "TARGET_TIME_STEPS = 12 # How far in the future you want to make predictions\n",
        "#INP_COLS = [0, 1, 2, 3, 4]\n",
        "INP_COLS = [1]\n",
        "OUT_COL = 1\n",
        "N_ITER = 500\n",
        "\n",
        "\n",
        "def build_timeseries(mat, input_cols, output_col, time_steps, target_time_steps):\n",
        "    # input_cols is a list of columns that would act as input columns\n",
        "    # output_col is the column that would act as output column\n",
        "    # total number of time-series samples = len(mat) - time_steps - target_time_steps + 1\n",
        "    dim_0 = mat.shape[0] - time_steps - target_time_steps + 1\n",
        "    dim_1 = len(input_cols)\n",
        "    \n",
        "    x = np.zeros((dim_0, time_steps))\n",
        "    y = np.zeros((dim_0,))\n",
        "    \n",
        "    for i in range(dim_0):  \n",
        "        x[i] = mat[i: time_steps + i]\n",
        "        y[i] = mat[time_steps + target_time_steps + i - 1]\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def convert_price(pred, sc, feature_num, out_col):\n",
        "# Return predicted price for given input\n",
        "    #pred_reverted = np.zeros(shape=(pred.shape[0], 1))\n",
        "    #pred_reverted[:, 0] = pred\n",
        "    pred_reverted = sc.inverse_transform(pred.reshape(-1, 1))\n",
        "    predicted_price = pred_reverted[:]\n",
        "    return predicted_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZDnaX8wWyT4"
      },
      "source": [
        "def lstm_price_generator(current_data):\n",
        "  sc = MinMaxScaler(feature_range = (0, 1))\n",
        "  normalized_data = sc.fit_transform(current_data.values.reshape(-1, 1))\n",
        "  normalized_data = normalized_data.ravel()\n",
        "  normalized_data = pd.Series(list(normalized_data))\n",
        "  \n",
        "  current_data_val = current_data.iloc[int(0.6*train_len):train_len]\n",
        "  current_data_test = current_data.iloc[train_len:]\n",
        "  #Build time series model for linear regression\n",
        "  x_train, y_train = build_timeseries(mat=normalized_data.iloc[:int(0.6*train_len)].values, input_cols=INP_COLS, output_col=OUT_COL, \n",
        "                                          time_steps=TIME_STEPS, target_time_steps=TARGET_TIME_STEPS)\n",
        "  x_val, y_val = build_timeseries(mat=normalized_data.iloc[int(0.6*train_len) -(TIME_STEPS + TARGET_TIME_STEPS - 1):train_len].values, input_cols=INP_COLS, output_col=OUT_COL, \n",
        "                                          time_steps=TIME_STEPS, target_time_steps=TARGET_TIME_STEPS)\n",
        "  x_test, y_test = build_timeseries(mat=normalized_data.iloc[int(train_len) -(TIME_STEPS + TARGET_TIME_STEPS - 1):].values, input_cols=INP_COLS, output_col=OUT_COL, \n",
        "                                          time_steps=TIME_STEPS, target_time_steps=TARGET_TIME_STEPS)\n",
        "  print(y_train)\n",
        "  inputs = Input(shape=(TIME_STEPS, 1))\n",
        "  hidden = LSTM(64, dropout=0.01, recurrent_dropout=0.05)(inputs)\n",
        "  hidden = Dense(32, activation='relu')(hidden)\n",
        "  hidden = Dropout(0.1)(hidden) \n",
        "  outputs = Dense(1)(hidden)\n",
        "  model = Model(inputs, outputs)\n",
        "  # Compiling the RNN\n",
        "  model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "  model.summary()\n",
        "  NUM_EPOCHS = 500\n",
        "  early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "  # Fitting the RNN to the Training set\n",
        "  history = model.fit(\n",
        "              x=x_train, \n",
        "              y=y_train,\n",
        "              epochs=NUM_EPOCHS,\n",
        "              batch_size=64,\n",
        "              validation_data=(x_val, y_val), \n",
        "              callbacks=[early_stopping_monitor]\n",
        "  )\n",
        "\n",
        "  pred_val = model.predict(x_val).flatten()\n",
        "  predicted_price_val = convert_price(pred_val, sc, 1, OUT_COL)\n",
        "  try:\n",
        "    inherent_noice = mean_squared_error(current_data_val, predicted_price_val)\n",
        "  except:\n",
        "    inherent_noice = 0\n",
        "  pred_do = np.stack([model(x_test, training=True) for _ in range(N_ITER)])\n",
        "  pred_do = pred_do.reshape((N_ITER, testing_num))\n",
        "  # .,,,,.print(predicted_price_val)\n",
        "  # Convert these predictions into price\n",
        "  for row in range(pred_do.shape[0]):\n",
        "    #print(convert_price(pred_do[row, :], sc, 1, OUT_COL))\n",
        "    pred_do[row, :] = convert_price(pred_do[row, :], sc, 1, OUT_COL).T\n",
        "\n",
        "  current_average = 0\n",
        "  current_std = 0\n",
        "  average_predicted_price = []\n",
        "  std_predicted_price = []\n",
        "  for i in pred_do.T:\n",
        "    if not math.isnan(i.mean()):\n",
        "      average_predicted_price.append(i.mean())\n",
        "      current_average = i.mean()\n",
        "      current_std = (i.std() + inherent_noice) ** 0.5\n",
        "      std_predicted_price.append(current_std)\n",
        "    else :\n",
        "      average_predicted_price.append(current_average)\n",
        "      std_predicted_price.append(current_std)\n",
        "\n",
        "  return average_predicted_price, std_predicted_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvdPE6ZrV89j"
      },
      "source": [
        "# Cryptocurrency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCIU42PfOVN7"
      },
      "source": [
        "## BTC-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl-y9q1iafIb",
        "outputId": "732331de-e276-4d55-f91f-51043e16a1e6"
      },
      "source": [
        "btc_data = pd.read_csv('/content/drive/My Drive/lstm_stock_predictions/BTC-USD.csv', index_col=0, parse_dates=True)\n",
        "total = len(btc_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(btc_data))\n",
        "train_len\n",
        "predicted_btc_price, predicted_btc_std = lstm_price_generator(btc_data['Close'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 4s 89ms/step - loss: 0.0051 - val_loss: 3.1706e-04\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 9.3648e-04 - val_loss: 4.6557e-04\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.9681e-04 - val_loss: 3.3332e-04\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.2824e-04 - val_loss: 2.6586e-04\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.1120e-04 - val_loss: 3.1500e-04\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.3824e-04 - val_loss: 3.6185e-04\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 6.9736e-04 - val_loss: 2.7348e-04\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.4372e-04 - val_loss: 2.6561e-04\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.2707e-04 - val_loss: 2.7260e-04\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 5.5387e-04 - val_loss: 3.2273e-04\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.5623e-04 - val_loss: 3.1005e-04\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.1758e-04 - val_loss: 2.8416e-04\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.3852e-04 - val_loss: 2.6756e-04\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.9182e-04 - val_loss: 2.5943e-04\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.3027e-04 - val_loss: 2.5825e-04\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.5364e-04 - val_loss: 3.3398e-04\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.8738e-04 - val_loss: 3.0104e-04\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 5.6140e-04 - val_loss: 3.1223e-04\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.4870e-04 - val_loss: 2.6514e-04\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 5.7135e-04 - val_loss: 2.5589e-04\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 4.8810e-04 - val_loss: 2.6183e-04\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.5046e-04 - val_loss: 2.6094e-04\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 5.3677e-04 - val_loss: 2.6577e-04\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.0527e-04 - val_loss: 4.3927e-04\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.6633e-04 - val_loss: 3.7857e-04\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.1978e-04 - val_loss: 3.9398e-04\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.9253e-04 - val_loss: 2.8566e-04\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.1223e-04 - val_loss: 2.7558e-04\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.4186e-04 - val_loss: 3.4908e-04\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.0199e-04 - val_loss: 2.6871e-04\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.0711e-04 - val_loss: 2.7161e-04\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.6600e-04 - val_loss: 2.7471e-04\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.6702e-04 - val_loss: 2.7737e-04\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.8826e-04 - val_loss: 2.9538e-04\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.8306e-04 - val_loss: 2.7084e-04\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.0907e-04 - val_loss: 2.9806e-04\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.7675e-04 - val_loss: 3.1932e-04\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.1745e-04 - val_loss: 3.0947e-04\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.6473e-04 - val_loss: 2.7878e-04\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.0132e-04 - val_loss: 2.6721e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDeE5QvJa0Z9",
        "outputId": "c75fa482-5432-4539-b39d-026c195eba68"
      },
      "source": [
        "test_price = btc_data[train_len:] \n",
        "test_price['Predicted'] = predicted_btc_price\n",
        "test_price['Predicted_std'] = predicted_btc_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/BTC-USD_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEO39H-tPnA7"
      },
      "source": [
        "## USD - ETH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6JHCPVFLOND",
        "outputId": "82bfbf0e-d298-4568-cfc0-452c854cca90"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/ETH-USD.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 4s 88ms/step - loss: 0.0061 - val_loss: 5.1700e-04\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 1.2584e-04\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 9.0577e-04 - val_loss: 3.0825e-04\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0011 - val_loss: 8.5512e-05\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 8.1587e-04 - val_loss: 1.2254e-04\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 8.8918e-04 - val_loss: 2.3675e-04\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.5931e-04 - val_loss: 1.9090e-04\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 8.1319e-04 - val_loss: 2.3583e-04\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.9805e-04 - val_loss: 2.3256e-04\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.6720e-04 - val_loss: 1.5974e-04\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 8.5610e-04 - val_loss: 2.5053e-04\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.3506e-04 - val_loss: 3.1776e-04\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.1467e-04 - val_loss: 1.3284e-04\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.2537e-04 - val_loss: 2.5179e-04\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 6.5667e-04 - val_loss: 1.8982e-04\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 6.2445e-04 - val_loss: 2.5192e-04\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.8117e-04 - val_loss: 3.0095e-04\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.1723e-04 - val_loss: 3.2455e-04\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.5606e-04 - val_loss: 3.6676e-04\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.0541e-04 - val_loss: 2.1437e-04\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.9681e-04 - val_loss: 3.2147e-04\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.9181e-04 - val_loss: 2.0114e-04\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.6159e-04 - val_loss: 2.8019e-04\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.7135e-04 - val_loss: 2.9956e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnw1QqZFPxJk",
        "outputId": "4a26189f-2569-4f8b-ab64-64acb79cdcdd"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/ETH-USD_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAhM2oc2P2N2"
      },
      "source": [
        "## USD - DOGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvbhhWLmP0x9",
        "outputId": "d195f3a2-8670-4de7-cac0-b318dc99aabf"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/DOGE-USD.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 4s 90ms/step - loss: 1.9181e-05 - val_loss: 3.4484e-06\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1.0880e-05 - val_loss: 4.1633e-06\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 8.6800e-06 - val_loss: 1.7447e-06\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.7558e-06 - val_loss: 1.2827e-06\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.4317e-06 - val_loss: 1.4463e-06\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.5487e-06 - val_loss: 2.1110e-06\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 5.3145e-06 - val_loss: 1.9498e-06\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.4790e-06 - val_loss: 2.4178e-06\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.5728e-06 - val_loss: 3.7817e-06\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 6.2418e-06 - val_loss: 1.6540e-06\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.0992e-06 - val_loss: 1.1740e-06\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 5.1238e-06 - val_loss: 1.6468e-06\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6.0314e-06 - val_loss: 1.6549e-06\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.6640e-06 - val_loss: 1.1587e-06\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.3663e-06 - val_loss: 2.6459e-06\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.6775e-06 - val_loss: 1.1108e-06\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.9012e-06 - val_loss: 1.0642e-06\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.9624e-06 - val_loss: 3.9323e-06\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.5047e-06 - val_loss: 1.2066e-06\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.1224e-06 - val_loss: 1.5155e-06\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.9755e-06 - val_loss: 3.0729e-06\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.5063e-06 - val_loss: 1.0992e-06\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 4.4769e-06 - val_loss: 1.0504e-06\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.3983e-06 - val_loss: 6.9548e-06\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.7468e-06 - val_loss: 2.1529e-06\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 6.0386e-06 - val_loss: 1.1333e-06\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 5.5781e-06 - val_loss: 1.3529e-06\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.6803e-06 - val_loss: 2.1703e-06\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.6082e-06 - val_loss: 1.3658e-06\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.7937e-06 - val_loss: 1.0577e-06\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.6142e-06 - val_loss: 1.1099e-06\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.2650e-06 - val_loss: 1.0220e-06\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.7694e-06 - val_loss: 1.1341e-06\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.6734e-06 - val_loss: 2.0541e-06\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 5.0572e-06 - val_loss: 1.0240e-06\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.7988e-06 - val_loss: 1.0566e-06\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.4011e-06 - val_loss: 1.2757e-06\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.0854e-06 - val_loss: 1.4315e-06\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 4.8799e-06 - val_loss: 2.5849e-06\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.8884e-06 - val_loss: 1.3506e-06\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.3552e-06 - val_loss: 1.1818e-06\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.6485e-06 - val_loss: 1.0156e-06\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.3589e-06 - val_loss: 9.6469e-07\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.5100e-06 - val_loss: 1.2643e-06\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 4.0257e-06 - val_loss: 1.0973e-06\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.9776e-06 - val_loss: 1.2531e-06\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 3.5779e-06 - val_loss: 1.1180e-06\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.7988e-06 - val_loss: 9.3289e-07\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.0828e-06 - val_loss: 9.7843e-07\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.3041e-06 - val_loss: 1.9510e-06\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.5441e-06 - val_loss: 1.1721e-06\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 4.6506e-06 - val_loss: 1.4982e-06\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.5942e-06 - val_loss: 1.7741e-06\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.5454e-06 - val_loss: 1.9337e-06\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.9340e-06 - val_loss: 1.1055e-06\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.7573e-06 - val_loss: 1.2545e-06\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.8197e-06 - val_loss: 2.2423e-06\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.9206e-06 - val_loss: 9.8528e-07\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.8742e-06 - val_loss: 2.4220e-06\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.5315e-06 - val_loss: 9.7040e-07\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.1867e-06 - val_loss: 2.5814e-06\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.7062e-06 - val_loss: 1.2443e-06\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 3.2186e-06 - val_loss: 1.4856e-06\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.1121e-06 - val_loss: 1.1690e-06\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.4482e-06 - val_loss: 1.2816e-06\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.0771e-06 - val_loss: 1.1834e-06\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.4634e-06 - val_loss: 1.1762e-06\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.6315e-06 - val_loss: 1.2915e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDio0jgmQMda",
        "outputId": "77b59ea7-bb91-4a25-a14c-7ef750a96882"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/DOGE-USD_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMnU4tItQGqi"
      },
      "source": [
        "## USD - XRP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Np3YEvcQEYV",
        "outputId": "4b4a243c-7d1c-4769-96ce-ac421856225e"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/XRP-USD.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 4s 86ms/step - loss: 0.0282 - val_loss: 3.4312e-04\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0109 - val_loss: 8.0063e-04\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0011\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 4.2715e-04\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 8.9180e-04\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0010\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0071 - val_loss: 6.9163e-04\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0076 - val_loss: 7.5506e-04\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0101 - val_loss: 5.3571e-04\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0082 - val_loss: 6.2826e-04\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0081 - val_loss: 4.3515e-04\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0015\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0017\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0071 - val_loss: 0.0020\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0048 - val_loss: 0.0021\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0010\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0018\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 8.9005e-04\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0070 - val_loss: 0.0018\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0015\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0065 - val_loss: 7.4912e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4l3GNu8Qlh2",
        "outputId": "6d4b7d0f-9603-42f6-d8d6-aa65de260a8f"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/XRP-USD_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btk9kBZNQt41"
      },
      "source": [
        "## USD - LTC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hkw5C60QtY2",
        "outputId": "e8394bc2-2b5f-43a4-bb80-eedb87d953cb"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/LTC-USD.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 4s 87ms/step - loss: 0.0462 - val_loss: 0.0037\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0148 - val_loss: 0.0027\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0102 - val_loss: 0.0015\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0084 - val_loss: 0.0010\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0070 - val_loss: 0.0013\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0085 - val_loss: 0.0013\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0013\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0013\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0018\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0079 - val_loss: 0.0016\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0017\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0085 - val_loss: 0.0024\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0013\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0083 - val_loss: 0.0036\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0026\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0017\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0018\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0036\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0022\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0031\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 0.0016\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0023\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0065 - val_loss: 0.0041\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 0.0020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRUCXyfPQzYM",
        "outputId": "f459ebcf-3a31-4d6b-9ab3-c4a92b5d45fe"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/LTC-USD_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XbSq0oGQ3U4"
      },
      "source": [
        "##USD - BCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghGcuu-wQ5Hq",
        "outputId": "4af17a06-8ae1-45b4-fcca-a2007a7a9602"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/BCH-USD.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "9/9 [==============================] - 4s 119ms/step - loss: 0.0503 - val_loss: 0.0046\n",
            "Epoch 2/500\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0123 - val_loss: 8.5370e-04\n",
            "Epoch 3/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0114 - val_loss: 7.1043e-04\n",
            "Epoch 4/500\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0095 - val_loss: 0.0013\n",
            "Epoch 5/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 5.3696e-04\n",
            "Epoch 6/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0102 - val_loss: 5.2530e-04\n",
            "Epoch 7/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0088 - val_loss: 5.3266e-04\n",
            "Epoch 8/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0085 - val_loss: 4.6973e-04\n",
            "Epoch 9/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0092 - val_loss: 3.4271e-04\n",
            "Epoch 10/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0086 - val_loss: 8.5137e-04\n",
            "Epoch 11/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0086 - val_loss: 4.1883e-04\n",
            "Epoch 12/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0086 - val_loss: 7.7815e-04\n",
            "Epoch 13/500\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0096 - val_loss: 2.5987e-04\n",
            "Epoch 14/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 6.8297e-04\n",
            "Epoch 15/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 3.7826e-04\n",
            "Epoch 16/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 5.0685e-04\n",
            "Epoch 17/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0102 - val_loss: 3.2611e-04\n",
            "Epoch 18/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 3.5561e-04\n",
            "Epoch 19/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 5.4881e-04\n",
            "Epoch 20/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 3.1659e-04\n",
            "Epoch 21/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 3.2324e-04\n",
            "Epoch 22/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0094 - val_loss: 3.1047e-04\n",
            "Epoch 23/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0087 - val_loss: 3.1773e-04\n",
            "Epoch 24/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 7.9526e-04\n",
            "Epoch 25/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 2.9764e-04\n",
            "Epoch 26/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0082 - val_loss: 5.6116e-04\n",
            "Epoch 27/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0093 - val_loss: 3.2208e-04\n",
            "Epoch 28/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 3.6555e-04\n",
            "Epoch 29/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0075 - val_loss: 3.0736e-04\n",
            "Epoch 30/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 3.2263e-04\n",
            "Epoch 31/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0079 - val_loss: 3.0240e-04\n",
            "Epoch 32/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 4.1115e-04\n",
            "Epoch 33/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0080 - val_loss: 3.4962e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky4R6v5aQ-Bb",
        "outputId": "79e2b430-d70a-4701-e679-71bef135aed5"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/BCH-USD_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9iZUIC6S6-B"
      },
      "source": [
        "## USD - ADA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRf4u0dSRAM0",
        "outputId": "ec09d072-32e2-4369-a17e-9e28d22cffff"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/ADA-USD.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "9/9 [==============================] - 4s 109ms/step - loss: 0.0086 - val_loss: nan\n",
            "Epoch 2/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0051 - val_loss: nan\n",
            "Epoch 3/500\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0037 - val_loss: nan\n",
            "Epoch 4/500\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0034 - val_loss: nan\n",
            "Epoch 5/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: nan\n",
            "Epoch 6/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: nan\n",
            "Epoch 7/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0027 - val_loss: nan\n",
            "Epoch 8/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: nan\n",
            "Epoch 9/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: nan\n",
            "Epoch 10/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0024 - val_loss: nan\n",
            "Epoch 11/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0019 - val_loss: nan\n",
            "Epoch 12/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0019 - val_loss: nan\n",
            "Epoch 13/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0015 - val_loss: nan\n",
            "Epoch 14/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0018 - val_loss: nan\n",
            "Epoch 15/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0022 - val_loss: nan\n",
            "Epoch 16/500\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: nan\n",
            "Epoch 17/500\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: nan\n",
            "Epoch 18/500\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0018 - val_loss: nan\n",
            "Epoch 19/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0017 - val_loss: nan\n",
            "Epoch 20/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuXFnzmcTAiv",
        "outputId": "38932552-fff4-4544-deef-4cee64547861"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/ADA-USD_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYOApVofTCpI"
      },
      "source": [
        "## USD - BNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohDT4s2_TCIR",
        "outputId": "e19fc72f-d2e5-4e3e-8534-02edd7c5d142"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/BNB-USD.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "9/9 [==============================] - 4s 112ms/step - loss: 9.6557e-05 - val_loss: 3.5047e-04\n",
            "Epoch 2/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 4.1534e-05 - val_loss: 2.4755e-04\n",
            "Epoch 3/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 3.3527e-05 - val_loss: 1.5924e-04\n",
            "Epoch 4/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 2.0891e-05 - val_loss: 1.0737e-04\n",
            "Epoch 5/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 2.1957e-05 - val_loss: 7.5940e-05\n",
            "Epoch 6/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 2.2224e-05 - val_loss: 8.6865e-05\n",
            "Epoch 7/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 2.0548e-05 - val_loss: 1.1635e-04\n",
            "Epoch 8/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 1.8649e-05 - val_loss: 8.5038e-05\n",
            "Epoch 9/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.4886e-05 - val_loss: 8.7413e-05\n",
            "Epoch 10/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 1.6708e-05 - val_loss: 1.0552e-04\n",
            "Epoch 11/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 1.7143e-05 - val_loss: 1.0028e-04\n",
            "Epoch 12/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.5585e-05 - val_loss: 1.3739e-04\n",
            "Epoch 13/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.7721e-05 - val_loss: 9.4391e-05\n",
            "Epoch 14/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.7500e-05 - val_loss: 1.0174e-04\n",
            "Epoch 15/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.7865e-05 - val_loss: 1.0349e-04\n",
            "Epoch 16/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 1.7205e-05 - val_loss: 1.2573e-04\n",
            "Epoch 17/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.3564e-05 - val_loss: 9.6305e-05\n",
            "Epoch 18/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.5415e-05 - val_loss: 1.2670e-04\n",
            "Epoch 19/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.6513e-05 - val_loss: 1.1950e-04\n",
            "Epoch 20/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.2594e-05 - val_loss: 1.2856e-04\n",
            "Epoch 21/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.2875e-05 - val_loss: 1.2399e-04\n",
            "Epoch 22/500\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.6905e-05 - val_loss: 1.1447e-04\n",
            "Epoch 23/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.7780e-05 - val_loss: 1.2607e-04\n",
            "Epoch 24/500\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.6449e-05 - val_loss: 1.3145e-04\n",
            "Epoch 25/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.5103e-05 - val_loss: 1.4343e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIi8mHxpTGNe",
        "outputId": "005d7532-ec5e-4fba-e249-1e4a97d13336"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/BNB-USD_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTmc2tTbTK1C"
      },
      "source": [
        "# S&P 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvnaOt8sTtZ8"
      },
      "source": [
        "## AAPL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1LgSQyPTsK9",
        "outputId": "418484ff-ab89-41bb-ccb1-02a7afbc2902"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/AAPL.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00551018 0.00756534 0.00923599 ... 0.16494547 0.16244354 0.151962  ]\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 3s 60ms/step - loss: 0.0017 - val_loss: 0.0037\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 4.0399e-04 - val_loss: 5.7215e-04\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.3791e-04 - val_loss: 1.9912e-04\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.1313e-04 - val_loss: 1.9147e-04\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.8148e-04 - val_loss: 1.8991e-04\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.6119e-04 - val_loss: 2.1538e-04\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.6305e-04 - val_loss: 1.9076e-04\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.5855e-04 - val_loss: 1.9009e-04\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.5538e-04 - val_loss: 1.8848e-04\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.6654e-04 - val_loss: 4.1751e-04\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 1.7101e-04 - val_loss: 1.8720e-04\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.7027e-04 - val_loss: 1.8748e-04\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.4136e-04 - val_loss: 1.8861e-04\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 1.4884e-04 - val_loss: 1.8469e-04\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.4236e-04 - val_loss: 2.7706e-04\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.6954e-04 - val_loss: 1.9138e-04\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.4292e-04 - val_loss: 1.8731e-04\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.3997e-04 - val_loss: 2.1966e-04\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 1.3725e-04 - val_loss: 1.8397e-04\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.2902e-04 - val_loss: 1.8362e-04\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.3891e-04 - val_loss: 1.8395e-04\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.2767e-04 - val_loss: 2.0491e-04\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.3201e-04 - val_loss: 2.0795e-04\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.2517e-04 - val_loss: 1.8252e-04\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.3432e-04 - val_loss: 1.8247e-04\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.4002e-04 - val_loss: 3.1608e-04\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.4989e-04 - val_loss: 1.9810e-04\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 1.2831e-04 - val_loss: 1.8266e-04\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.2414e-04 - val_loss: 2.2074e-04\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.1987e-04 - val_loss: 1.8259e-04\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.2573e-04 - val_loss: 1.9753e-04\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.3980e-04 - val_loss: 2.2431e-04\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 1.2598e-04 - val_loss: 1.7992e-04\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.1444e-04 - val_loss: 2.5450e-04\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.3128e-04 - val_loss: 1.8093e-04\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.2723e-04 - val_loss: 1.8176e-04\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.2119e-04 - val_loss: 1.9091e-04\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.1709e-04 - val_loss: 2.0746e-04\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.1076e-04 - val_loss: 2.1376e-04\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.1603e-04 - val_loss: 1.8894e-04\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.1948e-04 - val_loss: 1.8709e-04\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.1316e-04 - val_loss: 2.3286e-04\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.1601e-04 - val_loss: 2.1205e-04\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 1.2349e-04 - val_loss: 1.9318e-04\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.1423e-04 - val_loss: 1.9769e-04\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.2191e-04 - val_loss: 1.9705e-04\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 1.1368e-04 - val_loss: 1.9910e-04\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 1.2058e-04 - val_loss: 2.3108e-04\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.1573e-04 - val_loss: 1.8362e-04\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 1.2244e-04 - val_loss: 1.9852e-04\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 1.1806e-04 - val_loss: 1.9189e-04\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 1.2595e-04 - val_loss: 1.8673e-04\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 1.1563e-04 - val_loss: 2.5324e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anWmcVY5T1Ie",
        "outputId": "04e2b141-690e-44c0-a9c8-f045a4da7a15"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/AAPL_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q43Ht3kqT5N4"
      },
      "source": [
        "##FB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txQPtnLPT4Rn",
        "outputId": "539e6e58-d5a1-456a-9eee-f337f8b73165"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/FB.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "15/15 [==============================] - 4s 78ms/step - loss: 0.0170 - val_loss: 0.0039\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0026 - val_loss: 0.0012\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 9.4236e-04 - val_loss: 0.0017\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 6.6624e-04 - val_loss: 7.7855e-04\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 5.0395e-04 - val_loss: 7.6942e-04\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 5.3248e-04 - val_loss: 9.5294e-04\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 6.0024e-04 - val_loss: 9.8637e-04\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 5.3715e-04 - val_loss: 7.4328e-04\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.1785e-04 - val_loss: 7.4200e-04\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.7199e-04 - val_loss: 8.7614e-04\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 5.6265e-04 - val_loss: 0.0011\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.7292e-04 - val_loss: 7.0010e-04\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 5.5746e-04 - val_loss: 7.0702e-04\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 5.2810e-04 - val_loss: 0.0012\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.8191e-04 - val_loss: 9.5776e-04\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.4180e-04 - val_loss: 7.0098e-04\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.8224e-04 - val_loss: 7.2767e-04\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.9068e-04 - val_loss: 0.0013\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 4.2644e-04 - val_loss: 0.0014\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.1607e-04 - val_loss: 8.3466e-04\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.1036e-04 - val_loss: 0.0012\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.3090e-04 - val_loss: 6.7767e-04\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.2999e-04 - val_loss: 9.0195e-04\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.7207e-04 - val_loss: 9.2814e-04\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.8780e-04 - val_loss: 0.0013\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.4817e-04 - val_loss: 6.7195e-04\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.1974e-04 - val_loss: 0.0011\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.2125e-04 - val_loss: 0.0014\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.4083e-04 - val_loss: 8.9404e-04\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.0330e-04 - val_loss: 7.4826e-04\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 4.0065e-04 - val_loss: 0.0013\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.3861e-04 - val_loss: 9.6484e-04\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.7277e-04 - val_loss: 0.0013\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.0061e-04 - val_loss: 9.0971e-04\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.4671e-04 - val_loss: 9.3412e-04\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.3777e-04 - val_loss: 8.7731e-04\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.0491e-04 - val_loss: 0.0017\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.5736e-04 - val_loss: 0.0014\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.4017e-04 - val_loss: 0.0016\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 4.1728e-04 - val_loss: 9.9596e-04\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 3.8138e-04 - val_loss: 9.0137e-04\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.4195e-04 - val_loss: 0.0014\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.5523e-04 - val_loss: 0.0016\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 3.2480e-04 - val_loss: 0.0010\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 3.9207e-04 - val_loss: 0.0012\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.5167e-04 - val_loss: 0.0011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNZWFI0JT-tt",
        "outputId": "80e17584-4341-4e7d-efa7-c393901e5176"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/FB_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPA-qNOrUef8"
      },
      "source": [
        "##TSLA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zodcFl4rUef8",
        "outputId": "543c22a9-c60f-4027-f288-b26703c1bf5d"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/TSLA.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 71ms/step - loss: 6.0580e-04 - val_loss: 8.2940e-04\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.6996e-04 - val_loss: 3.7945e-05\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.8646e-05 - val_loss: 5.8470e-05\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.8315e-05 - val_loss: 5.8177e-05\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.6608e-05 - val_loss: 5.3799e-05\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.9242e-05 - val_loss: 5.2925e-05\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.7703e-05 - val_loss: 5.7465e-05\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.7942e-05 - val_loss: 5.2991e-05\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.6048e-05 - val_loss: 4.4641e-05\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.6329e-05 - val_loss: 6.6171e-05\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.8639e-05 - val_loss: 4.2249e-05\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3904e-05 - val_loss: 4.6529e-05\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.5250e-05 - val_loss: 4.5696e-05\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.3247e-05 - val_loss: 3.9842e-05\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.1148e-05 - val_loss: 3.9941e-05\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3967e-05 - val_loss: 3.5420e-05\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2383e-05 - val_loss: 3.7518e-05\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.0997e-05 - val_loss: 4.7943e-05\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.1768e-05 - val_loss: 5.7535e-05\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.5809e-05 - val_loss: 6.8268e-05\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.5077e-05 - val_loss: 5.4190e-05\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.4650e-05 - val_loss: 3.8007e-05\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3732e-05 - val_loss: 3.5266e-05\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.1435e-05 - val_loss: 3.8714e-05\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3572e-05 - val_loss: 4.0991e-05\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.2252e-05 - val_loss: 4.6730e-05\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0351e-05 - val_loss: 5.1435e-05\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2147e-05 - val_loss: 7.7835e-05\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.7392e-05 - val_loss: 5.2434e-05\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.9487e-05 - val_loss: 4.9977e-05\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.0032e-05 - val_loss: 4.5719e-05\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0491e-05 - val_loss: 5.0044e-05\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.0416e-05 - val_loss: 4.2977e-05\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.1820e-05 - val_loss: 5.2345e-05\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0967e-05 - val_loss: 5.7772e-05\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0658e-05 - val_loss: 4.4171e-05\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2771e-05 - val_loss: 4.2247e-05\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.9953e-05 - val_loss: 5.4076e-05\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.9337e-05 - val_loss: 5.5195e-05\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.9844e-05 - val_loss: 4.2284e-05\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.8035e-05 - val_loss: 4.1076e-05\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 1.9592e-05 - val_loss: 4.4796e-05\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.9601e-05 - val_loss: 3.4242e-05\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.0540e-05 - val_loss: 5.3432e-05\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.3566e-05 - val_loss: 4.7976e-05\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.1472e-05 - val_loss: 3.5690e-05\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0872e-05 - val_loss: 3.4945e-05\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0501e-05 - val_loss: 5.0808e-05\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0988e-05 - val_loss: 3.9408e-05\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.9727e-05 - val_loss: 4.7322e-05\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 1.9862e-05 - val_loss: 6.1738e-05\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3062e-05 - val_loss: 4.4254e-05\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 2.0326e-05 - val_loss: 3.8885e-05\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.8424e-05 - val_loss: 5.4070e-05\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.0387e-05 - val_loss: 4.9605e-05\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 1.9848e-05 - val_loss: 3.2107e-05\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.9496e-05 - val_loss: 3.4852e-05\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2704e-05 - val_loss: 4.8435e-05\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.8696e-05 - val_loss: 4.5709e-05\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.9603e-05 - val_loss: 3.8655e-05\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 1.8933e-05 - val_loss: 3.7130e-05\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0482e-05 - val_loss: 3.9770e-05\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2485e-05 - val_loss: 3.6106e-05\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2313e-05 - val_loss: 5.2289e-05\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2031e-05 - val_loss: 4.1944e-05\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.2137e-05 - val_loss: 5.6543e-05\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.7640e-05 - val_loss: 4.4146e-05\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0322e-05 - val_loss: 3.2699e-05\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.8972e-05 - val_loss: 3.9303e-05\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.9149e-05 - val_loss: 3.2566e-05\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.8006e-05 - val_loss: 5.3618e-05\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.1066e-05 - val_loss: 3.9579e-05\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.1032e-05 - val_loss: 4.2689e-05\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.9062e-05 - val_loss: 3.5251e-05\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.8848e-05 - val_loss: 5.2504e-05\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.1603e-05 - val_loss: 4.7529e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoSZt4InUef9",
        "outputId": "edeadf11-5f95-44c4-8588-b84bd74533aa"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/TSLA_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8qPHsjGUpTh"
      },
      "source": [
        "##GOOGL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncbIBBWsUpTh",
        "outputId": "c353670a-ae3d-4f19-d13e-203feb5d0564"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/GOOGL.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 73ms/step - loss: 0.0080 - val_loss: 0.0082\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0015 - val_loss: 0.0027\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.6262e-04 - val_loss: 8.5387e-04\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.6000e-04 - val_loss: 0.0016\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 4.0030e-04 - val_loss: 8.3642e-04\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.6754e-04 - val_loss: 8.2894e-04\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.0923e-04 - val_loss: 7.5469e-04\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 3.0919e-04 - val_loss: 7.3380e-04\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.8432e-04 - val_loss: 4.8049e-04\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.8365e-04 - val_loss: 7.2576e-04\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.4122e-04 - val_loss: 5.1772e-04\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.5094e-04 - val_loss: 9.9728e-04\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.7248e-04 - val_loss: 7.7871e-04\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3875e-04 - val_loss: 0.0012\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.8593e-04 - val_loss: 7.5825e-04\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.4352e-04 - val_loss: 9.2432e-04\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2926e-04 - val_loss: 8.0443e-04\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.5277e-04 - val_loss: 0.0011\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.2619e-04 - val_loss: 9.0283e-04\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.3633e-04 - val_loss: 0.0012\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2779e-04 - val_loss: 8.5518e-04\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.3915e-04 - val_loss: 0.0010\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.1951e-04 - val_loss: 0.0014\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.3784e-04 - val_loss: 0.0010\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0273e-04 - val_loss: 9.4479e-04\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3986e-04 - val_loss: 0.0010\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.5278e-04 - val_loss: 0.0012\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.4124e-04 - val_loss: 0.0012\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.5068e-04 - val_loss: 0.0018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf3QBS8BUpTi",
        "outputId": "69ed7a11-5d29-4916-e567-e2d74eadd5ca"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/GOOGL_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyLlq5yuVDiS"
      },
      "source": [
        "##BRK-B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fue6F2OoVDiS",
        "outputId": "08a7e346-75af-4e56-aeeb-9c10055563f7"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/BRK-B.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 71ms/step - loss: 0.0217 - val_loss: 0.0034\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0027 - val_loss: 0.0011\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0014 - val_loss: 7.3926e-04\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0010 - val_loss: 7.5005e-04\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0010 - val_loss: 6.8070e-04\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 8.3459e-04 - val_loss: 6.8660e-04\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.5840e-04 - val_loss: 9.8319e-04\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 8.3956e-04 - val_loss: 7.5449e-04\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.0805e-04 - val_loss: 6.7403e-04\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.1933e-04 - val_loss: 7.0827e-04\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 7.2491e-04 - val_loss: 8.6432e-04\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.3824e-04 - val_loss: 7.9110e-04\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.8532e-04 - val_loss: 8.2640e-04\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.1835e-04 - val_loss: 0.0011\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.8039e-04 - val_loss: 7.1908e-04\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 7.1748e-04 - val_loss: 0.0013\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.6500e-04 - val_loss: 7.9250e-04\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.5857e-04 - val_loss: 6.6889e-04\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.3466e-04 - val_loss: 8.9875e-04\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.9195e-04 - val_loss: 7.9544e-04\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.5614e-04 - val_loss: 9.0152e-04\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 8.1444e-04 - val_loss: 8.1420e-04\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.1786e-04 - val_loss: 6.9610e-04\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.4156e-04 - val_loss: 0.0011\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.9412e-04 - val_loss: 6.7900e-04\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.9773e-04 - val_loss: 0.0015\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.5474e-04 - val_loss: 7.4697e-04\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.5254e-04 - val_loss: 0.0019\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.6615e-04 - val_loss: 7.6787e-04\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.3510e-04 - val_loss: 0.0013\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.3323e-04 - val_loss: 9.1466e-04\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.6034e-04 - val_loss: 0.0016\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.8765e-04 - val_loss: 0.0016\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.2864e-04 - val_loss: 0.0011\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.6954e-04 - val_loss: 0.0012\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.2103e-04 - val_loss: 0.0011\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.5246e-04 - val_loss: 0.0010\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.6386e-04 - val_loss: 0.0012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsbZrVjTVDiT",
        "outputId": "e4a19c35-141e-4df2-d46c-b1f0062992fa"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/BRK-B_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "carzQ_t-VUM3"
      },
      "source": [
        "##JPM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q90RMORmVUM4",
        "outputId": "5747015d-ea7b-4d13-970f-7c109ebd919f"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/JPM.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 73ms/step - loss: 0.0185 - val_loss: 0.0052\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0021 - val_loss: 0.0045\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 8.8064e-04 - val_loss: 0.0011\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 8.5673e-04 - val_loss: 8.6488e-04\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.8808e-04 - val_loss: 7.6661e-04\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.8954e-04 - val_loss: 0.0014\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 7.2504e-04 - val_loss: 0.0011\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.9869e-04 - val_loss: 0.0013\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.4404e-04 - val_loss: 0.0011\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.7326e-04 - val_loss: 9.7792e-04\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.8021e-04 - val_loss: 8.1955e-04\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.2662e-04 - val_loss: 8.0249e-04\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.5612e-04 - val_loss: 8.6184e-04\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.2172e-04 - val_loss: 7.6529e-04\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.3567e-04 - val_loss: 7.6192e-04\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.2679e-04 - val_loss: 0.0011\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.1385e-04 - val_loss: 9.9284e-04\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.2836e-04 - val_loss: 7.7852e-04\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.5644e-04 - val_loss: 9.0225e-04\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.0051e-04 - val_loss: 8.1029e-04\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.8374e-04 - val_loss: 7.7151e-04\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.4762e-04 - val_loss: 8.0436e-04\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.3086e-04 - val_loss: 8.3816e-04\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.6128e-04 - val_loss: 0.0011\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.8690e-04 - val_loss: 7.6911e-04\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.4812e-04 - val_loss: 8.8290e-04\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.3747e-04 - val_loss: 7.8241e-04\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.8144e-04 - val_loss: 7.7375e-04\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.9650e-04 - val_loss: 7.8935e-04\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.8551e-04 - val_loss: 7.7290e-04\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.3857e-04 - val_loss: 9.9310e-04\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.2847e-04 - val_loss: 8.7917e-04\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.9082e-04 - val_loss: 7.4945e-04\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.9510e-04 - val_loss: 9.0452e-04\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.4299e-04 - val_loss: 7.2855e-04\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.4573e-04 - val_loss: 0.0011\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.7126e-04 - val_loss: 0.0010\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.4142e-04 - val_loss: 0.0011\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.1758e-04 - val_loss: 7.5217e-04\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.1146e-04 - val_loss: 0.0011\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.6743e-04 - val_loss: 9.2142e-04\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.7547e-04 - val_loss: 0.0018\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.4977e-04 - val_loss: 9.3754e-04\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.7291e-04 - val_loss: 7.6707e-04\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.2297e-04 - val_loss: 7.4211e-04\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.6566e-04 - val_loss: 0.0013\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.2104e-04 - val_loss: 7.6669e-04\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.6096e-04 - val_loss: 7.8137e-04\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.4970e-04 - val_loss: 7.4191e-04\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.3108e-04 - val_loss: 0.0011\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.5621e-04 - val_loss: 8.7979e-04\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.3578e-04 - val_loss: 8.5288e-04\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.4650e-04 - val_loss: 0.0012\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.0925e-04 - val_loss: 0.0014\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.4096e-04 - val_loss: 8.0913e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDZPkQZPVUM4",
        "outputId": "9d42ee95-a843-4c3b-f815-a298a652f6d2"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/JPM_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsYgtb_LVe16"
      },
      "source": [
        "##JNJ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gSps67tVe2G",
        "outputId": "5e2ca3a7-70a1-410d-8228-0f858c41af77"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/JNJ.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 72ms/step - loss: 0.0329 - val_loss: 0.0109\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0044 - val_loss: 0.0015\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0022 - val_loss: 0.0015\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0012 - val_loss: 0.0015\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0011 - val_loss: 0.0014\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0011 - val_loss: 0.0028\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.9051e-04 - val_loss: 0.0020\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 9.3164e-04 - val_loss: 0.0028\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 9.4498e-04 - val_loss: 0.0021\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.8728e-04 - val_loss: 0.0019\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.0957e-04 - val_loss: 0.0023\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 9.2039e-04 - val_loss: 0.0025\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 9.2949e-04 - val_loss: 0.0019\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.1811e-04 - val_loss: 0.0041\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.3522e-04 - val_loss: 0.0042\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 8.5015e-04 - val_loss: 0.0035\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 9.1388e-04 - val_loss: 0.0035\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 8.9815e-04 - val_loss: 0.0038\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.1004e-04 - val_loss: 0.0032\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0010 - val_loss: 0.0041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz9rWWwmVe2H",
        "outputId": "2a0c8074-1088-419d-f485-6c1b2814252b"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/JNJ_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ARTquwSVrHm"
      },
      "source": [
        "##SPY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOVrQP5xVrHn",
        "outputId": "2cba1397-94ff-4520-a051-17f6600fea9b"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/SPY.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 70ms/step - loss: 0.0155 - val_loss: 0.0050\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0019 - val_loss: 8.2972e-04\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0012 - val_loss: 3.8234e-04\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 7.4004e-04 - val_loss: 5.1564e-04\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 8.6317e-04 - val_loss: 5.9391e-04\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.3994e-04 - val_loss: 4.4136e-04\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.6346e-04 - val_loss: 3.7798e-04\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.7541e-04 - val_loss: 3.8673e-04\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 7.1863e-04 - val_loss: 4.1872e-04\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.1385e-04 - val_loss: 4.9767e-04\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 6.3976e-04 - val_loss: 4.0150e-04\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.4641e-04 - val_loss: 3.9133e-04\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.1016e-04 - val_loss: 5.7426e-04\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 6.0346e-04 - val_loss: 4.5772e-04\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.1888e-04 - val_loss: 6.5486e-04\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.0075e-04 - val_loss: 3.7303e-04\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.5981e-04 - val_loss: 4.5688e-04\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.5019e-04 - val_loss: 7.6631e-04\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.5000e-04 - val_loss: 4.4649e-04\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 6.1446e-04 - val_loss: 5.0309e-04\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.4680e-04 - val_loss: 4.6787e-04\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 6.5237e-04 - val_loss: 4.4783e-04\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 6.0049e-04 - val_loss: 6.2314e-04\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.9670e-04 - val_loss: 5.9039e-04\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.6065e-04 - val_loss: 4.5804e-04\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.5230e-04 - val_loss: 4.0188e-04\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.2562e-04 - val_loss: 5.8252e-04\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 4.6652e-04 - val_loss: 9.0962e-04\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.4992e-04 - val_loss: 3.9383e-04\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.7143e-04 - val_loss: 4.6736e-04\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 4.8770e-04 - val_loss: 3.7639e-04\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.3948e-04 - val_loss: 9.2427e-04\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 4.5558e-04 - val_loss: 5.6001e-04\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.6618e-04 - val_loss: 6.4859e-04\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.7787e-04 - val_loss: 4.0332e-04\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.1996e-04 - val_loss: 0.0011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYqcmW4MVrHn",
        "outputId": "e10d537a-0bce-4c57-9bc6-58290f845f63"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/SPY_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvuXKijgcDaI"
      },
      "source": [
        "##JNJ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "l8OKTRonVQeb",
        "outputId": "21fb9f38-b47f-463f-aea4-588e3a98cdbf"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/JNJ.csv', index_col=0, parse_dates=True)\n",
        "raw_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-05-19</th>\n",
              "      <td>66.529999</td>\n",
              "      <td>66.529999</td>\n",
              "      <td>65.849998</td>\n",
              "      <td>66.389999</td>\n",
              "      <td>49.643864</td>\n",
              "      <td>9685100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-05-20</th>\n",
              "      <td>66.250000</td>\n",
              "      <td>66.330002</td>\n",
              "      <td>65.279999</td>\n",
              "      <td>65.690002</td>\n",
              "      <td>49.120430</td>\n",
              "      <td>12367000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-05-23</th>\n",
              "      <td>65.190002</td>\n",
              "      <td>65.690002</td>\n",
              "      <td>65.080002</td>\n",
              "      <td>65.559998</td>\n",
              "      <td>49.023212</td>\n",
              "      <td>12020200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-05-24</th>\n",
              "      <td>65.739998</td>\n",
              "      <td>66.230003</td>\n",
              "      <td>65.500000</td>\n",
              "      <td>65.779999</td>\n",
              "      <td>49.187725</td>\n",
              "      <td>11017700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-05-25</th>\n",
              "      <td>66.290001</td>\n",
              "      <td>66.589996</td>\n",
              "      <td>66.070000</td>\n",
              "      <td>66.290001</td>\n",
              "      <td>49.569096</td>\n",
              "      <td>14767100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-12</th>\n",
              "      <td>168.539993</td>\n",
              "      <td>169.800003</td>\n",
              "      <td>167.949997</td>\n",
              "      <td>168.199997</td>\n",
              "      <td>168.199997</td>\n",
              "      <td>6758300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-13</th>\n",
              "      <td>166.970001</td>\n",
              "      <td>170.699997</td>\n",
              "      <td>166.970001</td>\n",
              "      <td>169.960007</td>\n",
              "      <td>169.960007</td>\n",
              "      <td>8018600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-14</th>\n",
              "      <td>171.479996</td>\n",
              "      <td>171.610001</td>\n",
              "      <td>170.169998</td>\n",
              "      <td>170.220001</td>\n",
              "      <td>170.220001</td>\n",
              "      <td>5797700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-17</th>\n",
              "      <td>170.399994</td>\n",
              "      <td>171.889999</td>\n",
              "      <td>170.309998</td>\n",
              "      <td>170.389999</td>\n",
              "      <td>170.389999</td>\n",
              "      <td>5722600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-18</th>\n",
              "      <td>169.979996</td>\n",
              "      <td>171.369995</td>\n",
              "      <td>169.529999</td>\n",
              "      <td>170.449997</td>\n",
              "      <td>170.449997</td>\n",
              "      <td>5844300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2516 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High  ...   Adj Close    Volume\n",
              "Date                                ...                      \n",
              "2011-05-19   66.529999   66.529999  ...   49.643864   9685100\n",
              "2011-05-20   66.250000   66.330002  ...   49.120430  12367000\n",
              "2011-05-23   65.190002   65.690002  ...   49.023212  12020200\n",
              "2011-05-24   65.739998   66.230003  ...   49.187725  11017700\n",
              "2011-05-25   66.290001   66.589996  ...   49.569096  14767100\n",
              "...                ...         ...  ...         ...       ...\n",
              "2021-05-12  168.539993  169.800003  ...  168.199997   6758300\n",
              "2021-05-13  166.970001  170.699997  ...  169.960007   8018600\n",
              "2021-05-14  171.479996  171.610001  ...  170.220001   5797700\n",
              "2021-05-17  170.399994  171.889999  ...  170.389999   5722600\n",
              "2021-05-18  169.979996  171.369995  ...  170.449997   5844300\n",
              "\n",
              "[2516 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV1VomVBcDaJ",
        "outputId": "864d0bc0-91c0-48af-ba55-cb60780d8316"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/JNJ.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06410951 0.06193325 0.06737392 ... 0.35201304 0.35845125 0.35944865]\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 3s 56ms/step - loss: 0.0208 - val_loss: 0.0017\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0041 - val_loss: 0.0108\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0015 - val_loss: 0.0022\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0012 - val_loss: 0.0034\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0013 - val_loss: 0.0046\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0013 - val_loss: 0.0033\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0012 - val_loss: 0.0028\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0011 - val_loss: 0.0030\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0012 - val_loss: 0.0044\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0012 - val_loss: 0.0041\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0011 - val_loss: 0.0040\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0013 - val_loss: 0.0050\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0012 - val_loss: 0.0046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YUOQ_cScDaK",
        "outputId": "d6c12997-ea78-45ea-b003-ed60c092b925"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/JNJ_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EGwJvbwcE6q"
      },
      "source": [
        "# HSI "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juzndgzSMUAS"
      },
      "source": [
        "## 0700 (Tencent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "Rt7XkLFRtk_7",
        "outputId": "193286a5-ff67-4bb6-d4f6-fc79fb51027a"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/0700.HK.csv', index_col=0, parse_dates=True)\n",
        "raw_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-07-05</th>\n",
              "      <td>42.919998</td>\n",
              "      <td>43.160000</td>\n",
              "      <td>42.680000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>41.858170</td>\n",
              "      <td>11164345.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-06</th>\n",
              "      <td>42.840000</td>\n",
              "      <td>43.520000</td>\n",
              "      <td>42.439999</td>\n",
              "      <td>42.919998</td>\n",
              "      <td>41.780296</td>\n",
              "      <td>15582130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-07</th>\n",
              "      <td>43.200001</td>\n",
              "      <td>43.599998</td>\n",
              "      <td>42.759998</td>\n",
              "      <td>42.959999</td>\n",
              "      <td>41.819229</td>\n",
              "      <td>13562530.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-08</th>\n",
              "      <td>43.599998</td>\n",
              "      <td>43.599998</td>\n",
              "      <td>42.119999</td>\n",
              "      <td>42.520000</td>\n",
              "      <td>41.390919</td>\n",
              "      <td>23646460.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-11</th>\n",
              "      <td>42.320000</td>\n",
              "      <td>42.400002</td>\n",
              "      <td>41.040001</td>\n",
              "      <td>41.400002</td>\n",
              "      <td>40.300659</td>\n",
              "      <td>22207165.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-25</th>\n",
              "      <td>588.500000</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>598.500000</td>\n",
              "      <td>598.500000</td>\n",
              "      <td>19252093.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-28</th>\n",
              "      <td>603.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>592.000000</td>\n",
              "      <td>595.500000</td>\n",
              "      <td>595.500000</td>\n",
              "      <td>11485959.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-29</th>\n",
              "      <td>600.000000</td>\n",
              "      <td>601.000000</td>\n",
              "      <td>588.000000</td>\n",
              "      <td>590.500000</td>\n",
              "      <td>590.500000</td>\n",
              "      <td>14714259.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-30</th>\n",
              "      <td>597.500000</td>\n",
              "      <td>597.500000</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>13618352.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-02</th>\n",
              "      <td>598.500000</td>\n",
              "      <td>598.500000</td>\n",
              "      <td>572.500000</td>\n",
              "      <td>574.500000</td>\n",
              "      <td>574.500000</td>\n",
              "      <td>24938624.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2467 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High  ...   Adj Close      Volume\n",
              "Date                                ...                        \n",
              "2011-07-05   42.919998   43.160000  ...   41.858170  11164345.0\n",
              "2011-07-06   42.840000   43.520000  ...   41.780296  15582130.0\n",
              "2011-07-07   43.200001   43.599998  ...   41.819229  13562530.0\n",
              "2011-07-08   43.599998   43.599998  ...   41.390919  23646460.0\n",
              "2011-07-11   42.320000   42.400002  ...   40.300659  22207165.0\n",
              "...                ...         ...  ...         ...         ...\n",
              "2021-06-25  588.500000  600.000000  ...  598.500000  19252093.0\n",
              "2021-06-28  603.000000  606.000000  ...  595.500000  11485959.0\n",
              "2021-06-29  600.000000  601.000000  ...  590.500000  14714259.0\n",
              "2021-06-30  597.500000  597.500000  ...  584.000000  13618352.0\n",
              "2021-07-02  598.500000  598.500000  ...  574.500000  24938624.0\n",
              "\n",
              "[2467 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbojOFqyMaOC",
        "outputId": "c53876af-ef35-4302-c116-3ad82b22d20b"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/0700.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.10891304e-03 8.02755134e-03 8.13603451e-03 8.19027609e-03\n",
            " 9.32931550e-03 9.89884063e-03 1.07938044e-02 1.14989274e-02\n",
            " 1.14175657e-02 1.00344398e-02 1.02242847e-02 1.15260489e-02\n",
            " 1.11463632e-02 1.06582066e-02 8.46147318e-03 9.03099830e-03\n",
            " 7.97330975e-03 8.97675672e-03 7.64787108e-03 7.24107071e-03\n",
            " 6.29186533e-03 3.09169176e-03 3.74257316e-03 2.90185095e-03\n",
            " 4.01377567e-03 5.47826459e-03 5.15282050e-03 1.03056166e-03\n",
            " 1.08483172e-04 4.82737641e-03 6.96986278e-03 6.34610692e-03\n",
            " 6.75290729e-03 7.62075097e-03 7.48515175e-03 7.43091016e-03\n",
            " 8.86827897e-03 6.02066418e-03 6.18338216e-03 4.82737641e-03\n",
            " 4.90873946e-03 7.40379005e-03 8.59707646e-03 8.65131263e-03\n",
            " 1.07938044e-02 1.13362094e-02 1.02785209e-02 8.75979580e-03\n",
            " 1.04954818e-02 9.27507934e-03 9.98020369e-03 7.91907359e-03\n",
            " 5.34266130e-03 5.77658179e-03 3.85105362e-03 3.39001438e-03\n",
            " 4.01377567e-03 3.28153121e-03 2.92897242e-03 2.35945001e-03\n",
            " 1.35600575e-03 2.27808695e-03 3.68833429e-03 2.49504787e-03\n",
            " 3.14593334e-03 1.57296667e-03 3.52558783e-04 4.33921840e-04\n",
            " 0.00000000e+00 2.98321130e-03 1.84416647e-03 2.11536762e-03\n",
            " 2.35945001e-03 2.73912891e-03 2.46793047e-03 9.76322785e-04\n",
            " 1.62719334e-04 1.00344426e-03 1.24752258e-03 1.35600575e-03\n",
            " 2.03400863e-03 2.33232854e-03 2.11536762e-03 2.98321130e-03\n",
            " 2.95608983e-03 3.74257316e-03            nan 3.33577279e-03\n",
            " 2.92897242e-03 2.95608983e-03            nan 3.74257316e-03\n",
            " 3.68833429e-03 3.30865268e-03 2.52216934e-03 2.71201150e-03\n",
            " 4.33921976e-03 5.96642259e-03 6.10202588e-03 6.75290729e-03\n",
            " 6.75290729e-03 8.73267568e-03 9.70900118e-03 9.30220081e-03\n",
            " 9.89884063e-03 1.02242847e-02 9.79035746e-03 1.06310851e-02\n",
            " 1.20684485e-02 1.04412456e-02 1.14446872e-02 1.10378855e-02\n",
            " 1.10107653e-02 1.04141242e-02 1.10650069e-02 1.20413270e-02\n",
            " 1.10650069e-02 1.14989274e-02 1.11192485e-02 1.31532571e-02\n",
            " 1.46991023e-02 1.43194167e-02 1.33702181e-02 1.31261357e-02\n",
            " 1.41024571e-02 1.48347016e-02 1.48347016e-02 1.41024571e-02\n",
            " 1.50787826e-02 1.54042267e-02 1.46719822e-02 1.48618217e-02\n",
            " 1.43194167e-02 1.37498970e-02 1.34786958e-02 1.41566987e-02\n",
            " 1.45363776e-02 1.48075801e-02 1.49703049e-02 1.50245410e-02\n",
            " 1.72483891e-02 1.94722439e-02 1.94180024e-02 1.94180024e-02\n",
            " 2.12079286e-02 2.08282497e-02 2.02316031e-02 2.07740081e-02\n",
            " 2.03943279e-02 1.92010414e-02 1.93637608e-02 1.93637608e-02\n",
            " 2.10452093e-02 2.10452093e-02 2.05570472e-02 2.01231253e-02\n",
            " 2.09909677e-02 2.19672945e-02 2.28351369e-02 2.27266537e-02\n",
            " 2.48420254e-02 2.49505031e-02 2.40826594e-02 2.47877838e-02\n",
            " 2.53844236e-02 2.23469734e-02 2.39199401e-02 2.40826594e-02\n",
            " 2.67404293e-02 2.66861932e-02 2.75540369e-02 2.64149907e-02\n",
            " 2.32148171e-02 2.33233003e-02 2.15876088e-02 2.11536870e-02\n",
            " 2.12621702e-02 2.16960920e-02 2.29978562e-02 2.01773615e-02\n",
            " 2.16418504e-02 2.13706479e-02 1.93095192e-02 1.77365525e-02\n",
            " 1.75738332e-02 1.87671196e-02 1.94722439e-02 1.85501587e-02\n",
            " 1.91467999e-02 1.90383221e-02 1.84959171e-02 1.86586364e-02\n",
            " 1.71941529e-02 1.71399113e-02 1.92552830e-02 2.01231253e-02\n",
            " 2.04485640e-02 2.33775364e-02 2.18588114e-02 2.21842554e-02\n",
            " 2.16418504e-02 2.30520978e-02 2.44081035e-02 2.52759458e-02\n",
            " 2.55471484e-02 2.26724121e-02 2.10452093e-02 2.06655249e-02\n",
            " 1.99061644e-02 2.18045698e-02 2.00688838e-02 2.19130529e-02\n",
            " 2.35402612e-02 2.40284178e-02 2.47335422e-02 2.45165813e-02\n",
            " 2.27266537e-02 2.31063394e-02 2.22384916e-02 2.03943279e-02\n",
            " 2.12621702e-02 2.16960920e-02 2.25639343e-02 2.08282497e-02\n",
            " 2.23469734e-02 2.35402612e-02 2.22927332e-02 2.21300139e-02\n",
            " 2.15876088e-02 2.10452093e-02 2.27266537e-02 2.31063394e-02\n",
            " 2.34860196e-02 2.30520978e-02 2.29978562e-02 2.31063394e-02\n",
            " 2.39741817e-02 2.42996204e-02 2.45165813e-02 2.56013845e-02\n",
            " 2.37572208e-02 2.25639343e-02 2.31063394e-02 2.29978562e-02\n",
            " 2.69573903e-02 2.79337158e-02 2.84218792e-02 2.79879574e-02\n",
            " 2.71743566e-02 2.78794742e-02 2.70658734e-02 2.70658734e-02\n",
            " 2.64149907e-02 2.64149907e-02 2.51674627e-02 2.48962669e-02\n",
            " 2.59810702e-02 2.50589849e-02 2.41369010e-02 2.54929068e-02\n",
            " 2.65777100e-02 2.71743566e-02 2.76625146e-02 2.85303624e-02\n",
            " 2.80964351e-02 2.99406043e-02 2.98321265e-02 2.97778849e-02\n",
            " 2.99406043e-02 2.89100426e-02 2.95066824e-02 2.98321265e-02\n",
            " 3.01033290e-02 3.00490874e-02 3.17305319e-02 3.22729355e-02\n",
            " 3.21644524e-02 3.23814133e-02 3.22186939e-02 3.12966100e-02\n",
            " 3.10254075e-02 3.10796491e-02 3.04287677e-02 3.08084466e-02\n",
            " 3.07542104e-02 3.11338907e-02 3.18390137e-02 3.11338907e-02\n",
            " 3.16220541e-02 3.26526158e-02 3.39543854e-02 3.43340656e-02\n",
            " 3.29780599e-02 3.38459022e-02 3.42798240e-02 3.49307054e-02\n",
            " 3.54188689e-02 3.60697503e-02 3.53646273e-02 3.54188689e-02\n",
            " 3.53646273e-02 3.40086215e-02 3.30323015e-02 3.42255825e-02\n",
            " 3.39001438e-02 3.32492610e-02 2.82049183e-02 2.79337158e-02\n",
            " 2.73370759e-02 2.88558010e-02 3.05914857e-02 3.10254075e-02\n",
            " 3.01575652e-02 2.90727620e-02 2.88558010e-02 2.93982047e-02\n",
            " 2.98863681e-02 2.92897215e-02 2.71743566e-02 2.70116319e-02\n",
            " 2.84761208e-02 2.91812438e-02 2.86930817e-02 2.93439631e-02\n",
            " 2.91270022e-02 2.92354799e-02 2.91812438e-02 2.88558010e-02\n",
            " 2.82591599e-02 2.84761208e-02 2.82591599e-02 2.81506767e-02\n",
            " 2.78252380e-02            nan 2.77709964e-02 2.84218792e-02\n",
            "            nan 3.04287677e-02 3.10254075e-02 3.09169298e-02\n",
            " 2.99406043e-02 2.99406043e-02 2.92897215e-02 2.93439631e-02\n",
            " 2.98321265e-02 2.97236434e-02 3.06457273e-02 3.30865376e-02\n",
            " 3.31407792e-02 3.39543854e-02 3.34119804e-02 3.35746997e-02\n",
            " 3.35746997e-02 3.40628631e-02 3.30865376e-02 3.32492610e-02\n",
            " 3.30865376e-02 3.40628631e-02 3.42255825e-02 3.34662219e-02\n",
            " 3.35204581e-02 3.25983796e-02 3.30323015e-02 3.43883072e-02\n",
            " 3.40086215e-02 3.43340656e-02 3.50391886e-02 3.52019079e-02\n",
            " 3.52019079e-02 3.56358298e-02 3.43340656e-02 3.23271771e-02\n",
            " 3.24356549e-02 3.30323015e-02 3.22729355e-02 3.33577388e-02\n",
            " 3.34662219e-02 3.49849470e-02 3.53103911e-02 3.62324696e-02\n",
            " 3.64494305e-02 3.77512001e-02 3.69918355e-02 3.61239919e-02\n",
            " 3.60697503e-02 3.54188689e-02 3.49849470e-02 3.20017330e-02\n",
            " 3.09169298e-02 3.18932553e-02 2.90727620e-02 2.71743566e-02\n",
            " 2.59268286e-02 2.79879574e-02 2.85845985e-02 2.75540369e-02\n",
            " 2.64692323e-02 2.64692323e-02 2.49505031e-02 2.60353118e-02\n",
            " 2.77709964e-02 2.82591599e-02 2.85303624e-02 2.84218792e-02\n",
            " 2.73370759e-02 2.69573903e-02 2.84218792e-02 2.76625146e-02\n",
            " 2.92354799e-02 2.97778849e-02 2.88558010e-02 2.96151656e-02\n",
            " 2.99406043e-02 3.08626882e-02 3.16762957e-02 3.28153405e-02\n",
            " 3.47679861e-02 3.41171047e-02 3.51476664e-02 3.52561495e-02\n",
            " 3.50934248e-02 3.48764639e-02 3.56900714e-02 3.35204581e-02\n",
            " 3.37916606e-02 3.50391886e-02 3.98665664e-02 4.45312289e-02\n",
            " 4.30667399e-02 4.27955374e-02 4.00292898e-02 4.18192174e-02\n",
            " 4.20904199e-02 4.31209815e-02 4.29582622e-02 4.40973070e-02\n",
            " 4.40973070e-02 4.28497790e-02 4.29040206e-02 4.20904199e-02\n",
            " 4.20361783e-02 4.19276951e-02 4.33921840e-02 4.32837009e-02\n",
            " 4.13852955e-02 4.21988976e-02 4.22531392e-02 4.21446560e-02\n",
            " 4.18734535e-02 3.93241668e-02 3.81308804e-02 3.61782334e-02\n",
            " 3.74799976e-02 3.93784084e-02 4.13852955e-02 4.31209815e-02\n",
            " 4.24701001e-02 4.16564926e-02 4.37176227e-02 4.42600264e-02\n",
            " 4.26328195e-02 4.23616170e-02 4.31752231e-02 4.49109091e-02\n",
            " 4.46397066e-02 4.77856400e-02 5.00637296e-02 5.01179712e-02\n",
            " 4.95213260e-02 5.11485383e-02 4.94670844e-02 5.08230901e-02\n",
            " 5.03349376e-02 5.13112522e-02 5.48368753e-02 5.54335110e-02\n",
            " 5.92303312e-02 5.60301576e-02 5.84167305e-02 5.83082473e-02\n",
            " 6.12372143e-02 6.24847477e-02 5.83082473e-02 5.72776802e-02\n",
            " 5.75488868e-02 6.02608983e-02 6.09660172e-02 6.09660172e-02\n",
            " 6.04236122e-02 6.00439333e-02 6.10202588e-02 5.93388144e-02\n",
            " 5.82540057e-02 5.82540057e-02 5.71149663e-02 5.73861634e-02\n",
            " 5.87964107e-02 5.72234386e-02 5.87421691e-02 5.92303312e-02\n",
            " 6.27017032e-02 6.36237871e-02 6.34068316e-02 6.57391534e-02\n",
            " 6.55764395e-02 6.64985234e-02 6.88308546e-02 6.96986970e-02\n",
            " 7.25734237e-02 7.20310296e-02 7.48515134e-02 7.42006361e-02\n",
            " 6.97529386e-02 7.18683048e-02 7.15970969e-02 6.98071707e-02\n",
            " 7.17055801e-02 7.15428662e-02 7.39294295e-02 7.09462209e-02\n",
            " 7.31700690e-02 7.44718331e-02 7.43091084e-02 7.37667142e-02\n",
            " 7.61532776e-02 7.28446303e-02 7.17598216e-02 7.42548777e-02\n",
            " 7.50142382e-02 7.49057550e-02 7.45803163e-02 7.71838447e-02\n",
            " 8.20654640e-02 7.97331314e-02 7.72923278e-02 7.69126476e-02\n",
            " 7.62075192e-02 7.80516870e-02 7.40921529e-02 7.68584060e-02\n",
            " 7.53939171e-02 7.52311937e-02 7.36582324e-02 7.23022267e-02\n",
            " 7.23564682e-02 7.11089443e-02 6.94817320e-02 7.21395019e-02\n",
            " 7.15428662e-02 6.70951592e-02 7.20310296e-02 7.44175916e-02\n",
            " 7.61532776e-02 7.42548777e-02 7.42548777e-02 7.50142382e-02\n",
            " 7.57735973e-02 7.94076927e-02 7.91364970e-02 8.03297780e-02\n",
            " 8.04925028e-02 8.22281874e-02 8.38011487e-02 8.20654640e-02\n",
            " 8.09264232e-02 8.26078677e-02 8.53741207e-02 8.60250076e-02\n",
            " 8.70555652e-02 8.93336548e-02 8.73810133e-02 8.70555652e-02\n",
            " 8.88997330e-02 8.69470928e-02 8.73267717e-02 8.64046878e-02\n",
            " 8.63504462e-02 8.73267717e-02 8.78691659e-02 9.16659861e-02\n",
            " 9.50831273e-02 9.47576778e-02 9.74425746e-02 9.45949639e-02\n",
            " 9.50288858e-02 9.45949639e-02 9.66289725e-02 9.43237560e-02\n",
            " 9.55170478e-02 9.53000828e-02 9.43237560e-02 9.85273725e-02\n",
            " 9.96121811e-02 1.04087004e-01 1.01781788e-01 1.01646190e-01\n",
            " 1.03544601e-01 1.02188595e-01 9.64933638e-02 9.33474305e-02\n",
            " 9.70357675e-02 1.04900606e-01 1.08019413e-01 9.90697761e-02\n",
            " 9.90697761e-02 9.85273725e-02 1.02866598e-01 1.05307401e-01\n",
            " 1.04358201e-01 1.06527808e-01 1.07070213e-01 1.09375418e-01\n",
            " 1.17918259e-01 1.19138667e-01 1.18596262e-01 1.13714644e-01\n",
            " 1.18053857e-01 1.17375854e-01 1.16697851e-01 1.19545462e-01\n",
            " 1.27817105e-01 1.29444308e-01 1.23884687e-01 1.26732296e-01\n",
            " 1.29444308e-01 1.32834322e-01 1.31613914e-01 1.27817105e-01\n",
            " 1.28088302e-01 1.23884687e-01 1.20087865e-01 1.13579044e-01\n",
            " 1.08833024e-01 1.17375854e-01 1.14528244e-01 1.11951831e-01\n",
            " 1.15884250e-01 1.19816670e-01 1.12087430e-01 1.10867033e-01\n",
            " 1.02052996e-01 1.05714207e-01 1.06934615e-01 1.13443436e-01\n",
            " 1.12901042e-01 1.08833024e-01 1.03002196e-01 9.66289725e-02\n",
            " 9.87985804e-02 1.02595390e-01 1.13307837e-01 1.03002196e-01\n",
            " 1.03273393e-01 1.00561381e-01 1.02052996e-01 1.03137793e-01\n",
            " 1.02866598e-01 1.04087004e-01 1.05036204e-01 1.02595390e-01\n",
            " 9.85273725e-02 9.87985804e-02 9.16659861e-02 9.49746442e-02\n",
            " 9.42152742e-02 8.91166993e-02 8.90624577e-02 9.04727051e-02\n",
            " 9.73069754e-02 9.82561754e-02 1.00018987e-01 1.08155021e-01\n",
            " 1.08155021e-01 1.06527808e-01 1.12358638e-01 1.12087430e-01\n",
            " 1.12901042e-01 1.11273828e-01 1.11680635e-01 1.11680635e-01\n",
            " 1.14257047e-01 1.09511027e-01 1.08833024e-01 1.12494236e-01\n",
            " 1.08697416e-01 1.07612618e-01 1.07341410e-01 1.10595825e-01\n",
            " 1.14528244e-01 1.18460664e-01 1.17375854e-01 1.18053857e-01\n",
            " 1.18731860e-01 1.17375854e-01 1.18189456e-01 1.17647062e-01\n",
            " 1.17647062e-01 1.15477444e-01 1.16426655e-01 1.16697851e-01\n",
            " 1.21172675e-01 1.21172675e-01 1.20901467e-01 1.27139102e-01\n",
            " 1.29715505e-01 1.30257908e-01 1.30664716e-01 1.30529116e-01\n",
            " 1.24969485e-01 1.26325490e-01 1.25511888e-01 1.27139102e-01\n",
            " 1.28495108e-01 1.29173111e-01 1.28088302e-01 1.27274701e-01\n",
            " 1.25376290e-01 1.28901903e-01 1.29173111e-01 1.29444308e-01\n",
            " 1.29986713e-01 1.35410725e-01 1.37444733e-01 1.34868331e-01\n",
            " 1.34732722e-01 1.34461525e-01 1.35817531e-01 1.41648359e-01\n",
            " 1.40834748e-01 1.34597134e-01 1.36631142e-01 1.40021157e-01\n",
            " 1.41377162e-01 1.41241554e-01 1.37037948e-01 1.37309145e-01\n",
            " 1.35275136e-01 1.36631142e-01 1.39478742e-01 1.37851539e-01\n",
            " 1.37851539e-01 1.36631142e-01 1.36088728e-01 1.34732722e-01\n",
            " 1.33919131e-01 1.32156319e-01 1.32291917e-01 1.31071510e-01\n",
            " 1.35953139e-01 1.36088728e-01 1.34597134e-01 1.31613914e-01\n",
            " 1.26054293e-01 1.26325490e-01 1.27274701e-01 1.27952704e-01\n",
            " 1.24698288e-01 1.28766305e-01 1.27274701e-01 1.30393508e-01\n",
            " 1.24833885e-01 1.21850678e-01 1.21308273e-01 1.20494672e-01\n",
            " 1.18596262e-01 1.17375854e-01 1.17240256e-01 1.17918259e-01\n",
            " 1.22935476e-01 1.22799877e-01 1.21308273e-01 1.20494672e-01\n",
            " 1.17511453e-01 1.15748652e-01 1.14392647e-01 1.15748652e-01\n",
            " 1.13850242e-01 1.13443436e-01 1.15613053e-01 1.17104658e-01\n",
            " 1.22393082e-01 1.22799877e-01 1.22664279e-01 1.20765868e-01\n",
            " 1.23477880e-01 1.25647487e-01 1.25918695e-01 1.28223900e-01\n",
            " 1.28495108e-01 1.27003493e-01 1.28766305e-01 1.28223900e-01\n",
            " 1.27545897e-01 1.31071510e-01 1.33647923e-01 1.35817531e-01\n",
            " 1.36224336e-01 1.39478742e-01 1.35681942e-01 1.31207119e-01\n",
            " 1.29308710e-01 1.31071510e-01 1.29037502e-01 1.30800313e-01\n",
            " 1.29715505e-01 1.31071510e-01 1.30257908e-01 1.28766305e-01\n",
            " 1.23749088e-01 1.22799877e-01 1.20223464e-01 1.20901467e-01\n",
            " 1.21850678e-01 1.21443871e-01 1.17647062e-01 1.17240256e-01\n",
            " 1.14392647e-01 1.14799441e-01 1.12358638e-01 1.07070213e-01\n",
            " 1.03409001e-01 1.12358638e-01 1.17511453e-01 1.13850242e-01\n",
            " 1.13579044e-01 1.13443436e-01 1.14392647e-01 1.14257047e-01\n",
            " 1.13172239e-01 1.13579044e-01 1.14528244e-01 1.23342282e-01\n",
            " 1.29308710e-01 1.33241128e-01 1.33105519e-01 1.32969920e-01\n",
            " 1.33919131e-01 1.31478316e-01 1.32698724e-01 1.25918695e-01\n",
            " 1.27410299e-01 1.28901903e-01 1.35139528e-01 1.39071957e-01\n",
            " 1.40563551e-01 1.46394380e-01 1.45038374e-01 1.46258771e-01\n",
            " 1.43139974e-01 1.39614351e-01 1.44767177e-01 1.43817977e-01\n",
            " 1.42190754e-01 1.43953565e-01 1.42597559e-01 1.40427962e-01\n",
            " 1.40970357e-01 1.39071957e-01 1.36359945e-01 1.37173536e-01\n",
            " 1.37580342e-01 1.37987148e-01 1.36766731e-01 1.43411171e-01\n",
            " 1.43817977e-01 1.44767177e-01 1.44495980e-01 1.44902765e-01\n",
            " 1.45987574e-01 1.44089174e-01 1.41377162e-01 1.39749960e-01\n",
            " 1.39207545e-01 1.39885548e-01 1.38393954e-01 1.39207545e-01\n",
            " 1.39343154e-01 1.41783968e-01 1.44495980e-01 1.42055165e-01\n",
            " 1.44902765e-01 1.57242426e-01 1.53988020e-01 1.57513623e-01\n",
            " 1.54530414e-01 1.54123608e-01 1.51547205e-01 1.53038800e-01\n",
            " 1.56835620e-01 1.60225634e-01 1.61310443e-01 1.63751257e-01\n",
            " 1.70124480e-01 1.77446903e-01 1.80023326e-01 1.92498575e-01\n",
            " 1.79209715e-01 1.74328106e-01 1.77582512e-01 1.75955309e-01\n",
            " 1.68226080e-01 1.76362115e-01 1.81243723e-01 1.78802909e-01\n",
            " 1.79752129e-01 1.81108135e-01 1.82464141e-01 1.83277732e-01\n",
            " 1.78802909e-01 1.74870500e-01 1.74328106e-01 1.72158489e-01\n",
            " 1.68090472e-01 1.69446477e-01 1.75684112e-01 1.73514495e-01\n",
            " 1.73243297e-01 1.79345323e-01 1.80701329e-01 1.79074126e-01\n",
            " 1.79480912e-01 1.75684112e-01 1.73243297e-01 1.75955309e-01\n",
            " 1.75955309e-01 1.74734892e-01 1.71073680e-01 1.71751683e-01\n",
            " 1.72294098e-01 1.73785692e-01 1.75006109e-01 1.74599303e-01\n",
            " 1.70395677e-01 1.70938092e-01 1.70802483e-01 1.68361669e-01\n",
            " 1.69853283e-01 1.73785692e-01 1.71073680e-01 1.69582086e-01\n",
            " 1.69853283e-01 1.69853283e-01 1.69717674e-01 1.73514495e-01\n",
            " 1.75006109e-01 1.82599729e-01 1.80294523e-01 1.77446903e-01\n",
            " 1.68226080e-01 1.70395677e-01 1.72836492e-01 1.70938092e-01\n",
            " 1.59276434e-01 1.56835620e-01 1.43411171e-01 1.58598431e-01\n",
            " 1.62530840e-01 1.64700457e-01 1.66327660e-01 1.64022454e-01\n",
            " 1.64022454e-01 1.68904083e-01 1.71480486e-01 1.72972100e-01\n",
            " 1.70124480e-01 1.70124480e-01 1.66056463e-01 1.58056037e-01\n",
            " 1.59276434e-01 1.56428814e-01 1.54259217e-01 1.56835620e-01\n",
            " 1.55886420e-01 1.54530414e-01 1.53716802e-01 1.51682794e-01\n",
            " 1.53310017e-01 1.54259217e-01 1.51547205e-01 1.43546759e-01\n",
            " 1.56022029e-01 1.55072808e-01 1.53174408e-01 1.49648785e-01\n",
            " 1.49920003e-01 1.45309571e-01 1.38800739e-01 1.30122311e-01\n",
            " 1.38122736e-01 1.35003939e-01 1.39885548e-01 1.37851539e-01\n",
            " 1.39343154e-01 1.33105519e-01 1.33376727e-01 1.33376727e-01\n",
            " 1.32020721e-01 1.36088728e-01 1.41783968e-01 1.35003939e-01]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 60ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 1s 44ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: nan - val_loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9co3pqJMhVP",
        "outputId": "97b02f72-3868-4c60-a396-0950730a8a5c"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/0700_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNjNrCB0Mju0"
      },
      "source": [
        "## 1398 (ICBC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-04Wj14Mju0",
        "outputId": "92bb3cae-70f9-48d9-cb1e-4dc342fcab06"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/1398.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 70ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PINFoEcwMju0",
        "outputId": "807ff827-4cfc-4a59-b24f-d333ba1dd718"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/1398_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-MQxEBfMju0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS3w74fmMjzA"
      },
      "source": [
        "## 4333 (CISCO-T)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qZgksLzMjzA",
        "outputId": "be499323-513b-403c-e580-b1a759690c03"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/4333.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 73ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1WyDKoKMjzA",
        "outputId": "f9eca898-8e1a-4cfb-9c62-6104be2a9c7c"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/4333_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0jHY33xMjzA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD13sk6nMj3S"
      },
      "source": [
        "## 3968 (CM Bank)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1jQ4PipMj3T",
        "outputId": "5d3bda1c-04e1-492a-db4a-2b92d4bac9eb"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/3968.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 71ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jpNvbPUMj3T",
        "outputId": "c36a23d3-9471-4565-e49b-cda0ffe480a9"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/3968_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIEeUp31Mj3T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-3IDlzvMj8D"
      },
      "source": [
        "## 939 (CCB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN-hh7_wMj8E",
        "outputId": "5e9574bc-dbf3-4fcb-dbd1-56ca63567631"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/0939.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_24 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_23 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 72ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pChnQ0wWMj8E",
        "outputId": "a9fe8ad4-6597-4243-814a-35d0fe13ba9b"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/0939_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_3y3yEvMj8E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcN2EOpFNVM1"
      },
      "source": [
        "## 2318 (Ping An)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZyXT5jtNVNH",
        "outputId": "4fcdcbe7-5501-4979-bec6-7087d12dfa9f"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/2318.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_25 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_24 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 71ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmKw_8KCNVNH",
        "outputId": "9c90ca99-7b53-4fe9-891c-d307dce79f63"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/2318_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjG6sSyPMiDL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er9baQYWNWDw"
      },
      "source": [
        "## 1288 (ABC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5d3wuWvNWDw",
        "outputId": "86be0318-99ac-4a57-9a0a-0d565268c26e"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/1288.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_25 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 69ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br-65Ln4NWDx",
        "outputId": "2e599faf-6efd-4601-f20d-244fa58d18f3"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/1288_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIKWGLyONWDx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERLnINGQNWSg"
      },
      "source": [
        "## 1299 (AIA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "jgkmKr-LqZb7",
        "outputId": "c5bb6384-02d6-4144-b557-5d79bc6d8cb8"
      },
      "source": [
        "raw_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-07-05</th>\n",
              "      <td>27.500000</td>\n",
              "      <td>27.799999</td>\n",
              "      <td>27.299999</td>\n",
              "      <td>27.600000</td>\n",
              "      <td>24.136076</td>\n",
              "      <td>21992190.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-06</th>\n",
              "      <td>27.750000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>27.200001</td>\n",
              "      <td>27.299999</td>\n",
              "      <td>23.873728</td>\n",
              "      <td>32105343.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-07</th>\n",
              "      <td>27.200001</td>\n",
              "      <td>27.950001</td>\n",
              "      <td>27.200001</td>\n",
              "      <td>27.750000</td>\n",
              "      <td>24.267256</td>\n",
              "      <td>35830557.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-08</th>\n",
              "      <td>27.900000</td>\n",
              "      <td>28.150000</td>\n",
              "      <td>27.799999</td>\n",
              "      <td>27.950001</td>\n",
              "      <td>24.442152</td>\n",
              "      <td>23433261.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-11</th>\n",
              "      <td>27.850000</td>\n",
              "      <td>27.900000</td>\n",
              "      <td>27.400000</td>\n",
              "      <td>27.450001</td>\n",
              "      <td>24.004904</td>\n",
              "      <td>11763659.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-25</th>\n",
              "      <td>98.500000</td>\n",
              "      <td>98.500000</td>\n",
              "      <td>96.949997</td>\n",
              "      <td>97.150002</td>\n",
              "      <td>97.150002</td>\n",
              "      <td>14431558.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-28</th>\n",
              "      <td>97.599998</td>\n",
              "      <td>97.800003</td>\n",
              "      <td>95.199997</td>\n",
              "      <td>95.800003</td>\n",
              "      <td>95.800003</td>\n",
              "      <td>15169745.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-29</th>\n",
              "      <td>96.550003</td>\n",
              "      <td>96.550003</td>\n",
              "      <td>95.500000</td>\n",
              "      <td>95.699997</td>\n",
              "      <td>95.699997</td>\n",
              "      <td>14331011.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-30</th>\n",
              "      <td>97.550003</td>\n",
              "      <td>97.800003</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>22907334.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-02</th>\n",
              "      <td>97.199997</td>\n",
              "      <td>97.300003</td>\n",
              "      <td>95.050003</td>\n",
              "      <td>95.800003</td>\n",
              "      <td>95.800003</td>\n",
              "      <td>23921232.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2467 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Open       High        Low      Close  Adj Close      Volume\n",
              "Date                                                                         \n",
              "2011-07-05  27.500000  27.799999  27.299999  27.600000  24.136076  21992190.0\n",
              "2011-07-06  27.750000  28.000000  27.200001  27.299999  23.873728  32105343.0\n",
              "2011-07-07  27.200001  27.950001  27.200001  27.750000  24.267256  35830557.0\n",
              "2011-07-08  27.900000  28.150000  27.799999  27.950001  24.442152  23433261.0\n",
              "2011-07-11  27.850000  27.900000  27.400000  27.450001  24.004904  11763659.0\n",
              "...               ...        ...        ...        ...        ...         ...\n",
              "2021-06-25  98.500000  98.500000  96.949997  97.150002  97.150002  14431558.0\n",
              "2021-06-28  97.599998  97.800003  95.199997  95.800003  95.800003  15169745.0\n",
              "2021-06-29  96.550003  96.550003  95.500000  95.699997  95.699997  14331011.0\n",
              "2021-06-30  97.550003  97.800003  96.500000  96.500000  96.500000  22907334.0\n",
              "2021-07-02  97.199997  97.300003  95.050003  95.800003  95.800003  23921232.0\n",
              "\n",
              "[2467 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uP23p0aNWSg",
        "outputId": "0e6c2cc3-4caf-476e-ca44-3d358be61c6c"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/1299.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0647482  0.06306203 0.06643434 0.06137589 0.06531024 0.07992354\n",
            " 0.08329585 0.0804856  0.07317896 0.06868253 0.0703687  0.0782374\n",
            " 0.07542715 0.06868253 0.05350719 0.04114207 0.05294513 0.05406923\n",
            " 0.04901077 0.05069694 0.04226619 0.01866006 0.02821493 0.02652875\n",
            " 0.03102518 0.02484261 0.02652875 0.01866006 0.         0.02203236\n",
            " 0.03383543 0.03046312 0.03889387 0.04844873 0.05013488 0.04451438\n",
            " 0.04058001 0.03046312 0.03608362 0.03664568 0.03439747 0.04339026\n",
            " 0.04058001 0.04226619 0.04451438 0.04676258 0.04676258 0.04788669\n",
            " 0.04563848 0.04001797 0.04901077 0.05069694 0.05463127 0.05519333\n",
            " 0.04451438 0.04507644 0.05182102 0.04620052 0.04170412 0.04282823\n",
            " 0.04170412 0.03495951 0.03833182 0.03608362 0.04282823 0.04170412\n",
            " 0.03945593 0.04226619 0.04058001 0.04620052 0.04395233 0.04620052\n",
            " 0.04395233 0.04844873 0.04563848 0.04001797 0.04282823 0.03889387\n",
            " 0.04058001 0.03158722 0.03271132 0.03158722 0.03889387 0.04451438\n",
            " 0.04451438 0.04732463        nan 0.04732463 0.04676258 0.04844873\n",
            "        nan 0.05238308 0.05125898 0.05182102 0.04732463 0.04451438\n",
            " 0.04563848 0.04507644 0.04676258 0.04451438 0.04563848 0.05013488\n",
            " 0.05463127 0.06418614 0.06643434 0.07205484 0.07261689 0.06587228\n",
            " 0.06699639 0.07093074 0.07093074 0.06980664 0.06587228 0.06531024\n",
            " 0.06924459 0.07093074 0.07093074 0.07655125 0.07598921 0.07767535\n",
            " 0.07317896 0.07542715 0.07767535 0.0804856  0.08779225 0.0838579\n",
            " 0.0939748  0.1052158  0.10802606 0.10633992 0.10352966 0.10409173\n",
            " 0.10409173 0.07655125 0.084982   0.0838579  0.08329585 0.08441996\n",
            " 0.08666815 0.09004047 0.09509891 0.09509891 0.08723021 0.08554404\n",
            " 0.08779225 0.08835429 0.0861061  0.09228866 0.09172661 0.09172661\n",
            " 0.09566097 0.09228866 0.09116454 0.09228866 0.09060251 0.084982\n",
            " 0.08273379 0.08273379 0.07879946 0.08273379 0.08666815 0.09060251\n",
            " 0.09060251 0.084982   0.08273379 0.08273379 0.08104765 0.0793615\n",
            " 0.0861061  0.09285072 0.09341276 0.09285072 0.08104765 0.0804856\n",
            " 0.08104765 0.07879946 0.073741   0.073741   0.07711329 0.07261689\n",
            " 0.06924459 0.06643434 0.06812049 0.06587228 0.06137589 0.05575538\n",
            " 0.05350719 0.05294513 0.05856564 0.05856564 0.06025178 0.05968974\n",
            " 0.05294513 0.0591277  0.06025178 0.06362409 0.06306203 0.06868253\n",
            " 0.06755845 0.06755845 0.06643434 0.06812049 0.07149278 0.07149278\n",
            " 0.0703687  0.06755845 0.06643434 0.06249999 0.06531024 0.06699639\n",
            " 0.06306203 0.073741   0.08329585 0.08104765 0.08104765 0.08891635\n",
            " 0.07992354 0.08329585 0.0861061  0.07992354 0.08160971 0.07992354\n",
            " 0.0861061  0.08666815 0.08723021 0.08947841 0.07598921 0.07655125\n",
            " 0.07542715 0.07711329 0.07655125 0.08441996 0.08217175 0.0804856\n",
            " 0.0793615  0.07655125 0.07879946 0.07767535 0.07711329 0.07767535\n",
            " 0.07655125 0.07879946 0.08160971 0.08104765 0.08104765 0.08160971\n",
            " 0.08329585 0.0804856  0.07711329 0.07767535 0.07655125 0.0782374\n",
            " 0.07767535 0.0782374  0.07430303 0.07542715 0.07149278 0.06924459\n",
            " 0.06980664 0.07149278 0.09172661 0.09228866 0.084982   0.09228866\n",
            " 0.09172661 0.10296761 0.10015736 0.10071941 0.09847122 0.0939748\n",
            " 0.09566097 0.09734711 0.09566097 0.09341276 0.10015736 0.10071941\n",
            " 0.10802606 0.10690198 0.11252248 0.10971223 0.11196042 0.10858812\n",
            " 0.10858812 0.10465376 0.10690198 0.10746402 0.11083631 0.11308452\n",
            " 0.11196042 0.11533273 0.12657374 0.12544963 0.12320143 0.11645681\n",
            " 0.11926706 0.12095324 0.12657374 0.13331832 0.12657374 0.12601168\n",
            " 0.12544963 0.12095324 0.11533273 0.11870502 0.11533273 0.11701887\n",
            " 0.11420862 0.11420862 0.11364656 0.11027427 0.11589477 0.11814298\n",
            " 0.11701887 0.11364656 0.11758092 0.11589477 0.11870502 0.11477067\n",
            " 0.11027427 0.10858812 0.11533273 0.11420862 0.11308452 0.11196042\n",
            " 0.12151528 0.12207731 0.12095324 0.13163218 0.13163218 0.11982912\n",
            " 0.11758092 0.11814298 0.11645681        nan 0.11589477 0.11645681\n",
            "        nan 0.12544963 0.12432553 0.12320143 0.11926706 0.11758092\n",
            " 0.11758092 0.11533273 0.11252248 0.11589477 0.11814298 0.11533273\n",
            " 0.11252248 0.10971223 0.10802606 0.11308452 0.11926706 0.12151528\n",
            " 0.12263938 0.12095324 0.11982912 0.12320143 0.12263938 0.12095324\n",
            " 0.11814298 0.11364656 0.12263938 0.12601168 0.13163218 0.12657374\n",
            " 0.12488757 0.12882193 0.13107013 0.13837679 0.13669061 0.13500449\n",
            " 0.13893882 0.13050807 0.14512137 0.15355212 0.15355212 0.15186601\n",
            " 0.15242804 0.14905575 0.15299008 0.15580034 0.16198288 0.16029676\n",
            " 0.15692447 0.15804855 0.16366905 0.15074187 0.15130397 0.15130397\n",
            " 0.15467626 0.15411422 0.15636237 0.15467626 0.15917263 0.15804855\n",
            " 0.15973472 0.16254497 0.1462455  0.14343525 0.14399729 0.14287321\n",
            " 0.14905575 0.14905575 0.14343525 0.13837679 0.14006296 0.13950086\n",
            " 0.15017983 0.14849371 0.14849371 0.14961779 0.15580034 0.1608588\n",
            " 0.15973472 0.16310701 0.16142084 0.16029676 0.16535523 0.17378598\n",
            " 0.17603414 0.17659623 0.18053056 0.17378598 0.16985159 0.17266185\n",
            " 0.17041363 0.18558903 0.18165464 0.17940648 0.16591726 0.16872752\n",
            " 0.16872752 0.17209981 0.16535523 0.16310701 0.16423109 0.16198288\n",
            " 0.16198288 0.14905575 0.14568346 0.14343525 0.14793162 0.14905575\n",
            " 0.14455933 0.14736958 0.14905575 0.14793162 0.14455933 0.13669061\n",
            " 0.14118704 0.13163218 0.13388038 0.13950086 0.14287321 0.14512137\n",
            " 0.14793162 0.13669061 0.14118704 0.14961779 0.14287321 0.15017983\n",
            " 0.15861059 0.16928956 0.16479313 0.15917263 0.16310701 0.16254497\n",
            " 0.16029676 0.16423109 0.1754721  0.17659623 0.18390285 0.17715827\n",
            " 0.17884439 0.17996852 0.18615107 0.18896132 0.19120953 0.19345774\n",
            " 0.18558903 0.17772031 0.17153777 0.16985159 0.17715827 0.18277877\n",
            " 0.18221674 0.18221674 0.17940648 0.18334081 0.1754721  0.16366905\n",
            " 0.16366905 0.16198288 0.16366905 0.16254497 0.15467626 0.15074187\n",
            " 0.15580034 0.15861059 0.16423109 0.16816548 0.16872752 0.17434802\n",
            " 0.16985159 0.16928956 0.16985159 0.17209981 0.16872752 0.17097573\n",
            " 0.1810926  0.17715827 0.18502699 0.19289565 0.19120953 0.1900854\n",
            " 0.19289565 0.19233361 0.19401978 0.18558903 0.19345774 0.19345774\n",
            " 0.19289565 0.18727514 0.19177157 0.19514386 0.1957059  0.20301258\n",
            " 0.20919512 0.20526079 0.20694691 0.22605663 0.22043613 0.22437051\n",
            " 0.22099817 0.21537766 0.21144333 0.21088129 0.20694691 0.21931205\n",
            " 0.21818791 0.22268434 0.21875001 0.21144333 0.21031925 0.207509\n",
            " 0.20413665 0.21537766 0.20694691 0.20076436 0.20357462 0.20975716\n",
            " 0.21762587 0.21818791 0.21256741 0.21200537 0.21425358 0.21425358\n",
            " 0.2165018  0.21706384 0.21875001 0.21762587 0.21987409 0.21537766\n",
            " 0.20919512 0.21200537 0.20694691 0.21144333 0.20863308 0.19964029\n",
            " 0.20076436 0.19739207 0.19345774 0.20245054 0.2013264  0.20413665\n",
            " 0.20076436 0.20526079 0.20694691 0.20638487 0.20863308 0.21312951\n",
            " 0.21818791 0.20807104 0.20413665 0.20020232 0.19964029 0.19964029\n",
            " 0.19851615 0.19401978 0.19120953 0.19345774 0.20301258 0.21144333\n",
            " 0.20357462 0.20638487 0.20638487 0.19739207 0.19177157 0.18615107\n",
            " 0.17996852 0.18558903 0.17772031 0.16985159 0.17659623 0.17434802\n",
            " 0.17659623 0.17659623 0.19177157 0.19739207 0.19289565 0.18727514\n",
            " 0.19064749 0.19851615 0.2018885  0.1957059  0.19514386 0.19120953\n",
            " 0.19233361 0.19907825 0.20020232 0.20245054 0.19289565 0.1957059\n",
            " 0.19626799 0.19851615 0.19514386 0.19177157 0.1867131  0.18390285\n",
            " 0.17828235 0.17772031 0.17659623 0.17715827 0.17996852 0.17041363\n",
            " 0.17041363 0.17940648 0.1754721  0.18277877 0.18502699 0.19120953\n",
            " 0.18952336 0.1957059  0.20076436 0.20413665 0.20582283 0.19683003\n",
            " 0.20413665 0.19795411 0.20807104 0.22156026 0.21931205 0.21200537\n",
            " 0.21762587 0.21481562 0.21537766 0.20526079 0.21031925 0.2013264\n",
            " 0.19739207 0.21256741 0.19851615 0.20582283 0.19964029 0.19120953\n",
            " 0.1957059  0.19739207 0.20526079 0.207509   0.20301258 0.20469875\n",
            " 0.20582283 0.20301258 0.20694691 0.20301258 0.20357462 0.20469875\n",
            " 0.20357462 0.20357462 0.20694691 0.20863308 0.21256741 0.21706384\n",
            " 0.21875001 0.21537766 0.21031925 0.21481562 0.21762587 0.21593976\n",
            " 0.21537766 0.21762587 0.21875001 0.21256741 0.21088129 0.21537766\n",
            " 0.2165018  0.20638487 0.21031925 0.21031925 0.21256741 0.21875001\n",
            " 0.21369154 0.22437051 0.22043613 0.22099817 0.21875001 0.21931205\n",
            " 0.21537766 0.21593976 0.21762587 0.21481562 0.21481562 0.21931205\n",
            " 0.22268434 0.22043613 0.2221223  0.2367356  0.24010789 0.23785968\n",
            " 0.24123202 0.24291814 0.24291814 0.24179406 0.24629043 0.24853864\n",
            " 0.24853864 0.2479766  0.24853864 0.24348018 0.24123202 0.25472119\n",
            " 0.25640736 0.26090379 0.26371404 0.25865557 0.25247303 0.25865557\n",
            " 0.26933454 0.26090379 0.26315194 0.26821041 0.26371404 0.25809353\n",
            " 0.25415915 0.2513489  0.25977965 0.25640736 0.27045862 0.26427608\n",
            " 0.2625899  0.25865557 0.25472119 0.25865557 0.25640736 0.25078686\n",
            " 0.24966278 0.24910068 0.24516635 0.25640736 0.24348018 0.24291814\n",
            " 0.24348018 0.2367356  0.23898381 0.22718076 0.22718076 0.23898381\n",
            " 0.23617356 0.24010789 0.23842177 0.25191093 0.23898381 0.24685253\n",
            " 0.24066993 0.24572839 0.2423561  0.23785968 0.23561152 0.23842177\n",
            " 0.2479766  0.24853864 0.24741457 0.2479766  0.25472119 0.26034169\n",
            " 0.25640736 0.26202786 0.26202786 0.25977965 0.25977965 0.2625899\n",
            " 0.25865557 0.26540015 0.26877245 0.27607912 0.28226166 0.28113759\n",
            " 0.27495504 0.26764837 0.27102066 0.26821041 0.26989658 0.27439295\n",
            " 0.27551708 0.2828237  0.28113759 0.27945141 0.26371404 0.26821041\n",
            " 0.26090379 0.26933454 0.2772032  0.26427608 0.26652429 0.26933454\n",
            " 0.25921761 0.26146582 0.25528328 0.24516635 0.23617356 0.23785968\n",
            " 0.25359711 0.24685253 0.25528328 0.25921761 0.26821041 0.25977965\n",
            " 0.26090379 0.26989658 0.26090379 0.2479766  0.24853864 0.25584532\n",
            " 0.25865557 0.25921761 0.26933454 0.27045862 0.28169963 0.2777653\n",
            " 0.28001345 0.2772032  0.27945141 0.28226166 0.28113759 0.28619605\n",
            " 0.29013038 0.29687496 0.2828237  0.28450988 0.28394784 0.2777653\n",
            " 0.27664116 0.27607912 0.27270683 0.27439295 0.27270683 0.26933454\n",
            " 0.26821041 0.27551708 0.27607912 0.27551708 0.27607912 0.27664116\n",
            " 0.28844421 0.28956834 0.29013038 0.2890063  0.30811597 0.31935698\n",
            " 0.32497748 0.31092622 0.32160519 0.3182329  0.30586781 0.30530572\n",
            " 0.30586781 0.30024731 0.30755393 0.30080935 0.30137139 0.31767086\n",
            " 0.31542265 0.31486061 0.31429857 0.32553958 0.32553958 0.32497748\n",
            " 0.32947391 0.32441544 0.32891187 0.33059798 0.35757642 0.37893436\n",
            " 0.38005844 0.37612411 0.37443793 0.36656922 0.36151075 0.37443793\n",
            " 0.3592626  0.35476617 0.34970771 0.36207285 0.3587005  0.36151075\n",
            " 0.36263489 0.35757642 0.35813846 0.35026975 0.3440872  0.35083184\n",
            " 0.35589025 0.35195592 0.35420413 0.34577338 0.34296313 0.34183899\n",
            " 0.36432101 0.36544514 0.36038668 0.35139388 0.34970771 0.35645235\n",
            " 0.37331386 0.36375897 0.34464924 0.34970771 0.35532821 0.34802159\n",
            " 0.34745949 0.34802159 0.34633542 0.34577338 0.33959083 0.33340824\n",
            " 0.33509441 0.34352516 0.33902874 0.33959083 0.34352516 0.34352516\n",
            " 0.35308    0.36994151 0.36881743 0.36375897 0.36825539 0.35813846\n",
            " 0.33902874 0.34633542 0.35757642 0.34914567 0.33228416 0.3384667\n",
            " 0.30530572 0.33116008 0.3328462  0.3440872  0.33678058 0.34577338\n",
            " 0.34240109 0.34633542 0.34464924 0.34914567 0.34183899 0.35420413\n",
            " 0.34464924 0.32722569 0.34183899 0.34464924 0.33902874 0.34352516\n",
            " 0.32834983 0.33116008 0.33678058 0.33340824 0.34015287 0.33116008\n",
            " 0.32722569 0.31092622 0.31373647 0.31317443 0.30249547 0.29294063\n",
            " 0.28169963 0.27495504 0.26540015 0.23448738 0.25753144 0.24853864\n",
            " 0.25359711 0.25977965 0.25753144 0.24966278 0.2423561  0.24179406\n",
            " 0.2367356  0.24741457 0.27102066 0.2569694 ]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 69ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 1s 43ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 1s 45ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 1s 46ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 1s 44ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 1s 44ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 1s 43ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 1s 45ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 1s 43ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5grfHTH0NWSg",
        "outputId": "2eb03767-e37f-44cd-ae4f-bcd2ace50e3f"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/1299_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GrJ36cANWSg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUU-eVTjNWfB"
      },
      "source": [
        "## 0857 (Petrochina)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQOL6ogRNWfC",
        "outputId": "63d1e357-7ec4-41b8-bdab-ebad2c898b46"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/0857.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_27 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 73ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 25ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdvNg2mKNWfC",
        "outputId": "4ebf8cd1-e6fe-46cf-8511-786f37201f0b"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/0857_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5zhpn-8NWfC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWybrT6SNWrH"
      },
      "source": [
        "## 3988 (Bank of China)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slYfoSNkNWrH",
        "outputId": "c1458c3b-2b7a-461b-ad1d-69542a927954"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/3988.HK.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_29 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_28 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 72ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_e1oDePNWrH",
        "outputId": "d1e4529f-4cb0-489b-a130-360496442e54"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/3988_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvGmATu5NWrH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS5PTPnGtmgL"
      },
      "source": [
        "# SSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX_B-ioEuFGc"
      },
      "source": [
        "## 601628 (China Life Insurance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXxQiL5gy-fz",
        "outputId": "788d3312-cd8b-4611-c65a-879cf78431af"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/601628.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_30 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_29 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 72ms/step - loss: 0.0476 - val_loss: 0.0040\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0029\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0050 - val_loss: 0.0021\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0043 - val_loss: 0.0022\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0040 - val_loss: 0.0022\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0043 - val_loss: 0.0022\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0042 - val_loss: 0.0022\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0037 - val_loss: 0.0026\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0033 - val_loss: 0.0029\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0035 - val_loss: 0.0030\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0036 - val_loss: 0.0025\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0037 - val_loss: 0.0021\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0023\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0021\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0034 - val_loss: 0.0022\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0033 - val_loss: 0.0022\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0032 - val_loss: 0.0026\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0024\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0042 - val_loss: 0.0021\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0034 - val_loss: 0.0023\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0028 - val_loss: 0.0023\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0023\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0025\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0029 - val_loss: 0.0024\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0035 - val_loss: 0.0031\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0028 - val_loss: 0.0024\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0027 - val_loss: 0.0024\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0023\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0023\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oL4r5rqz-Uw",
        "outputId": "1f7db1b1-5c44-4af8-c84d-d91c1a22e22a"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/601628_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIVtUj4guQNg"
      },
      "source": [
        "## 601857 (Petrochina)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s75ItKU0zTjY",
        "outputId": "2047ca6f-b027-4e85-d3ed-dcc2dd65cd74"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/601857.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_31 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_30 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 71ms/step - loss: 0.1531 - val_loss: 0.0141\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0150 - val_loss: 0.0016\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0018\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0023\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0084 - val_loss: 0.0023\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0018\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0080 - val_loss: 0.0016\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0017\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0083 - val_loss: 0.0016\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0013\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0012\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0012\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0011\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0081 - val_loss: 0.0012\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0013\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0013\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0014\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0072 - val_loss: 0.0011\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0011\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.0011\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0065 - val_loss: 0.0014\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0014\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0012\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0012\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0012\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0011\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0071 - val_loss: 0.0012\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0011\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0066 - val_loss: 0.0011\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0065 - val_loss: 0.0012\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0061 - val_loss: 0.0011\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0070 - val_loss: 0.0023\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0017\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0015\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0013\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0017\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0014\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0015\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0070 - val_loss: 0.0020\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0017\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0021\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0016\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0012\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.0012\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0015\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0061 - val_loss: 0.0018\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0014\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0012\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0014\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0064 - val_loss: 0.0015\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0063 - val_loss: 0.0011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18yMEtu00TuS",
        "outputId": "c615c066-5bd7-41de-b965-4fbbd40e1d0c"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/601857_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7FJtO_TuaA5"
      },
      "source": [
        "## 601318 (Ping An Insurance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLZBvcmR0Xby",
        "outputId": "079f5d25-0fc8-48a3-de42-215cf27f5ef4"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/601318.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_32 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_31 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 72ms/step - loss: 0.0111 - val_loss: 0.0133\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0027 - val_loss: 0.0046\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.7337e-04 - val_loss: 0.0022\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0011 - val_loss: 0.0041\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0011 - val_loss: 0.0029\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.0032\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.4789e-04 - val_loss: 0.0034\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0011 - val_loss: 0.0028\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.9403e-04 - val_loss: 0.0035\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0010 - val_loss: 0.0065\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 8.6921e-04 - val_loss: 0.0065\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 8.8137e-04 - val_loss: 0.0043\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.3951e-04 - val_loss: 0.0030\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 8.5476e-04 - val_loss: 0.0062\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 8.6654e-04 - val_loss: 0.0075\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 7.9089e-04 - val_loss: 0.0056\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.8749e-04 - val_loss: 0.0036\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 8.3677e-04 - val_loss: 0.0038\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 8.7251e-04 - val_loss: 0.0041\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 8.5303e-04 - val_loss: 0.0045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea73Vlyh0e2t",
        "outputId": "534fa404-267e-4961-9848-3a63be51232d"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/601318_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JagZYVoiuhym"
      },
      "source": [
        "## 601939 (China Construction Bank)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9KoZAgL0hkF",
        "outputId": "b83794ee-de37-4f0a-b838-19c997f4817b"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/601939.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_33 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_32 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 71ms/step - loss: 0.0273 - val_loss: 0.0066\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0053 - val_loss: 0.0049\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0038 - val_loss: 0.0055\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0043 - val_loss: 0.0067\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0034 - val_loss: 0.0075\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0035 - val_loss: 0.0056\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0034 - val_loss: 0.0070\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0073\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0032 - val_loss: 0.0056\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0053\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0054\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0033 - val_loss: 0.0054\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0035 - val_loss: 0.0060\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0035 - val_loss: 0.0045\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0068\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0034 - val_loss: 0.0050\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0055\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0032 - val_loss: 0.0048\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0071\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0036 - val_loss: 0.0046\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0032 - val_loss: 0.0039\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0033 - val_loss: 0.0045\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0039\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0033 - val_loss: 0.0047\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0030 - val_loss: 0.0059\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0034 - val_loss: 0.0049\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0051\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0031 - val_loss: 0.0044\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0050\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0026 - val_loss: 0.0051\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0029 - val_loss: 0.0059\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0029 - val_loss: 0.0108\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0099\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0037 - val_loss: 0.0063\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0031 - val_loss: 0.0048\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0026 - val_loss: 0.0049\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0031 - val_loss: 0.0047\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0026 - val_loss: 0.0068\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0029 - val_loss: 0.0066\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0028 - val_loss: 0.0054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlQ5evnh0mD4",
        "outputId": "b16a065d-735a-4e75-b125-08f855120349"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/601939_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBKbu8RMuoAc"
      },
      "source": [
        "## 600036 (China Merchants Bank)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u48yTOLm0ptk",
        "outputId": "f23f8867-177d-49b5-f60e-c3e66ab2e1c0"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/600036.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_34 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_33 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 70ms/step - loss: 0.0047 - val_loss: 0.0181\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0012 - val_loss: 8.4654e-04\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.0090e-04 - val_loss: 0.0023\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.3106e-04 - val_loss: 8.7823e-04\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.4815e-04 - val_loss: 8.6283e-04\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.0635e-04 - val_loss: 8.2822e-04\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.2816e-04 - val_loss: 8.7543e-04\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.4341e-04 - val_loss: 0.0015\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.9321e-04 - val_loss: 0.0011\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.7928e-04 - val_loss: 9.5931e-04\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 4.1733e-04 - val_loss: 8.6533e-04\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.5441e-04 - val_loss: 6.8872e-04\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.2659e-04 - val_loss: 7.2054e-04\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.3091e-04 - val_loss: 8.8861e-04\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.1731e-04 - val_loss: 0.0014\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.1069e-04 - val_loss: 7.3457e-04\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.8357e-04 - val_loss: 0.0011\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.8625e-04 - val_loss: 9.8098e-04\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.3826e-04 - val_loss: 0.0010\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.0592e-04 - val_loss: 0.0014\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.3072e-04 - val_loss: 7.2900e-04\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.0193e-04 - val_loss: 0.0012\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 3.6484e-04 - val_loss: 0.0010\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.7104e-04 - val_loss: 0.0019\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.8134e-04 - val_loss: 9.5839e-04\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.4429e-04 - val_loss: 0.0015\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.7288e-04 - val_loss: 9.4033e-04\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.1513e-04 - val_loss: 0.0015\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.7292e-04 - val_loss: 0.0015\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.4187e-04 - val_loss: 0.0011\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.8971e-04 - val_loss: 0.0012\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.5831e-04 - val_loss: 0.0012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R-kNFA00tI7",
        "outputId": "a7048154-40dd-453a-bdf5-adcbea5c67df"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/600036_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lIDC94Kuswf"
      },
      "source": [
        "## 601398 (Industrial and Commercial Bank of China)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZV5FU1K0zUC",
        "outputId": "fefd78ba-a1d2-4587-8d5b-59d54ccd1be7"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/601398.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_35 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_34 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 69ms/step - loss: 0.0298 - val_loss: 0.0153\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0045 - val_loss: 0.0052\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0041\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0035 - val_loss: 0.0048\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0054\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0075\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0028 - val_loss: 0.0046\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0027 - val_loss: 0.0063\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0028 - val_loss: 0.0042\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0027 - val_loss: 0.0046\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0027 - val_loss: 0.0045\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0027 - val_loss: 0.0042\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0058\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0028 - val_loss: 0.0046\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0039\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0040\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0046\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0026 - val_loss: 0.0048\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0022 - val_loss: 0.0040\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0022 - val_loss: 0.0055\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0023 - val_loss: 0.0044\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0046\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0046\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0023 - val_loss: 0.0034\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0048\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0028 - val_loss: 0.0047\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.0062\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0058\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0027 - val_loss: 0.0046\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0026 - val_loss: 0.0048\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0039\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.0050\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0021 - val_loss: 0.0052\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0021 - val_loss: 0.0040\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0054\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0022 - val_loss: 0.0047\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0023 - val_loss: 0.0051\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0055\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.0057\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0021 - val_loss: 0.0058\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0023 - val_loss: 0.0059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tm7MMeC05gy",
        "outputId": "190201ce-4028-4b3f-8c82-f3758a2a86ea"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/601398_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBsYI1l8uw6e"
      },
      "source": [
        "## 600519 (Kweichow Moutai)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C5YWnqG0-lD",
        "outputId": "3ce32de1-4591-4e7e-8da1-8883d4d389b1"
      },
      "source": [
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/600519.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_36 (InputLayer)        [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_35 (LSTM)               (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 4s 71ms/step - loss: 2.1620e-04 - val_loss: 0.0036\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 6.5569e-05 - val_loss: 0.0026\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.0639e-05 - val_loss: 0.0012\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.4217e-05 - val_loss: 8.8742e-04\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.2879e-05 - val_loss: 5.4999e-04\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.4168e-05 - val_loss: 4.9665e-04\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.1871e-05 - val_loss: 3.7567e-04\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.1135e-05 - val_loss: 4.3600e-04\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.8528e-05 - val_loss: 3.1898e-04\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.8078e-05 - val_loss: 3.1668e-04\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.4910e-05 - val_loss: 4.0131e-04\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.4407e-05 - val_loss: 3.4773e-04\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.8071e-05 - val_loss: 3.4065e-04\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.5738e-05 - val_loss: 3.9003e-04\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.8502e-05 - val_loss: 2.7080e-04\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.1384e-05 - val_loss: 2.7493e-04\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.6848e-05 - val_loss: 3.4539e-04\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.7867e-05 - val_loss: 2.7083e-04\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.8721e-05 - val_loss: 2.7495e-04\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.7432e-05 - val_loss: 3.0678e-04\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.9251e-05 - val_loss: 2.6945e-04\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.6014e-05 - val_loss: 2.6545e-04\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 3.0202e-05 - val_loss: 2.4978e-04\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.4350e-05 - val_loss: 1.9859e-04\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.6935e-05 - val_loss: 2.2544e-04\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.5475e-05 - val_loss: 2.6046e-04\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.5377e-05 - val_loss: 4.4306e-04\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.5353e-05 - val_loss: 2.6502e-04\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 3.4064e-05 - val_loss: 2.5622e-04\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.8434e-05 - val_loss: 2.5150e-04\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.4301e-05 - val_loss: 1.8882e-04\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.7846e-05 - val_loss: 2.8395e-04\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.4123e-05 - val_loss: 3.3913e-04\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.4147e-05 - val_loss: 2.9514e-04\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 2.4127e-05 - val_loss: 3.0007e-04\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 2.2804e-05 - val_loss: 2.4065e-04\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.4513e-05 - val_loss: 1.7065e-04\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.3626e-05 - val_loss: 1.3466e-04\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.7010e-05 - val_loss: 1.5703e-04\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.4205e-05 - val_loss: 1.8626e-04\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.4871e-05 - val_loss: 2.6548e-04\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.7232e-05 - val_loss: 1.5361e-04\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.1479e-05 - val_loss: 1.8032e-04\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.2510e-05 - val_loss: 2.1924e-04\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.6193e-05 - val_loss: 2.3255e-04\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.3245e-05 - val_loss: 2.3253e-04\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.6611e-05 - val_loss: 2.1522e-04\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.9253e-05 - val_loss: 1.2996e-04\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3886e-05 - val_loss: 1.1238e-04\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.5461e-05 - val_loss: 1.4362e-04\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.2491e-05 - val_loss: 1.5484e-04\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.4050e-05 - val_loss: 1.7014e-04\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.5712e-05 - val_loss: 1.4701e-04\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.6363e-05 - val_loss: 1.5563e-04\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3887e-05 - val_loss: 1.9282e-04\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3713e-05 - val_loss: 2.2873e-04\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.2965e-05 - val_loss: 1.4633e-04\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3471e-05 - val_loss: 1.3743e-04\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.6304e-05 - val_loss: 1.5105e-04\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.3408e-05 - val_loss: 1.9555e-04\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.8673e-05 - val_loss: 3.0897e-04\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.4991e-05 - val_loss: 1.9811e-04\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.8593e-05 - val_loss: 1.6466e-04\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.1720e-05 - val_loss: 1.7782e-04\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.3265e-05 - val_loss: 2.1513e-04\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.0687e-05 - val_loss: 2.9861e-04\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.6238e-05 - val_loss: 2.8390e-04\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.4057e-05 - val_loss: 2.7280e-04\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.4974e-05 - val_loss: 1.8922e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGlCVsZx1C8J",
        "outputId": "738f4782-abef-4642-9dda-7bf26754389a"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/600519_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEiRZadklYSu"
      },
      "source": [
        "#2 week minute data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnT62TqGl77A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91SH15zVhvzh"
      },
      "source": [
        "### Parse the raw_data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W4toAMOa0HS",
        "outputId": "423dcadf-f35b-4ecb-fb3d-bbb0f08a39d9"
      },
      "source": [
        "raw_data = pd.read_csv('/content/drive/My Drive/lstm_stock_predictions/crypto_2_weeks.csv', index_col=0, parse_dates=True)\n",
        "crypto_data = {}\n",
        "for name in raw_data.index.unique() :\n",
        "  print(name)\n",
        "  crypto_data[name] = pd.DataFrame()\n",
        "  crypto_data[name]['Time'] = pd.to_datetime(raw_data.loc[name]['TIME'], format='%d-%m-%y %H:%M:%S')\n",
        "  crypto_data[name]['Close'] = (raw_data.loc[name]['ASK'] + raw_data.loc[name]['BID'])/2\n",
        "  crypto_data[name] = crypto_data[name].set_index('Time')\n",
        "  crypto_data[name] = crypto_data[name].sort_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "YFI/USD\n",
            "UNI/USD\n",
            "LINK/USD\n",
            "ADA/USD\n",
            "DOT/USD\n",
            "DOG/USD\n",
            "UST/USD\n",
            "LTC/USD\n",
            "ETH/USD\n",
            "BTC/USD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmhmwgclHtXI"
      },
      "source": [
        "##YFI-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez_-m8Famxda",
        "outputId": "62e25b79-1f51-42ae-dad1-0a35ae91b950"
      },
      "source": [
        "raw_data = crypto_data['YFI/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.53019713 0.49638734 0.46324511 ... 0.33660567 0.33876541 0.33951151]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "416/416 [==============================] - 19s 38ms/step - loss: 0.0065 - val_loss: 6.6027e-05\n",
            "Epoch 2/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 0.0026 - val_loss: 7.7589e-05\n",
            "Epoch 3/500\n",
            "416/416 [==============================] - 16s 37ms/step - loss: 0.0022 - val_loss: 6.5340e-05\n",
            "Epoch 4/500\n",
            "416/416 [==============================] - 15s 36ms/step - loss: 0.0018 - val_loss: 1.0335e-04\n",
            "Epoch 5/500\n",
            "416/416 [==============================] - 16s 37ms/step - loss: 0.0015 - val_loss: 7.9446e-05\n",
            "Epoch 6/500\n",
            "416/416 [==============================] - 15s 36ms/step - loss: 0.0013 - val_loss: 7.7111e-05\n",
            "Epoch 7/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 0.0010 - val_loss: 1.0416e-04\n",
            "Epoch 8/500\n",
            "416/416 [==============================] - 16s 39ms/step - loss: 8.6817e-04 - val_loss: 8.9825e-05\n",
            "Epoch 9/500\n",
            "416/416 [==============================] - 16s 39ms/step - loss: 7.6297e-04 - val_loss: 8.1479e-05\n",
            "Epoch 10/500\n",
            "416/416 [==============================] - 15s 36ms/step - loss: 7.1086e-04 - val_loss: 1.5442e-04\n",
            "Epoch 11/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 6.9112e-04 - val_loss: 7.6004e-05\n",
            "Epoch 12/500\n",
            "416/416 [==============================] - 16s 39ms/step - loss: 6.6687e-04 - val_loss: 8.0442e-05\n",
            "Epoch 13/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 6.5374e-04 - val_loss: 6.8898e-05\n",
            "Epoch 14/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 6.2019e-04 - val_loss: 1.1452e-04\n",
            "Epoch 15/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 5.9486e-04 - val_loss: 1.1054e-04\n",
            "Epoch 16/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 5.5875e-04 - val_loss: 6.4954e-05\n",
            "Epoch 17/500\n",
            "416/416 [==============================] - 16s 37ms/step - loss: 5.4089e-04 - val_loss: 8.6626e-05\n",
            "Epoch 18/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 5.4116e-04 - val_loss: 1.3329e-04\n",
            "Epoch 19/500\n",
            "416/416 [==============================] - 16s 37ms/step - loss: 5.2327e-04 - val_loss: 7.3983e-05\n",
            "Epoch 20/500\n",
            "416/416 [==============================] - 15s 36ms/step - loss: 5.1494e-04 - val_loss: 7.0162e-05\n",
            "Epoch 21/500\n",
            "416/416 [==============================] - 15s 36ms/step - loss: 5.1222e-04 - val_loss: 9.7075e-05\n",
            "Epoch 22/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.8846e-04 - val_loss: 2.3654e-04\n",
            "Epoch 23/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 5.0160e-04 - val_loss: 7.0414e-05\n",
            "Epoch 24/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.9516e-04 - val_loss: 9.8366e-05\n",
            "Epoch 25/500\n",
            "416/416 [==============================] - 15s 36ms/step - loss: 4.8147e-04 - val_loss: 8.3982e-05\n",
            "Epoch 26/500\n",
            "416/416 [==============================] - 16s 37ms/step - loss: 4.8026e-04 - val_loss: 6.1192e-05\n",
            "Epoch 27/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.7049e-04 - val_loss: 6.0440e-05\n",
            "Epoch 28/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 4.6885e-04 - val_loss: 7.6028e-05\n",
            "Epoch 29/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 4.7202e-04 - val_loss: 1.6939e-04\n",
            "Epoch 30/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.7217e-04 - val_loss: 1.0935e-04\n",
            "Epoch 31/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 4.7513e-04 - val_loss: 1.1888e-04\n",
            "Epoch 32/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.6511e-04 - val_loss: 5.8871e-05\n",
            "Epoch 33/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.5729e-04 - val_loss: 6.5192e-05\n",
            "Epoch 34/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.5332e-04 - val_loss: 8.3388e-05\n",
            "Epoch 35/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 4.5143e-04 - val_loss: 1.2161e-04\n",
            "Epoch 36/500\n",
            "416/416 [==============================] - 15s 36ms/step - loss: 4.5588e-04 - val_loss: 8.7161e-05\n",
            "Epoch 37/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.4326e-04 - val_loss: 7.9280e-05\n",
            "Epoch 38/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.3700e-04 - val_loss: 7.6584e-05\n",
            "Epoch 39/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.2904e-04 - val_loss: 1.0323e-04\n",
            "Epoch 40/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.3733e-04 - val_loss: 6.6026e-05\n",
            "Epoch 41/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.4128e-04 - val_loss: 7.2422e-05\n",
            "Epoch 42/500\n",
            "416/416 [==============================] - 16s 37ms/step - loss: 4.2731e-04 - val_loss: 7.0917e-05\n",
            "Epoch 43/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 4.3307e-04 - val_loss: 6.5014e-05\n",
            "Epoch 44/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.3150e-04 - val_loss: 6.0834e-05\n",
            "Epoch 45/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 4.2960e-04 - val_loss: 6.8536e-05\n",
            "Epoch 46/500\n",
            "416/416 [==============================] - 16s 38ms/step - loss: 4.2446e-04 - val_loss: 1.6187e-04\n",
            "Epoch 47/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.2054e-04 - val_loss: 7.3805e-05\n",
            "Epoch 48/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.3011e-04 - val_loss: 1.6928e-04\n",
            "Epoch 49/500\n",
            "416/416 [==============================] - 16s 37ms/step - loss: 4.2247e-04 - val_loss: 5.8900e-05\n",
            "Epoch 50/500\n",
            "416/416 [==============================] - 16s 37ms/step - loss: 4.1705e-04 - val_loss: 6.5938e-05\n",
            "Epoch 51/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.1986e-04 - val_loss: 6.8896e-05\n",
            "Epoch 52/500\n",
            "416/416 [==============================] - 16s 37ms/step - loss: 4.1820e-04 - val_loss: 6.1369e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT21sfLYoRHL",
        "outputId": "7bf0d75c-145a-49a4-9413-f91801fa9111"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/YFI-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UZ_CSUjITN5"
      },
      "source": [
        "## UNI-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRoZaA1pepYP",
        "outputId": "fb87812b-2a3a-4b3e-cc57-0dc9c4027f89"
      },
      "source": [
        "raw_data = crypto_data['UNI/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.55043115 0.50759388 0.43115438 ... 0.30097357 0.30130737 0.30114047]\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "416/416 [==============================] - 19s 36ms/step - loss: 0.0234 - val_loss: 3.9938e-04\n",
            "Epoch 2/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0033 - val_loss: 9.8243e-05\n",
            "Epoch 3/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0027 - val_loss: 6.6445e-05\n",
            "Epoch 4/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0022 - val_loss: 1.6512e-04\n",
            "Epoch 5/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0018 - val_loss: 6.8866e-05\n",
            "Epoch 6/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0014 - val_loss: 7.6255e-05\n",
            "Epoch 7/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0010 - val_loss: 9.0798e-05\n",
            "Epoch 8/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 8.5625e-04 - val_loss: 1.9124e-04\n",
            "Epoch 9/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 7.8209e-04 - val_loss: 2.1062e-04\n",
            "Epoch 10/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 7.3642e-04 - val_loss: 1.4466e-04\n",
            "Epoch 11/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.8447e-04 - val_loss: 1.0085e-04\n",
            "Epoch 12/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.7693e-04 - val_loss: 8.3539e-05\n",
            "Epoch 13/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.8001e-04 - val_loss: 7.5575e-05\n",
            "Epoch 14/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.7402e-04 - val_loss: 6.7165e-05\n",
            "Epoch 15/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.3789e-04 - val_loss: 8.1009e-05\n",
            "Epoch 16/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.1386e-04 - val_loss: 1.4994e-04\n",
            "Epoch 17/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.7346e-04 - val_loss: 6.8559e-05\n",
            "Epoch 18/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.5847e-04 - val_loss: 1.1126e-04\n",
            "Epoch 19/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.5633e-04 - val_loss: 1.2396e-04\n",
            "Epoch 20/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.2310e-04 - val_loss: 9.5708e-05\n",
            "Epoch 21/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.9885e-04 - val_loss: 1.0928e-04\n",
            "Epoch 22/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.1527e-04 - val_loss: 1.1150e-04\n",
            "Epoch 23/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.8710e-04 - val_loss: 9.3498e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vb_J1iapQFU",
        "outputId": "bc367003-fcc9-4ebd-a0b3-9cddd7babfcd"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/UNI-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2JP6leFIVjC"
      },
      "source": [
        "##LINK-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjD35LyPe1lj",
        "outputId": "274567c4-47bd-4169-e68c-ec16c824807a"
      },
      "source": [
        "raw_data = crypto_data['LINK/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.51891201 0.49626553 0.45776251 ... 0.27223709 0.27475337 0.27611136]\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "416/416 [==============================] - 19s 36ms/step - loss: 0.0256 - val_loss: 5.1089e-05\n",
            "Epoch 2/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 0.0027 - val_loss: 3.6910e-05\n",
            "Epoch 3/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0023 - val_loss: 3.8081e-05\n",
            "Epoch 4/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0019 - val_loss: 5.7715e-05\n",
            "Epoch 5/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0015 - val_loss: 4.9744e-05\n",
            "Epoch 6/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0012 - val_loss: 6.9626e-05\n",
            "Epoch 7/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 9.3194e-04 - val_loss: 5.9194e-05\n",
            "Epoch 8/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 7.5186e-04 - val_loss: 9.3050e-05\n",
            "Epoch 9/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.3827e-04 - val_loss: 1.1928e-04\n",
            "Epoch 10/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.8628e-04 - val_loss: 3.5719e-04\n",
            "Epoch 11/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.4434e-04 - val_loss: 6.4715e-05\n",
            "Epoch 12/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.4919e-04 - val_loss: 9.5551e-05\n",
            "Epoch 13/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.4479e-04 - val_loss: 1.3365e-04\n",
            "Epoch 14/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.4295e-04 - val_loss: 4.6434e-05\n",
            "Epoch 15/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.9629e-04 - val_loss: 1.0512e-04\n",
            "Epoch 16/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.7914e-04 - val_loss: 7.6831e-05\n",
            "Epoch 17/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.0823e-04 - val_loss: 3.7993e-05\n",
            "Epoch 18/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.5769e-04 - val_loss: 7.0889e-05\n",
            "Epoch 19/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.4041e-04 - val_loss: 5.8093e-05\n",
            "Epoch 20/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.2623e-04 - val_loss: 6.4303e-05\n",
            "Epoch 21/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.4780e-04 - val_loss: 1.2214e-04\n",
            "Epoch 22/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 4.1963e-04 - val_loss: 5.8554e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef9WDfs7ph95",
        "outputId": "2a451b60-25d4-4bf5-86fd-ca6b5bc2f420"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/LINK-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg0_QexQIXXY"
      },
      "source": [
        "##ADA-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnEmVyR3fVwg",
        "outputId": "a5e6c040-5516-460a-e93f-3ced6ac052ab"
      },
      "source": [
        "raw_data = crypto_data['ADA/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.40297648 0.39644743 0.34008641 ... 0.33307729 0.33346135 0.33528565]\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "416/416 [==============================] - 21s 42ms/step - loss: 0.0271 - val_loss: 9.2859e-05\n",
            "Epoch 2/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0025 - val_loss: 6.3771e-05\n",
            "Epoch 3/500\n",
            "416/416 [==============================] - 15s 37ms/step - loss: 0.0023 - val_loss: 6.8117e-05\n",
            "Epoch 4/500\n",
            "416/416 [==============================] - 15s 36ms/step - loss: 0.0019 - val_loss: 1.0414e-04\n",
            "Epoch 5/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 0.0016 - val_loss: 6.6919e-05\n",
            "Epoch 6/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0013 - val_loss: 1.4855e-04\n",
            "Epoch 7/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0011 - val_loss: 8.9960e-05\n",
            "Epoch 8/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 9.0990e-04 - val_loss: 8.5594e-05\n",
            "Epoch 9/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 7.3740e-04 - val_loss: 7.3345e-05\n",
            "Epoch 10/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.9619e-04 - val_loss: 1.4207e-04\n",
            "Epoch 11/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.4656e-04 - val_loss: 6.7474e-05\n",
            "Epoch 12/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.2376e-04 - val_loss: 1.1462e-04\n",
            "Epoch 13/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.9198e-04 - val_loss: 7.4277e-05\n",
            "Epoch 14/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.1476e-04 - val_loss: 7.4020e-05\n",
            "Epoch 15/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.7032e-04 - val_loss: 7.4048e-05\n",
            "Epoch 16/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 5.7436e-04 - val_loss: 6.9038e-05\n",
            "Epoch 17/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.9367e-04 - val_loss: 7.3960e-05\n",
            "Epoch 18/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.7576e-04 - val_loss: 6.3309e-05\n",
            "Epoch 19/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.2205e-04 - val_loss: 9.3301e-05\n",
            "Epoch 20/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.9796e-04 - val_loss: 1.2941e-04\n",
            "Epoch 21/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.9459e-04 - val_loss: 8.8863e-05\n",
            "Epoch 22/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.9696e-04 - val_loss: 1.2081e-04\n",
            "Epoch 23/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.5668e-04 - val_loss: 7.5064e-05\n",
            "Epoch 24/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.6701e-04 - val_loss: 9.5253e-05\n",
            "Epoch 25/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.4049e-04 - val_loss: 2.0137e-04\n",
            "Epoch 26/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.0712e-04 - val_loss: 1.0386e-04\n",
            "Epoch 27/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.0649e-04 - val_loss: 1.6586e-04\n",
            "Epoch 28/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.2344e-04 - val_loss: 8.7410e-05\n",
            "Epoch 29/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.9076e-04 - val_loss: 7.0544e-05\n",
            "Epoch 30/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.0508e-04 - val_loss: 5.4483e-05\n",
            "Epoch 31/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.0968e-04 - val_loss: 6.6154e-05\n",
            "Epoch 32/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.9174e-04 - val_loss: 7.4565e-05\n",
            "Epoch 33/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.9977e-04 - val_loss: 8.2807e-05\n",
            "Epoch 34/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.9907e-04 - val_loss: 7.6131e-05\n",
            "Epoch 35/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.9423e-04 - val_loss: 6.9871e-05\n",
            "Epoch 36/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.6642e-04 - val_loss: 6.2028e-05\n",
            "Epoch 37/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 3.5589e-04 - val_loss: 6.7778e-05\n",
            "Epoch 38/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.7347e-04 - val_loss: 5.5961e-05\n",
            "Epoch 39/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.8420e-04 - val_loss: 1.5379e-04\n",
            "Epoch 40/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.8427e-04 - val_loss: 7.2996e-05\n",
            "Epoch 41/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.6484e-04 - val_loss: 5.8738e-05\n",
            "Epoch 42/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.7546e-04 - val_loss: 6.0793e-05\n",
            "Epoch 43/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.6624e-04 - val_loss: 7.5616e-05\n",
            "Epoch 44/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.6999e-04 - val_loss: 1.1570e-04\n",
            "Epoch 45/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5434e-04 - val_loss: 1.2385e-04\n",
            "Epoch 46/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5370e-04 - val_loss: 8.2676e-05\n",
            "Epoch 47/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.4555e-04 - val_loss: 6.2105e-05\n",
            "Epoch 48/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.6777e-04 - val_loss: 5.6822e-05\n",
            "Epoch 49/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5928e-04 - val_loss: 5.2396e-05\n",
            "Epoch 50/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5889e-04 - val_loss: 1.5707e-04\n",
            "Epoch 51/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.6131e-04 - val_loss: 1.5565e-04\n",
            "Epoch 52/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.8551e-04 - val_loss: 8.2704e-05\n",
            "Epoch 53/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.6134e-04 - val_loss: 1.0503e-04\n",
            "Epoch 54/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.4999e-04 - val_loss: 7.5922e-05\n",
            "Epoch 55/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.0948e-04 - val_loss: 5.0513e-05\n",
            "Epoch 56/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.8505e-04 - val_loss: 5.2182e-05\n",
            "Epoch 57/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5093e-04 - val_loss: 5.2470e-05\n",
            "Epoch 58/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5636e-04 - val_loss: 6.7816e-05\n",
            "Epoch 59/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5201e-04 - val_loss: 6.9642e-05\n",
            "Epoch 60/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5054e-04 - val_loss: 6.1423e-05\n",
            "Epoch 61/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5674e-04 - val_loss: 5.8559e-05\n",
            "Epoch 62/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.3470e-04 - val_loss: 9.1935e-05\n",
            "Epoch 63/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.6291e-04 - val_loss: 5.8723e-05\n",
            "Epoch 64/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5135e-04 - val_loss: 4.8317e-05\n",
            "Epoch 65/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5410e-04 - val_loss: 8.8361e-05\n",
            "Epoch 66/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5840e-04 - val_loss: 8.0662e-05\n",
            "Epoch 67/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5516e-04 - val_loss: 5.7608e-05\n",
            "Epoch 68/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5402e-04 - val_loss: 7.0794e-05\n",
            "Epoch 69/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.4871e-04 - val_loss: 5.2355e-05\n",
            "Epoch 70/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5941e-04 - val_loss: 1.4050e-04\n",
            "Epoch 71/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 3.5222e-04 - val_loss: 5.5234e-05\n",
            "Epoch 72/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.3076e-04 - val_loss: 1.2024e-04\n",
            "Epoch 73/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5766e-04 - val_loss: 6.6568e-05\n",
            "Epoch 74/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5743e-04 - val_loss: 5.9639e-05\n",
            "Epoch 75/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5339e-04 - val_loss: 9.4811e-05\n",
            "Epoch 76/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.6299e-04 - val_loss: 5.3241e-05\n",
            "Epoch 77/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5710e-04 - val_loss: 7.1417e-05\n",
            "Epoch 78/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 3.5954e-04 - val_loss: 5.3575e-05\n",
            "Epoch 79/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.4841e-04 - val_loss: 6.8826e-05\n",
            "Epoch 80/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.5692e-04 - val_loss: 7.8465e-05\n",
            "Epoch 81/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.5462e-04 - val_loss: 5.3498e-05\n",
            "Epoch 82/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.3902e-04 - val_loss: 5.9534e-05\n",
            "Epoch 83/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.0647e-04 - val_loss: 5.5833e-05\n",
            "Epoch 84/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 3.8499e-04 - val_loss: 6.8744e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I1v30MGpqL8",
        "outputId": "becbcfe6-7b70-48f0-91fc-d1e993eda81d"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/ADA-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtYrdGpLIY7j"
      },
      "source": [
        "##DOT-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjScw4eflvom",
        "outputId": "99ce6172-c4da-48ef-ad70-b7864024f42a"
      },
      "source": [
        "raw_data = crypto_data['DOT/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.12868375 0.11595443 0.07765952 ... 0.19088624 0.19190244 0.19179548]\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "416/416 [==============================] - 19s 36ms/step - loss: 0.0248 - val_loss: 2.0676e-04\n",
            "Epoch 2/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0023 - val_loss: 9.2875e-05\n",
            "Epoch 3/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0018 - val_loss: 7.0045e-05\n",
            "Epoch 4/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0015 - val_loss: 1.1854e-04\n",
            "Epoch 5/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0013 - val_loss: 7.6842e-05\n",
            "Epoch 6/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 0.0010 - val_loss: 7.4659e-05\n",
            "Epoch 7/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 9.2311e-04 - val_loss: 1.2250e-04\n",
            "Epoch 8/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 7.7777e-04 - val_loss: 7.9888e-05\n",
            "Epoch 9/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 7.3144e-04 - val_loss: 1.2388e-04\n",
            "Epoch 10/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.7363e-04 - val_loss: 9.9058e-05\n",
            "Epoch 11/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.4603e-04 - val_loss: 1.0489e-04\n",
            "Epoch 12/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.3655e-04 - val_loss: 2.2027e-04\n",
            "Epoch 13/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.1871e-04 - val_loss: 1.2520e-04\n",
            "Epoch 14/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.3053e-04 - val_loss: 9.3678e-05\n",
            "Epoch 15/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.1218e-04 - val_loss: 1.9225e-04\n",
            "Epoch 16/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.1633e-04 - val_loss: 1.1430e-04\n",
            "Epoch 17/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.9942e-04 - val_loss: 8.7240e-05\n",
            "Epoch 18/500\n",
            "416/416 [==============================] - 15s 36ms/step - loss: 5.7516e-04 - val_loss: 9.6951e-05\n",
            "Epoch 19/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 5.8482e-04 - val_loss: 7.9773e-05\n",
            "Epoch 20/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.3917e-04 - val_loss: 8.9782e-05\n",
            "Epoch 21/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 5.3576e-04 - val_loss: 6.7212e-05\n",
            "Epoch 22/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.9219e-04 - val_loss: 8.1321e-05\n",
            "Epoch 23/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 5.1381e-04 - val_loss: 1.3033e-04\n",
            "Epoch 24/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.7547e-04 - val_loss: 6.7973e-05\n",
            "Epoch 25/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.9842e-04 - val_loss: 8.9343e-05\n",
            "Epoch 26/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.5097e-04 - val_loss: 8.0317e-05\n",
            "Epoch 27/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.3819e-04 - val_loss: 6.5774e-05\n",
            "Epoch 28/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.4045e-04 - val_loss: 7.6321e-05\n",
            "Epoch 29/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.3826e-04 - val_loss: 8.1644e-05\n",
            "Epoch 30/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.4748e-04 - val_loss: 8.3932e-05\n",
            "Epoch 31/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.3476e-04 - val_loss: 1.0544e-04\n",
            "Epoch 32/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.4965e-04 - val_loss: 6.5127e-05\n",
            "Epoch 33/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.6215e-04 - val_loss: 7.2102e-05\n",
            "Epoch 34/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.4245e-04 - val_loss: 1.1669e-04\n",
            "Epoch 35/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.4796e-04 - val_loss: 1.1386e-04\n",
            "Epoch 36/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.5376e-04 - val_loss: 1.4169e-04\n",
            "Epoch 37/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.4439e-04 - val_loss: 1.8460e-04\n",
            "Epoch 38/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.2183e-04 - val_loss: 8.0579e-05\n",
            "Epoch 39/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.1360e-04 - val_loss: 7.0021e-05\n",
            "Epoch 40/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.1758e-04 - val_loss: 5.8311e-05\n",
            "Epoch 41/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.0357e-04 - val_loss: 7.1389e-05\n",
            "Epoch 42/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.1754e-04 - val_loss: 5.8438e-05\n",
            "Epoch 43/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.1820e-04 - val_loss: 5.7692e-05\n",
            "Epoch 44/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 4.2369e-04 - val_loss: 5.6575e-05\n",
            "Epoch 45/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.1555e-04 - val_loss: 7.4629e-05\n",
            "Epoch 46/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.4372e-04 - val_loss: 1.3696e-04\n",
            "Epoch 47/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.1829e-04 - val_loss: 9.7971e-05\n",
            "Epoch 48/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.9567e-04 - val_loss: 6.5271e-05\n",
            "Epoch 49/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.2784e-04 - val_loss: 9.4559e-05\n",
            "Epoch 50/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 3.9852e-04 - val_loss: 5.7815e-05\n",
            "Epoch 51/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 4.0834e-04 - val_loss: 5.8193e-05\n",
            "Epoch 52/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.8700e-04 - val_loss: 5.8269e-05\n",
            "Epoch 53/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.9939e-04 - val_loss: 1.1448e-04\n",
            "Epoch 54/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.0580e-04 - val_loss: 1.2824e-04\n",
            "Epoch 55/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 3.9980e-04 - val_loss: 7.6962e-05\n",
            "Epoch 56/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 3.8667e-04 - val_loss: 6.3345e-05\n",
            "Epoch 57/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.1150e-04 - val_loss: 6.8204e-05\n",
            "Epoch 58/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 3.8140e-04 - val_loss: 1.0807e-04\n",
            "Epoch 59/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.1865e-04 - val_loss: 1.1384e-04\n",
            "Epoch 60/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.0785e-04 - val_loss: 9.2980e-05\n",
            "Epoch 61/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.0437e-04 - val_loss: 9.4171e-05\n",
            "Epoch 62/500\n",
            "416/416 [==============================] - 15s 35ms/step - loss: 3.9824e-04 - val_loss: 6.9277e-05\n",
            "Epoch 63/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 3.9467e-04 - val_loss: 6.4757e-05\n",
            "Epoch 64/500\n",
            "416/416 [==============================] - 14s 35ms/step - loss: 4.0394e-04 - val_loss: 9.1008e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x0jFD7-Cp6M3",
        "outputId": "5c4cd697-b6bd-4e1f-c630-5f2ff8566d3a"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/DOT-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns1e9T_OIbml"
      },
      "source": [
        "##DOG-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MXxSjXT-l0pX",
        "outputId": "460eebc8-b412-46a4-e771-a35fa745d1c8"
      },
      "source": [
        "raw_data = crypto_data['DOG/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04082    0.02507566 0.01469952 ... 0.16659461 0.16814382 0.16223519]\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "416/416 [==============================] - 19s 36ms/step - loss: 0.0068 - val_loss: 1.3729e-04\n",
            "Epoch 2/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 0.0016 - val_loss: 1.3013e-04\n",
            "Epoch 3/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 0.0014 - val_loss: 1.7639e-04\n",
            "Epoch 4/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 0.0011 - val_loss: 1.1957e-04\n",
            "Epoch 5/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 9.8020e-04 - val_loss: 1.4862e-04\n",
            "Epoch 6/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 7.9640e-04 - val_loss: 1.7852e-04\n",
            "Epoch 7/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 7.9516e-04 - val_loss: 1.2920e-04\n",
            "Epoch 8/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 7.7614e-04 - val_loss: 1.7042e-04\n",
            "Epoch 9/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 7.6738e-04 - val_loss: 1.2736e-04\n",
            "Epoch 10/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 7.2131e-04 - val_loss: 1.3506e-04\n",
            "Epoch 11/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 6.8298e-04 - val_loss: 1.7131e-04\n",
            "Epoch 12/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 6.4504e-04 - val_loss: 1.4500e-04\n",
            "Epoch 13/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 6.2660e-04 - val_loss: 1.4998e-04\n",
            "Epoch 14/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.7744e-04 - val_loss: 1.6321e-04\n",
            "Epoch 15/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 6.0365e-04 - val_loss: 1.6108e-04\n",
            "Epoch 16/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 5.8132e-04 - val_loss: 2.0637e-04\n",
            "Epoch 17/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.8420e-04 - val_loss: 2.4934e-04\n",
            "Epoch 18/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 5.9712e-04 - val_loss: 1.3699e-04\n",
            "Epoch 19/500\n",
            "416/416 [==============================] - 14s 34ms/step - loss: 5.8213e-04 - val_loss: 1.6470e-04\n",
            "Epoch 20/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 5.4859e-04 - val_loss: 1.5555e-04\n",
            "Epoch 21/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 5.3162e-04 - val_loss: 2.1189e-04\n",
            "Epoch 22/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 5.6234e-04 - val_loss: 2.3901e-04\n",
            "Epoch 23/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 5.8145e-04 - val_loss: 1.4700e-04\n",
            "Epoch 24/500\n",
            "416/416 [==============================] - 14s 33ms/step - loss: 5.7459e-04 - val_loss: 1.9860e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O3BAwEmrqIUq",
        "outputId": "1520bf76-742e-4d72-ab30-c7f41b81a4f2"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/DOG-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64hnGqROIdzN"
      },
      "source": [
        "##UST-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-d4LQMMDmOwC"
      },
      "source": [
        "raw_data = crypto_data['UST/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vV06MS9MqOZP"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/UST-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq1E1NXCJbX1"
      },
      "source": [
        "##LTC-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpeVxHsimRTk"
      },
      "source": [
        "raw_data = crypto_data['LTC/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQf_hk_fKTrk"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/LTC-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUU9PXAhJdzM"
      },
      "source": [
        "## ETH-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxPwjwzzmSUU"
      },
      "source": [
        "train_len = int(0.7 * len(crypto_data['ETH/USD']))\n",
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/600519.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQhPaS7eK7kj"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/ETH-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI5n8HagJlW8"
      },
      "source": [
        "##BTC-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qI6nXHhmTJt"
      },
      "source": [
        "train_len = int(0.7 * len(crypto_data['BTC/USD']))\n",
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/600519.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF2cvnoll5Rj"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/BTC-USD_2_Week_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjgQ_gKCLSDx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JirzcmxGXvYU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7xzlnlOXv9o"
      },
      "source": [
        "#1 month minute data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v08gLHUEXv9p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1utNbWbIXv9p"
      },
      "source": [
        "### Parse the raw_data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA0zWg1nXv9p",
        "outputId": "f73ffe52-1a91-406f-f966-8bb8d068a675"
      },
      "source": [
        "raw_data = pd.read_csv('/content/drive/My Drive/lstm_stock_predictions/crypto_1_month.csv', index_col=0, parse_dates=True)\n",
        "crypto_data = {}\n",
        "for name in raw_data.index.unique() :\n",
        "  print(name)\n",
        "  crypto_data[name] = pd.DataFrame()\n",
        "  crypto_data[name]['Time'] = pd.to_datetime(raw_data.loc[name]['TIME'], format='%d-%m-%y %H:%M:%S')\n",
        "  crypto_data[name]['Close'] = (raw_data.loc[name]['ASK'] + raw_data.loc[name]['BID'])/2\n",
        "  crypto_data[name] = crypto_data[name].set_index('Time')\n",
        "  crypto_data[name] = crypto_data[name].sort_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UST/USD\n",
            "BTC/USD\n",
            "ETH/USD\n",
            "LTC/BTC\n",
            "YFI/USD\n",
            "UNI/USD\n",
            "LINK/USD\n",
            "ADA/USD\n",
            "DOT/USD\n",
            "DOG/USD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za-wShv4Xv9s"
      },
      "source": [
        "##YFI-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr8dXEAEXv9s",
        "outputId": "0d354613-41dc-4e6a-e1ae-030e9c77d139"
      },
      "source": [
        "raw_data = crypto_data['YFI/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.80066894 0.77623714 0.77784189 ... 0.24371399 0.24370498 0.24347058]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "433/433 [==============================] - 42s 38ms/step - loss: 0.0040 - val_loss: 6.0808e-06\n",
            "Epoch 2/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 7.9189e-04 - val_loss: 1.2461e-05\n",
            "Epoch 3/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 6.4299e-04 - val_loss: 1.4314e-05\n",
            "Epoch 4/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 5.3643e-04 - val_loss: 8.0686e-06\n",
            "Epoch 5/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 4.2728e-04 - val_loss: 4.4941e-05\n",
            "Epoch 6/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.3938e-04 - val_loss: 1.1277e-04\n",
            "Epoch 7/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.0664e-04 - val_loss: 2.6916e-05\n",
            "Epoch 8/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.9820e-04 - val_loss: 3.2684e-05\n",
            "Epoch 9/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.9168e-04 - val_loss: 9.4885e-05\n",
            "Epoch 10/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.8191e-04 - val_loss: 1.3215e-04\n",
            "Epoch 11/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.6091e-04 - val_loss: 4.9771e-05\n",
            "Epoch 12/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4892e-04 - val_loss: 1.8432e-05\n",
            "Epoch 13/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.6290e-04 - val_loss: 2.2609e-05\n",
            "Epoch 14/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.3905e-04 - val_loss: 1.1223e-05\n",
            "Epoch 15/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4605e-04 - val_loss: 1.4427e-05\n",
            "Epoch 16/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.1851e-04 - val_loss: 3.5189e-05\n",
            "Epoch 17/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.3596e-04 - val_loss: 9.6938e-06\n",
            "Epoch 18/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4268e-04 - val_loss: 2.1729e-05\n",
            "Epoch 19/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.7624e-04 - val_loss: 4.4255e-05\n",
            "Epoch 20/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.5854e-04 - val_loss: 1.5658e-05\n",
            "Epoch 21/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4512e-04 - val_loss: 1.7744e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlbrxes2Xv9s",
        "outputId": "aa4bb18b-71ce-4893-8c18-ed06270e2e64"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/YFI-USD_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tr1YWqIXv9t"
      },
      "source": [
        "## UNI-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbkSCvGQXv9t",
        "outputId": "336a0a90-b92a-463f-d094-d12958044e25"
      },
      "source": [
        "raw_data = crypto_data['UNI/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.87831648 0.85412776 0.86566717 ... 0.32035517 0.32072513 0.3206899 ]\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "433/433 [==============================] - 22s 42ms/step - loss: 0.0099 - val_loss: 1.0529e-05\n",
            "Epoch 2/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 0.0014 - val_loss: 2.5843e-05\n",
            "Epoch 3/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 0.0012 - val_loss: 2.9627e-05\n",
            "Epoch 4/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 9.0573e-04 - val_loss: 1.2506e-05\n",
            "Epoch 5/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 6.8338e-04 - val_loss: 2.1831e-05\n",
            "Epoch 6/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 5.3755e-04 - val_loss: 3.8305e-05\n",
            "Epoch 7/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 4.0946e-04 - val_loss: 5.9899e-05\n",
            "Epoch 8/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.7619e-04 - val_loss: 1.1304e-04\n",
            "Epoch 9/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.3612e-04 - val_loss: 3.8812e-05\n",
            "Epoch 10/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.4129e-04 - val_loss: 5.9998e-05\n",
            "Epoch 11/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.2941e-04 - val_loss: 8.7770e-05\n",
            "Epoch 12/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 3.4446e-04 - val_loss: 1.1750e-05\n",
            "Epoch 13/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.1272e-04 - val_loss: 2.7886e-05\n",
            "Epoch 14/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.8681e-04 - val_loss: 4.8196e-05\n",
            "Epoch 15/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.8326e-04 - val_loss: 4.3551e-05\n",
            "Epoch 16/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.8786e-04 - val_loss: 5.8076e-05\n",
            "Epoch 17/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.9021e-04 - val_loss: 6.7658e-06\n",
            "Epoch 18/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.5291e-04 - val_loss: 1.3105e-05\n",
            "Epoch 19/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.5884e-04 - val_loss: 1.2075e-05\n",
            "Epoch 20/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.8079e-04 - val_loss: 3.1513e-05\n",
            "Epoch 21/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.5046e-04 - val_loss: 1.1715e-05\n",
            "Epoch 22/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4371e-04 - val_loss: 7.8032e-06\n",
            "Epoch 23/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4461e-04 - val_loss: 1.1783e-05\n",
            "Epoch 24/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.3591e-04 - val_loss: 2.3208e-05\n",
            "Epoch 25/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.2611e-04 - val_loss: 2.3427e-05\n",
            "Epoch 26/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.2119e-04 - val_loss: 1.0600e-04\n",
            "Epoch 27/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.2213e-04 - val_loss: 5.0760e-05\n",
            "Epoch 28/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.4563e-04 - val_loss: 3.1270e-05\n",
            "Epoch 29/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4412e-04 - val_loss: 2.1454e-05\n",
            "Epoch 30/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.2282e-04 - val_loss: 2.7580e-05\n",
            "Epoch 31/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 2.2312e-04 - val_loss: 5.6465e-06\n",
            "Epoch 32/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 2.4092e-04 - val_loss: 1.2578e-05\n",
            "Epoch 33/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.0870e-04 - val_loss: 3.5621e-05\n",
            "Epoch 34/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 2.1952e-04 - val_loss: 7.3011e-06\n",
            "Epoch 35/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.2245e-04 - val_loss: 3.9791e-05\n",
            "Epoch 36/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4605e-04 - val_loss: 1.5197e-05\n",
            "Epoch 37/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 2.2528e-04 - val_loss: 1.1464e-05\n",
            "Epoch 38/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.2488e-04 - val_loss: 2.1956e-05\n",
            "Epoch 39/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.2466e-04 - val_loss: 1.4472e-05\n",
            "Epoch 40/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.1577e-04 - val_loss: 8.1298e-06\n",
            "Epoch 41/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 1.9949e-04 - val_loss: 3.1973e-05\n",
            "Epoch 42/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.0617e-04 - val_loss: 5.6028e-06\n",
            "Epoch 43/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.3518e-04 - val_loss: 1.8806e-05\n",
            "Epoch 44/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.1763e-04 - val_loss: 8.2736e-06\n",
            "Epoch 45/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.2546e-04 - val_loss: 1.7583e-05\n",
            "Epoch 46/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 1.9834e-04 - val_loss: 5.5063e-06\n",
            "Epoch 47/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 2.2598e-04 - val_loss: 9.0318e-06\n",
            "Epoch 48/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 2.1127e-04 - val_loss: 8.1796e-06\n",
            "Epoch 49/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.3057e-04 - val_loss: 1.0176e-05\n",
            "Epoch 50/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 1.9441e-04 - val_loss: 8.5707e-06\n",
            "Epoch 51/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.1693e-04 - val_loss: 7.9857e-06\n",
            "Epoch 52/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.0348e-04 - val_loss: 3.2343e-05\n",
            "Epoch 53/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 2.2579e-04 - val_loss: 1.5465e-05\n",
            "Epoch 54/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 1.8044e-04 - val_loss: 8.2868e-06\n",
            "Epoch 55/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.2036e-04 - val_loss: 6.3481e-06\n",
            "Epoch 56/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 1.8903e-04 - val_loss: 3.8402e-05\n",
            "Epoch 57/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 1.8905e-04 - val_loss: 1.2693e-05\n",
            "Epoch 58/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 1.9903e-04 - val_loss: 7.2025e-06\n",
            "Epoch 59/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.0073e-04 - val_loss: 6.3865e-06\n",
            "Epoch 60/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.0837e-04 - val_loss: 6.0780e-05\n",
            "Epoch 61/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.0990e-04 - val_loss: 3.2119e-05\n",
            "Epoch 62/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.0240e-04 - val_loss: 9.4833e-06\n",
            "Epoch 63/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 1.9605e-04 - val_loss: 2.0133e-05\n",
            "Epoch 64/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 1.9713e-04 - val_loss: 4.0621e-05\n",
            "Epoch 65/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 1.8628e-04 - val_loss: 1.3855e-05\n",
            "Epoch 66/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.0398e-04 - val_loss: 5.3754e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaRJ4coVXv9t",
        "outputId": "a1ec70bb-4b7e-431c-8fb7-4e1a32ac660a"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/UNI-USD_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2lO7Ze2Xv9t"
      },
      "source": [
        "##LINK-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aChXY_7Xv9t",
        "outputId": "1c83c206-8882-4038-b6c2-8d11c854be68"
      },
      "source": [
        "raw_data = crypto_data['LINK/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.89406559 0.87808411 0.87767473 ... 0.2264962  0.2266694  0.22696856]\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "433/433 [==============================] - 21s 41ms/step - loss: 0.0072 - val_loss: 1.2552e-05\n",
            "Epoch 2/500\n",
            "433/433 [==============================] - 17s 39ms/step - loss: 0.0011 - val_loss: 1.2358e-05\n",
            "Epoch 3/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 8.1218e-04 - val_loss: 5.3701e-06\n",
            "Epoch 4/500\n",
            "433/433 [==============================] - 16s 38ms/step - loss: 6.2525e-04 - val_loss: 2.1022e-05\n",
            "Epoch 5/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 4.8951e-04 - val_loss: 2.8068e-05\n",
            "Epoch 6/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 3.9905e-04 - val_loss: 6.4762e-05\n",
            "Epoch 7/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 3.9283e-04 - val_loss: 4.0758e-05\n",
            "Epoch 8/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.3727e-04 - val_loss: 1.6824e-05\n",
            "Epoch 9/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 3.4073e-04 - val_loss: 3.5628e-05\n",
            "Epoch 10/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.5524e-04 - val_loss: 1.8732e-05\n",
            "Epoch 11/500\n",
            "433/433 [==============================] - 16s 38ms/step - loss: 3.1675e-04 - val_loss: 8.6008e-06\n",
            "Epoch 12/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.9518e-04 - val_loss: 1.8474e-05\n",
            "Epoch 13/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 3.1570e-04 - val_loss: 1.2085e-05\n",
            "Epoch 14/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.2779e-04 - val_loss: 2.6438e-05\n",
            "Epoch 15/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 3.0357e-04 - val_loss: 2.3280e-05\n",
            "Epoch 16/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.7765e-04 - val_loss: 6.9194e-05\n",
            "Epoch 17/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.8336e-04 - val_loss: 2.4349e-05\n",
            "Epoch 18/500\n",
            "433/433 [==============================] - 17s 39ms/step - loss: 2.5696e-04 - val_loss: 2.0895e-05\n",
            "Epoch 19/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.9622e-04 - val_loss: 9.1950e-06\n",
            "Epoch 20/500\n",
            "433/433 [==============================] - 17s 39ms/step - loss: 2.6929e-04 - val_loss: 1.1019e-05\n",
            "Epoch 21/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 2.5703e-04 - val_loss: 2.0311e-05\n",
            "Epoch 22/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.1594e-04 - val_loss: 1.4046e-05\n",
            "Epoch 23/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.6283e-04 - val_loss: 1.4578e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNhEW9dgXv9u",
        "outputId": "a6144f47-4cb8-4e65-ded0-60cce3becad7"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/LINK-USD_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzyTfi1UXv9u"
      },
      "source": [
        "##ADA-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O64qgQDUXv9u",
        "outputId": "7dea3102-6236-431b-9b34-8e80b372912c"
      },
      "source": [
        "raw_data = crypto_data['ADA/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.55201367 0.52931342 0.5346634  ... 0.29551196 0.2968123  0.29599495]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "433/433 [==============================] - 40s 36ms/step - loss: 0.0114 - val_loss: 1.4010e-05\n",
            "Epoch 2/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 0.0016 - val_loss: 2.7543e-05\n",
            "Epoch 3/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 0.0013 - val_loss: 6.4915e-05\n",
            "Epoch 4/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 9.6046e-04 - val_loss: 1.0693e-05\n",
            "Epoch 5/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 7.6172e-04 - val_loss: 1.8536e-05\n",
            "Epoch 6/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 6.0692e-04 - val_loss: 6.8088e-05\n",
            "Epoch 7/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 4.7477e-04 - val_loss: 1.1388e-05\n",
            "Epoch 8/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.3303e-04 - val_loss: 2.5795e-05\n",
            "Epoch 9/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 4.2598e-04 - val_loss: 1.9335e-05\n",
            "Epoch 10/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 4.2642e-04 - val_loss: 3.4770e-05\n",
            "Epoch 11/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 4.1014e-04 - val_loss: 4.1747e-05\n",
            "Epoch 12/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 4.0738e-04 - val_loss: 1.1485e-05\n",
            "Epoch 13/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.9519e-04 - val_loss: 2.0531e-05\n",
            "Epoch 14/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.8320e-04 - val_loss: 2.3519e-05\n",
            "Epoch 15/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.4234e-04 - val_loss: 1.1005e-05\n",
            "Epoch 16/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.2268e-04 - val_loss: 1.0307e-05\n",
            "Epoch 17/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.1997e-04 - val_loss: 1.0824e-05\n",
            "Epoch 18/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.3116e-04 - val_loss: 8.6714e-06\n",
            "Epoch 19/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.5028e-04 - val_loss: 1.1667e-05\n",
            "Epoch 20/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.2446e-04 - val_loss: 9.3045e-06\n",
            "Epoch 21/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.3228e-04 - val_loss: 6.0603e-05\n",
            "Epoch 22/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.2246e-04 - val_loss: 1.9255e-05\n",
            "Epoch 23/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.1229e-04 - val_loss: 3.2305e-05\n",
            "Epoch 24/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.6657e-04 - val_loss: 1.0529e-05\n",
            "Epoch 25/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.0097e-04 - val_loss: 5.5365e-05\n",
            "Epoch 26/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.9427e-04 - val_loss: 1.0338e-05\n",
            "Epoch 27/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.0025e-04 - val_loss: 3.0473e-05\n",
            "Epoch 28/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.2508e-04 - val_loss: 1.0239e-04\n",
            "Epoch 29/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.9049e-04 - val_loss: 1.6319e-05\n",
            "Epoch 30/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.7361e-04 - val_loss: 3.0083e-05\n",
            "Epoch 31/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.9951e-04 - val_loss: 1.3474e-05\n",
            "Epoch 32/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.8611e-04 - val_loss: 1.1602e-05\n",
            "Epoch 33/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.9853e-04 - val_loss: 9.3963e-06\n",
            "Epoch 34/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.6852e-04 - val_loss: 2.9471e-05\n",
            "Epoch 35/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.9159e-04 - val_loss: 1.2384e-05\n",
            "Epoch 36/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.0488e-04 - val_loss: 1.1314e-05\n",
            "Epoch 37/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.9064e-04 - val_loss: 1.6605e-05\n",
            "Epoch 38/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.8931e-04 - val_loss: 2.3872e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy8zB9MCXv9u",
        "outputId": "c1cdd001-0e58-40e7-e530-5de6f296500f"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/ADA-USD_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zS7fMZTXv9u"
      },
      "source": [
        "##DOT-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCAc8KddXv9v",
        "outputId": "b510669d-c52b-477e-e636-fc5556bb9b71"
      },
      "source": [
        "raw_data = crypto_data['DOT/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.74651095 0.71570803 0.72366423 ... 0.16773723 0.16827737 0.16820438]\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "433/433 [==============================] - 20s 38ms/step - loss: 0.0046 - val_loss: 3.8235e-05\n",
            "Epoch 2/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 6.7754e-04 - val_loss: 1.3779e-05\n",
            "Epoch 3/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 5.0192e-04 - val_loss: 6.0774e-05\n",
            "Epoch 4/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 3.7934e-04 - val_loss: 5.7353e-06\n",
            "Epoch 5/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 3.0413e-04 - val_loss: 5.0916e-05\n",
            "Epoch 6/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.7238e-04 - val_loss: 5.9623e-05\n",
            "Epoch 7/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.5549e-04 - val_loss: 3.0917e-05\n",
            "Epoch 8/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.4713e-04 - val_loss: 1.7622e-05\n",
            "Epoch 9/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.8223e-04 - val_loss: 1.3933e-05\n",
            "Epoch 10/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.9684e-04 - val_loss: 1.2418e-05\n",
            "Epoch 11/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.8865e-04 - val_loss: 6.1324e-05\n",
            "Epoch 12/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.5039e-04 - val_loss: 1.0497e-04\n",
            "Epoch 13/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.5171e-04 - val_loss: 3.4273e-05\n",
            "Epoch 14/500\n",
            "433/433 [==============================] - 16s 37ms/step - loss: 2.5036e-04 - val_loss: 1.3922e-05\n",
            "Epoch 15/500\n",
            "433/433 [==============================] - 16s 36ms/step - loss: 2.7360e-04 - val_loss: 1.9068e-05\n",
            "Epoch 16/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.4243e-04 - val_loss: 7.3361e-05\n",
            "Epoch 17/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4971e-04 - val_loss: 9.5867e-05\n",
            "Epoch 18/500\n",
            "433/433 [==============================] - 15s 36ms/step - loss: 2.5435e-04 - val_loss: 1.2756e-05\n",
            "Epoch 19/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.3981e-04 - val_loss: 1.5140e-05\n",
            "Epoch 20/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.5149e-04 - val_loss: 7.7422e-06\n",
            "Epoch 21/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.4535e-04 - val_loss: 8.0456e-06\n",
            "Epoch 22/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.1333e-04 - val_loss: 1.7044e-05\n",
            "Epoch 23/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.3955e-04 - val_loss: 1.8715e-05\n",
            "Epoch 24/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 2.1171e-04 - val_loss: 3.1440e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g3gWqpYXv9v",
        "outputId": "8b1cd14e-9829-4f74-9dd6-7b736794ab93"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/DOT-USD_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk6JyGuEXv9v"
      },
      "source": [
        "##DOG-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVuhmDJ5Xv9v",
        "outputId": "7a94f247-78c5-4cbb-b7fc-5d74edd343bf"
      },
      "source": [
        "raw_data = crypto_data['DOG/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.84035655 0.89305003 0.93231093 ... 0.18372305 0.18417184 0.18428017]\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "433/433 [==============================] - 19s 35ms/step - loss: 0.0097 - val_loss: 3.6187e-05\n",
            "Epoch 2/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 0.0010 - val_loss: 1.1165e-04\n",
            "Epoch 3/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 9.0437e-04 - val_loss: 2.0840e-05\n",
            "Epoch 4/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 6.3053e-04 - val_loss: 5.8822e-05\n",
            "Epoch 5/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 5.1101e-04 - val_loss: 2.6571e-05\n",
            "Epoch 6/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 4.4118e-04 - val_loss: 4.8781e-05\n",
            "Epoch 7/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 4.1449e-04 - val_loss: 2.7850e-05\n",
            "Epoch 8/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.8385e-04 - val_loss: 6.6061e-05\n",
            "Epoch 9/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.3818e-04 - val_loss: 3.6167e-05\n",
            "Epoch 10/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.2551e-04 - val_loss: 5.5114e-05\n",
            "Epoch 11/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.3833e-04 - val_loss: 2.6783e-05\n",
            "Epoch 12/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.6350e-04 - val_loss: 2.6778e-05\n",
            "Epoch 13/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.9212e-04 - val_loss: 5.0916e-05\n",
            "Epoch 14/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.0353e-04 - val_loss: 4.2597e-05\n",
            "Epoch 15/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.7752e-04 - val_loss: 3.4263e-05\n",
            "Epoch 16/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.1770e-04 - val_loss: 2.7317e-05\n",
            "Epoch 17/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.8944e-04 - val_loss: 3.1548e-05\n",
            "Epoch 18/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.5467e-04 - val_loss: 3.1731e-05\n",
            "Epoch 19/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.4570e-04 - val_loss: 3.9531e-05\n",
            "Epoch 20/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.7940e-04 - val_loss: 3.1209e-05\n",
            "Epoch 21/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.8435e-04 - val_loss: 3.5954e-05\n",
            "Epoch 22/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.9171e-04 - val_loss: 2.6709e-05\n",
            "Epoch 23/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.6815e-04 - val_loss: 1.0094e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU65yQOAXv9v",
        "outputId": "237508bb-cbb4-4e00-ef90-ae46ddc72cb9"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/DOG-USD_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNW05unTXv9w"
      },
      "source": [
        "##UST-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qZG9-54Xv9w",
        "outputId": "3e75c2cd-022b-4046-bf3e-3ec596484918"
      },
      "source": [
        "raw_data = crypto_data['UST/USD']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.37200957 0.38397129 0.37200957 ... 0.43181818 0.43181818 0.43181818]\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "433/433 [==============================] - 20s 36ms/step - loss: 0.0075 - val_loss: 1.4513e-04\n",
            "Epoch 2/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 0.0015 - val_loss: 6.8190e-05\n",
            "Epoch 3/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 0.0010 - val_loss: 6.6169e-05\n",
            "Epoch 4/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 8.1861e-04 - val_loss: 4.6439e-05\n",
            "Epoch 5/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 6.8581e-04 - val_loss: 6.8771e-05\n",
            "Epoch 6/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 6.4577e-04 - val_loss: 9.7389e-05\n",
            "Epoch 7/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.7386e-04 - val_loss: 3.5441e-05\n",
            "Epoch 8/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.7444e-04 - val_loss: 7.5394e-05\n",
            "Epoch 9/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 6.5861e-04 - val_loss: 1.4836e-04\n",
            "Epoch 10/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.8668e-04 - val_loss: 5.0008e-05\n",
            "Epoch 11/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.7349e-04 - val_loss: 6.7303e-05\n",
            "Epoch 12/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 6.3551e-04 - val_loss: 4.5568e-05\n",
            "Epoch 13/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.0554e-04 - val_loss: 4.4485e-05\n",
            "Epoch 14/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.4459e-04 - val_loss: 9.5747e-05\n",
            "Epoch 15/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.3894e-04 - val_loss: 4.7154e-05\n",
            "Epoch 16/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.8341e-04 - val_loss: 3.7759e-05\n",
            "Epoch 17/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.8904e-04 - val_loss: 3.2331e-05\n",
            "Epoch 18/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.1181e-04 - val_loss: 7.4780e-05\n",
            "Epoch 19/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.1004e-04 - val_loss: 8.8240e-05\n",
            "Epoch 20/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.0665e-04 - val_loss: 4.2978e-05\n",
            "Epoch 21/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.8098e-04 - val_loss: 3.3389e-05\n",
            "Epoch 22/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.2388e-04 - val_loss: 8.7542e-05\n",
            "Epoch 23/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.9123e-04 - val_loss: 5.5321e-05\n",
            "Epoch 24/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.7053e-04 - val_loss: 8.8862e-05\n",
            "Epoch 25/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.5363e-04 - val_loss: 4.4533e-05\n",
            "Epoch 26/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.3126e-04 - val_loss: 4.4267e-05\n",
            "Epoch 27/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.5415e-04 - val_loss: 3.2179e-05\n",
            "Epoch 28/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.6538e-04 - val_loss: 4.0269e-05\n",
            "Epoch 29/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.9038e-04 - val_loss: 2.9789e-05\n",
            "Epoch 30/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.2407e-04 - val_loss: 3.3644e-05\n",
            "Epoch 31/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.5727e-04 - val_loss: 7.1082e-05\n",
            "Epoch 32/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 4.5121e-04 - val_loss: 3.2772e-05\n",
            "Epoch 33/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.3641e-04 - val_loss: 3.1389e-05\n",
            "Epoch 34/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.1665e-04 - val_loss: 4.4240e-05\n",
            "Epoch 35/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.2322e-04 - val_loss: 4.3979e-05\n",
            "Epoch 36/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.4722e-04 - val_loss: 3.5676e-05\n",
            "Epoch 37/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.9765e-04 - val_loss: 6.0168e-05\n",
            "Epoch 38/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.4581e-04 - val_loss: 5.4543e-05\n",
            "Epoch 39/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.3862e-04 - val_loss: 3.4419e-05\n",
            "Epoch 40/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.1966e-04 - val_loss: 5.0478e-05\n",
            "Epoch 41/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.0047e-04 - val_loss: 4.8545e-05\n",
            "Epoch 42/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.9842e-04 - val_loss: 3.8798e-05\n",
            "Epoch 43/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.0899e-04 - val_loss: 3.3127e-05\n",
            "Epoch 44/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.2603e-04 - val_loss: 4.0645e-05\n",
            "Epoch 45/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.8004e-04 - val_loss: 3.1657e-05\n",
            "Epoch 46/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.3788e-04 - val_loss: 3.6658e-05\n",
            "Epoch 47/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.9921e-04 - val_loss: 4.4458e-05\n",
            "Epoch 48/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.2897e-04 - val_loss: 3.4621e-05\n",
            "Epoch 49/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 4.4802e-04 - val_loss: 3.4245e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JC5x8uWXv9w",
        "outputId": "cb406368-15ee-4458-b6b4-34f8f1aec70a"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/UST-USD_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cmYzzihXv9w"
      },
      "source": [
        "##LTC-BTC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH76LSs3Xv9w",
        "outputId": "85a01016-a5f6-4f9c-b2e0-66ab9ba2ca6e"
      },
      "source": [
        "raw_data = crypto_data['LTC/BTC']\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.78688423 0.77938288 0.79311731 ... 0.27744181 0.27699327 0.27702421]\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "433/433 [==============================] - 19s 35ms/step - loss: 0.0053 - val_loss: 4.9170e-04\n",
            "Epoch 2/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 9.1709e-04 - val_loss: 1.5816e-04\n",
            "Epoch 3/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 6.3972e-04 - val_loss: 5.3705e-05\n",
            "Epoch 4/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 5.3510e-04 - val_loss: 2.0447e-04\n",
            "Epoch 5/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 3.5706e-04 - val_loss: 5.1173e-04\n",
            "Epoch 6/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 3.0765e-04 - val_loss: 6.4266e-04\n",
            "Epoch 7/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.4968e-04 - val_loss: 0.0013\n",
            "Epoch 8/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.8240e-04 - val_loss: 3.9872e-04\n",
            "Epoch 9/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 2.1053e-04 - val_loss: 8.9753e-04\n",
            "Epoch 10/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.5469e-04 - val_loss: 6.0834e-04\n",
            "Epoch 11/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.1095e-04 - val_loss: 5.2562e-04\n",
            "Epoch 12/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.1207e-04 - val_loss: 1.9204e-04\n",
            "Epoch 13/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.3694e-04 - val_loss: 3.8199e-04\n",
            "Epoch 14/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.2864e-04 - val_loss: 6.9789e-04\n",
            "Epoch 15/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.3650e-04 - val_loss: 2.5511e-04\n",
            "Epoch 16/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.6536e-04 - val_loss: 1.6112e-04\n",
            "Epoch 17/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.2264e-04 - val_loss: 1.9399e-05\n",
            "Epoch 18/500\n",
            "433/433 [==============================] - 14s 33ms/step - loss: 1.8507e-04 - val_loss: 2.8617e-04\n",
            "Epoch 19/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.0301e-04 - val_loss: 2.2919e-04\n",
            "Epoch 20/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.6169e-04 - val_loss: 1.7061e-04\n",
            "Epoch 21/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.8707e-04 - val_loss: 3.3372e-04\n",
            "Epoch 22/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.5707e-04 - val_loss: 2.8741e-04\n",
            "Epoch 23/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.0340e-04 - val_loss: 1.1290e-04\n",
            "Epoch 24/500\n",
            "433/433 [==============================] - 15s 35ms/step - loss: 1.6218e-04 - val_loss: 1.8811e-04\n",
            "Epoch 25/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.4484e-04 - val_loss: 3.1068e-04\n",
            "Epoch 26/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.5156e-04 - val_loss: 3.7689e-04\n",
            "Epoch 27/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 2.8766e-04 - val_loss: 2.0728e-04\n",
            "Epoch 28/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.4612e-04 - val_loss: 5.0168e-05\n",
            "Epoch 29/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.7002e-04 - val_loss: 2.9431e-05\n",
            "Epoch 30/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.6161e-04 - val_loss: 2.3122e-04\n",
            "Epoch 31/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.7764e-04 - val_loss: 4.9826e-05\n",
            "Epoch 32/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.9704e-04 - val_loss: 9.0659e-05\n",
            "Epoch 33/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.5693e-04 - val_loss: 4.0431e-04\n",
            "Epoch 34/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.5401e-04 - val_loss: 1.2838e-04\n",
            "Epoch 35/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.4652e-04 - val_loss: 7.6795e-05\n",
            "Epoch 36/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.6000e-04 - val_loss: 4.8242e-04\n",
            "Epoch 37/500\n",
            "433/433 [==============================] - 15s 34ms/step - loss: 1.4043e-04 - val_loss: 9.2015e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKurT2g5Xv9w",
        "outputId": "9a808429-1d43-418f-94d5-6164eb2dcadd"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/LTC-BTC_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkAp441AXv9x"
      },
      "source": [
        "## ETH-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkfY4slUXv9x",
        "outputId": "b271ce6d-20f5-4687-ae57-574c7a05f9fc"
      },
      "source": [
        "train_len = int(0.7 * len(crypto_data['ETH/USD']))\n",
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/600519.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01920395 0.01920395 0.02042869 0.01894278 0.0215814  0.02196263\n",
            " 0.02379075 0.02280014 0.02430706 0.02318438 0.02344554 0.02136827\n",
            " 0.0215904  0.02126921 0.02216075 0.02178552 0.02172849 0.02341252\n",
            " 0.02186057 0.02181254 0.02260202 0.0232204  0.02275511 0.02330445\n",
            " 0.02395885 0.02410594 0.02461325 0.02406182 0.02452079 0.02399577\n",
            " 0.0238769  0.02488072 0.02487081 0.02577886 0.02475854 0.02503921\n",
            " 0.02459674 0.02522413 0.02648219 0.02644257 0.02678928 0.0279582\n",
            " 0.02889927 0.02803084 0.02800112 0.02825207 0.02938467 0.02903465\n",
            " 0.02794169 0.02719213 0.02741667 0.02847001 0.02785914 0.02671334\n",
            " 0.02718883 0.02870776 0.03167957 0.03236309 0.03121729 0.03002526\n",
            " 0.03007809 0.02953326 0.0300946  0.02824878 0.0284535  0.02874077\n",
            " 0.02927571 0.03107861 0.03186779 0.0317192  0.03170269 0.03061632\n",
            " 0.0307418  0.02922617 0.02781951 0.02933184 0.02876389 0.02916343\n",
            " 0.02736384 0.02614869 0.026327   0.0277898  0.02772375 0.02710298\n",
            " 0.02826529 0.02605293 0.0248609  0.0229028  0.02334527 0.0225726\n",
            " 0.02256269 0.0237184  0.02286318 0.02252307 0.0241972  0.0242071\n",
            " 0.02399908 0.02588122 0.02564348 0.02620482 0.02388681 0.02497317\n",
            " 0.02700722 0.02703033 0.02743978 0.02748601 0.02847992 0.02821576\n",
            " 0.02919975 0.02998564 0.02922948 0.02938797 0.02907098 0.02839406\n",
            " 0.02818604 0.02847992 0.02813651 0.02922287 0.0281233  0.02707986\n",
            " 0.02743318 0.02701382 0.02711288 0.02882993 0.02983374 0.02936486\n",
            " 0.03012102 0.0314055  0.03097294 0.03014743 0.0310654  0.03145834\n",
            " 0.02904456 0.02803744 0.02870776 0.02781621 0.02676617 0.02601331\n",
            " 0.02558735 0.02611237 0.02582839 0.02741336 0.02715581 0.02690486\n",
            " 0.02591095 0.02671664 0.02707656 0.02455381 0.02320329 0.02359953\n",
            " 0.02425333 0.02461325 0.02196173 0.0212617  0.02241411 0.02286648\n",
            " 0.02500289 0.02341792 0.02363916 0.02309102 0.01936634 0.02036685\n",
            " 0.01935644 0.02045271 0.02219287 0.02147634 0.02233816 0.02225231\n",
            " 0.02234477 0.02236128 0.02304149 0.02215655 0.02295894 0.02377123\n",
            " 0.02369199 0.02465288 0.02478496 0.02510855 0.02409153 0.02399908\n",
            " 0.02380756 0.02416748 0.02443494 0.02494676 0.02619162 0.0263303\n",
            " 0.02706996 0.0282983  0.02767753 0.02712278 0.02677277 0.02552131\n",
            " 0.02455712 0.02498968 0.02680249 0.02700391 0.02737374 0.02638643\n",
            " 0.02647229 0.02933184 0.02934835 0.02938467 0.02850964 0.02859218\n",
            " 0.03079463 0.03184467 0.02732091 0.02728788 0.02720534 0.02582179\n",
            " 0.02880682 0.02945732 0.02988328 0.02950354 0.02974789 0.03092672\n",
            " 0.03112813 0.0310621  0.03018706 0.0314022  0.02995592 0.03095313\n",
            " 0.0307352  0.03062953 0.03109182 0.03233667 0.03493536 0.03540425\n",
            " 0.03563869 0.03805247 0.03822087 0.03808879 0.03700573 0.0359722\n",
            " 0.0359689  0.03414948 0.03445657 0.03343625 0.03339993 0.03274282\n",
            " 0.03448299 0.03649392 0.03688686 0.03350889 0.03296075 0.03524245\n",
            " 0.03524245 0.03628919 0.03893741 0.04015586 0.03888788 0.04029785\n",
            " 0.03890439 0.03936667 0.03969688 0.03856428 0.03800294 0.03970017\n",
            " 0.04154931 0.04114976 0.04216678 0.04125543 0.0412092  0.03996103\n",
            " 0.0392412  0.03932375 0.04066107 0.0387591  0.03975301 0.04064456\n",
            " 0.0449669  0.04619525 0.04388384 0.04663442 0.04489756 0.04346778\n",
            " 0.04598062 0.04533672 0.04752926 0.04738067 0.04457726 0.04167148\n",
            " 0.04208424 0.0410507  0.0408856  0.04313097 0.04516832 0.04348099\n",
            " 0.04315409 0.04328287 0.04216018 0.0410408  0.04074692 0.04233188\n",
            " 0.04294936 0.04396309 0.04426026 0.04694151 0.04274464 0.0426753\n",
            " 0.0425102  0.04139742 0.03979593 0.03660619 0.03760669 0.03864353\n",
            " 0.0374515  0.03616041 0.03735244 0.03623636 0.03525566 0.03315227\n",
            " 0.03272962 0.03335039 0.03335039 0.03786426 0.03807228 0.03730952\n",
            " 0.040562   0.04058842 0.03994452 0.04011953 0.04002708 0.04160544\n",
            " 0.04046295 0.04014265 0.03724678 0.03641467 0.03692648 0.03751094\n",
            " 0.03954168 0.03866995 0.04026152 0.04194885 0.04001387 0.04140402\n",
            " 0.04129505 0.04067097 0.04119269 0.04191913 0.04327296 0.04293285\n",
            " 0.04373854 0.04432631 0.04351401 0.04158563 0.04210735 0.04203801\n",
            " 0.0403936  0.04063465 0.04154601 0.04245736 0.04313758 0.04279417\n",
            " 0.04099787 0.03868976 0.03919827 0.03808549 0.03831993 0.03721376\n",
            " 0.03609107 0.03694629 0.03582361 0.03488253 0.03146494 0.03209563\n",
            " 0.03298387 0.03253479 0.034166   0.03245554 0.03335039 0.03289802\n",
            " 0.0331919  0.03211214 0.02688834 0.02581849 0.02571612 0.02491374\n",
            " 0.02642606 0.02642606 0.02758837 0.0307418  0.02870776 0.02944081\n",
            " 0.03048754 0.03162344 0.03324803 0.03290132 0.03230696 0.02833793\n",
            " 0.02838416 0.02855916 0.02932854 0.03088709 0.02980403 0.02911721\n",
            " 0.02824217 0.030405   0.03225742 0.03161353 0.03054368 0.02993611\n",
            " 0.03040829 0.02880682 0.02851954 0.02806717 0.02593736 0.02643927\n",
            " 0.0264888  0.02549159 0.02320989 0.01972626 0.019614   0.02026119\n",
            " 0.01985835 0.01988476 0.01861348 0.02168436 0.02151926 0.02192871\n",
            " 0.02281695 0.0201192  0.01953475 0.01952814 0.02022817 0.02206739\n",
            " 0.02058149 0.01935314 0.01915502 0.01857056 0.01818092 0.0184781\n",
            " 0.01857056 0.01930361 0.02149614 0.0215853  0.02193861 0.02094141\n",
            " 0.02148624 0.01987155 0.01922105 0.01673794 0.01532797 0.01688983\n",
            " 0.0158563  0.01660585 0.01659925 0.01687992 0.0158596  0.0158695\n",
            " 0.01654312 0.01525203 0.01484258 0.01488881 0.015044   0.01480625\n",
            " 0.01690634 0.01656293 0.0176559  0.0178243  0.01796298 0.01972296\n",
            " 0.01994089 0.01996731 0.0181446  0.01751721 0.01852763 0.0191319\n",
            " 0.01823705 0.01728607 0.01772854 0.01949512 0.02276082 0.02315706\n",
            " 0.02589444 0.02587132 0.02605954 0.02391653 0.02506233 0.02512506\n",
            " 0.02547508 0.0251746  0.0251812  0.0266506  0.0276313  0.02713269\n",
            " 0.02736384 0.02753223 0.02731761 0.02690815 0.02586802 0.02751243\n",
            " 0.02738695 0.02721194 0.02737374 0.02559065 0.02507884 0.024851\n",
            " 0.02335188 0.02406842 0.02511846 0.02409814 0.02390992 0.0220773\n",
            " 0.02347075 0.02310093 0.0233849  0.02430617 0.02494015 0.02614869\n",
            " 0.0261553  0.02570952 0.02587462 0.02522743 0.0242005  0.02479156\n",
            " 0.02549489 0.02313064 0.02284667 0.02383728 0.02250656 0.02189569\n",
            " 0.01890406 0.01853093 0.02008619 0.01844508 0.01980551 0.01856065\n",
            " 0.01735541 0.01640113 0.01642424 0.01754363 0.01891067 0.01873566\n",
            " 0.0186465  0.01902624 0.01862339 0.01785402 0.01966352 0.02020506\n",
            " 0.019789   0.01938286 0.01837244 0.01862669 0.01811158 0.01846819\n",
            " 0.01859697 0.01790685 0.01822054 0.01795968 0.01688653 0.01641764\n",
            " 0.0165167  0.0109495  0.01086364 0.01100893 0.01040466 0.01040797\n",
            " 0.0106292  0.01085044 0.01116413 0.01088676 0.01098252 0.01019994\n",
            " 0.00744275 0.00764087 0.00728095 0.00595684 0.00541531 0.00550117\n",
            " 0.00505209 0.00567287 0.00591392 0.00601958 0.00603609 0.00619459\n",
            " 0.00689792 0.00841685 0.00841355 0.00839704 0.00799749 0.00869422\n",
            " 0.00814278 0.00823194 0.00823854 0.00593373 0.00502237 0.00463604\n",
            " 0.00456669 0.0053988  0.00542192 0.00580495 0.00638941 0.00689792\n",
            " 0.00667338 0.00573891 0.0068649  0.00861167 0.00857204 0.00835741\n",
            " 0.00814938 0.00816589 0.00794466 0.00769371 0.00657102 0.00650828\n",
            " 0.00732058 0.00700689 0.00699698 0.00761776 0.00748898 0.00595024\n",
            " 0.0062144  0.00651158 0.00601958 0.00660074 0.00633327 0.00600637\n",
            " 0.00582146 0.00582476 0.00582476 0.00469217 0.00477142 0.00453367\n",
            " 0.0040912  0.00260529 0.00255907 0.00259208 0.00247652 0.00197461\n",
            " 0.0024567  0.00188215 0.00317654 0.00238406 0.00172365 0.0006505\n",
            " 0.00059436 0.00021133 0.00019152 0.0001684  0.00037313 0.00084201\n",
            " 0.         0.00106655 0.00050851 0.00265152 0.00271756 0.00508841\n",
            " 0.005062   0.00552758 0.00726114 0.00675593 0.00602619 0.00443791\n",
            " 0.00499596 0.00465585 0.00504548 0.00508181 0.00558371 0.00797108\n",
            " 0.01030891 0.0093282  0.01016031 0.00998201 0.01001172 0.00952963\n",
            " 0.00779607 0.0076838  0.00864799 0.01032211 0.0119434  0.01143819\n",
            " 0.01356469 0.01427793 0.01543034 0.01260711 0.01433737 0.01313213\n",
            " 0.01522561 0.01489541 0.01575393 0.01735541 0.01836253 0.01664878\n",
            " 0.01738183 0.01734551 0.0158662  0.01311892 0.01284485 0.01118724\n",
            " 0.01186746 0.01443973 0.01547987 0.0153709  0.01495815 0.01511665\n",
            " 0.0147237  0.01675775 0.01892717 0.01835922 0.01840215 0.01725635\n",
            " 0.01863659 0.01867292 0.01759646 0.01762288 0.01892057 0.01882151\n",
            " 0.01516617 0.01453879 0.01480295 0.01489871 0.01370008 0.01387839\n",
            " 0.01383546 0.01383876 0.01382225 0.01391801 0.01386188 0.01205567\n",
            " 0.01234625 0.01201935 0.0096485  0.0086579  0.01064571 0.01033202\n",
            " 0.01107497 0.01149433 0.01137216 0.0116165  0.01173208 0.01137876\n",
            " 0.01123017 0.01069524 0.01189057 0.01150093 0.01138206 0.01190048\n",
            " 0.0116165  0.01118394 0.01124337 0.011775   0.01136885 0.01149763\n",
            " 0.01121696 0.01136555 0.01239909 0.01479635 0.0124463  0.012232\n",
            " 0.01177434 0.01235549 0.01227922 0.01239182 0.01282042 0.01284221\n",
            " 0.01314732 0.01242814 0.01208671 0.01201407 0.01231554 0.01518499\n",
            " 0.01665241 0.01692847 0.01663062 0.01925672 0.01925672 0.02006307\n",
            " 0.02031369 0.02018293 0.02031006 0.02044445 0.01928577 0.01835956\n",
            " 0.01899883 0.01998316 0.02049894 0.0211709  0.02010666 0.01911869\n",
            " 0.01967805 0.02001585 0.01964173 0.01980518 0.01943106 0.01946012\n",
            " 0.01880995 0.01842131 0.0196272  0.01888986 0.01863561 0.01844673\n",
            " 0.01807261 0.01758226 0.01745514 0.01825786 0.01833777 0.01983061\n",
            " 0.02065149 0.02073866 0.02162856 0.0203827  0.02032096 0.01961994\n",
            " 0.01979066 0.01868646 0.01797817 0.01825786 0.01862834 0.01920949\n",
            " 0.0177893  0.01798544 0.01896977 0.01969621 0.0197398  0.01979792\n",
            " 0.01967442 0.01916591 0.01890439 0.0185448  0.01748419 0.01705196\n",
            " 0.01792733 0.01792733 0.01831234 0.01778203 0.0183414  0.0185448\n",
            " 0.0185557  0.01849395 0.01799271 0.0184431  0.01828328 0.0172372\n",
            " 0.01769486 0.01729531 0.01577342 0.01387013 0.01423335 0.01455662\n",
            " 0.01663788 0.01648533 0.01631825 0.01584243 0.01791643 0.01891892\n",
            " 0.01732074 0.01638363 0.01551553 0.01640542 0.01670326 0.01695389\n",
            " 0.01742971 0.01769486 0.01738976 0.01892255 0.01931483 0.02065512\n",
            " 0.02403309 0.02286715 0.02361175 0.02357179 0.02613614 0.02467236\n",
            " 0.02492661 0.02763262 0.02639403 0.0258274  0.02592547 0.02646304\n",
            " 0.02765441 0.02938335 0.02727666 0.02828278 0.02891479 0.02742922\n",
            " 0.02864964 0.0296594  0.03434496 0.03264145 0.03086529 0.03043669\n",
            " 0.02991002 0.02850072 0.02793772 0.02732024 0.02836996 0.02838449\n",
            " 0.02452343 0.02546782 0.0270224  0.02661196 0.02653568 0.02718223\n",
            " 0.02620515 0.02524625 0.0247668  0.02514091 0.02428371 0.02557315\n",
            " 0.02516634 0.02400403 0.0242038  0.02772706 0.02721128 0.02730935\n",
            " 0.0274619  0.02706962 0.02736746 0.02697155 0.02760356 0.028577\n",
            " 0.03017881 0.03006258 0.02832637 0.02877677 0.02817019 0.02748007\n",
            " 0.03036405 0.02900923 0.0305166  0.03079628 0.02976473 0.03116313\n",
            " 0.03225644 0.03322987 0.03171523 0.03094157 0.03164259 0.03186415\n",
            " 0.03080718 0.0329066  0.03145008 0.03225644 0.03196222 0.03173703\n",
            " 0.03146098 0.03227096 0.033673   0.03506414 0.03342964 0.03350955\n",
            " 0.03484621 0.03560897 0.03550001 0.04297149 0.04525616 0.04579009\n",
            " 0.05428949 0.0566359  0.05378461 0.0546745  0.0536938  0.05082435\n",
            " 0.05151084 0.05240074 0.05339596 0.04830359 0.04893196 0.04974921\n",
            " 0.05310538 0.05429312 0.05319619 0.05391537 0.05210289 0.04983639\n",
            " 0.0483726  0.05160528 0.05302547 0.05471083 0.06098367 0.06496822\n",
            " 0.06449966 0.06136142 0.05562615 0.05661411 0.05938549 0.0576275\n",
            " 0.05623636 0.0545728  0.05298552 0.05690832 0.05487064 0.05560435\n",
            " 0.05524476]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 31s 148ms/step - loss: 3.3393e-04 - val_loss: 0.0035\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 5.8570e-05 - val_loss: 0.0017\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 3.5120e-05 - val_loss: 8.0850e-04\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 4.0858e-05 - val_loss: 7.4798e-04\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 3.7311e-05 - val_loss: 4.7235e-04\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 3.4237e-05 - val_loss: 4.8981e-04\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 3.1069e-05 - val_loss: 3.7918e-04\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 3.0657e-05 - val_loss: 4.1858e-04\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 2.8463e-05 - val_loss: 4.3180e-04\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.9126e-05 - val_loss: 4.3910e-04\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 2.8254e-05 - val_loss: 4.1300e-04\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 3.2435e-05 - val_loss: 5.3648e-04\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 2.7371e-05 - val_loss: 4.5426e-04\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 2.7375e-05 - val_loss: 3.6426e-04\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.7359e-05 - val_loss: 4.6820e-04\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 2.8695e-05 - val_loss: 5.2316e-04\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 3.0608e-05 - val_loss: 5.9443e-04\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 2.7208e-05 - val_loss: 5.1282e-04\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.8812e-05 - val_loss: 7.1719e-04\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 3.0725e-05 - val_loss: 4.4593e-04\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.7153e-05 - val_loss: 4.9928e-04\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 2.6229e-05 - val_loss: 7.5178e-04\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.4795e-05 - val_loss: 5.6488e-04\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.9324e-05 - val_loss: 4.1631e-04\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.5105e-05 - val_loss: 5.6767e-04\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 2.4177e-05 - val_loss: 5.9948e-04\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.6565e-05 - val_loss: 4.9612e-04\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 2.8187e-05 - val_loss: 4.7065e-04\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 2.6075e-05 - val_loss: 3.6605e-04\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.9440e-05 - val_loss: 3.9580e-04\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 3.1822e-05 - val_loss: 4.4252e-04\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 2.3258e-05 - val_loss: 5.7387e-04\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 2.7405e-05 - val_loss: 6.5637e-04\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 2.8634e-05 - val_loss: 6.2887e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcVShZdTXv9x",
        "outputId": "4c5110da-7265-4f8e-9d37-1a38a552251f"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/ETH-USD_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ZXXEanXv9x"
      },
      "source": [
        "##BTC-USD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqwYFvpiXv9x",
        "outputId": "a67d5e36-39e4-4c4a-bfc7-a2157b9e6566"
      },
      "source": [
        "train_len = int(0.7 * len(crypto_data['BTC/USD']))\n",
        "raw_data = pd.read_csv(r'/content/drive/My Drive/lstm_stock_predictions/600519.SS.csv', index_col=0, parse_dates=True)\n",
        "total = len(raw_data)\n",
        "training_num = int(total * 0.7)\n",
        "testing_num = total - training_num \n",
        "train_len = int(0.7 * len(raw_data))\n",
        "train_len\n",
        "predicted_price, predicted_price_std = lstm_price_generator(raw_data['Close']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01920395 0.01920395 0.02042869 0.01894278 0.0215814  0.02196263\n",
            " 0.02379075 0.02280014 0.02430706 0.02318438 0.02344554 0.02136827\n",
            " 0.0215904  0.02126921 0.02216075 0.02178552 0.02172849 0.02341252\n",
            " 0.02186057 0.02181254 0.02260202 0.0232204  0.02275511 0.02330445\n",
            " 0.02395885 0.02410594 0.02461325 0.02406182 0.02452079 0.02399577\n",
            " 0.0238769  0.02488072 0.02487081 0.02577886 0.02475854 0.02503921\n",
            " 0.02459674 0.02522413 0.02648219 0.02644257 0.02678928 0.0279582\n",
            " 0.02889927 0.02803084 0.02800112 0.02825207 0.02938467 0.02903465\n",
            " 0.02794169 0.02719213 0.02741667 0.02847001 0.02785914 0.02671334\n",
            " 0.02718883 0.02870776 0.03167957 0.03236309 0.03121729 0.03002526\n",
            " 0.03007809 0.02953326 0.0300946  0.02824878 0.0284535  0.02874077\n",
            " 0.02927571 0.03107861 0.03186779 0.0317192  0.03170269 0.03061632\n",
            " 0.0307418  0.02922617 0.02781951 0.02933184 0.02876389 0.02916343\n",
            " 0.02736384 0.02614869 0.026327   0.0277898  0.02772375 0.02710298\n",
            " 0.02826529 0.02605293 0.0248609  0.0229028  0.02334527 0.0225726\n",
            " 0.02256269 0.0237184  0.02286318 0.02252307 0.0241972  0.0242071\n",
            " 0.02399908 0.02588122 0.02564348 0.02620482 0.02388681 0.02497317\n",
            " 0.02700722 0.02703033 0.02743978 0.02748601 0.02847992 0.02821576\n",
            " 0.02919975 0.02998564 0.02922948 0.02938797 0.02907098 0.02839406\n",
            " 0.02818604 0.02847992 0.02813651 0.02922287 0.0281233  0.02707986\n",
            " 0.02743318 0.02701382 0.02711288 0.02882993 0.02983374 0.02936486\n",
            " 0.03012102 0.0314055  0.03097294 0.03014743 0.0310654  0.03145834\n",
            " 0.02904456 0.02803744 0.02870776 0.02781621 0.02676617 0.02601331\n",
            " 0.02558735 0.02611237 0.02582839 0.02741336 0.02715581 0.02690486\n",
            " 0.02591095 0.02671664 0.02707656 0.02455381 0.02320329 0.02359953\n",
            " 0.02425333 0.02461325 0.02196173 0.0212617  0.02241411 0.02286648\n",
            " 0.02500289 0.02341792 0.02363916 0.02309102 0.01936634 0.02036685\n",
            " 0.01935644 0.02045271 0.02219287 0.02147634 0.02233816 0.02225231\n",
            " 0.02234477 0.02236128 0.02304149 0.02215655 0.02295894 0.02377123\n",
            " 0.02369199 0.02465288 0.02478496 0.02510855 0.02409153 0.02399908\n",
            " 0.02380756 0.02416748 0.02443494 0.02494676 0.02619162 0.0263303\n",
            " 0.02706996 0.0282983  0.02767753 0.02712278 0.02677277 0.02552131\n",
            " 0.02455712 0.02498968 0.02680249 0.02700391 0.02737374 0.02638643\n",
            " 0.02647229 0.02933184 0.02934835 0.02938467 0.02850964 0.02859218\n",
            " 0.03079463 0.03184467 0.02732091 0.02728788 0.02720534 0.02582179\n",
            " 0.02880682 0.02945732 0.02988328 0.02950354 0.02974789 0.03092672\n",
            " 0.03112813 0.0310621  0.03018706 0.0314022  0.02995592 0.03095313\n",
            " 0.0307352  0.03062953 0.03109182 0.03233667 0.03493536 0.03540425\n",
            " 0.03563869 0.03805247 0.03822087 0.03808879 0.03700573 0.0359722\n",
            " 0.0359689  0.03414948 0.03445657 0.03343625 0.03339993 0.03274282\n",
            " 0.03448299 0.03649392 0.03688686 0.03350889 0.03296075 0.03524245\n",
            " 0.03524245 0.03628919 0.03893741 0.04015586 0.03888788 0.04029785\n",
            " 0.03890439 0.03936667 0.03969688 0.03856428 0.03800294 0.03970017\n",
            " 0.04154931 0.04114976 0.04216678 0.04125543 0.0412092  0.03996103\n",
            " 0.0392412  0.03932375 0.04066107 0.0387591  0.03975301 0.04064456\n",
            " 0.0449669  0.04619525 0.04388384 0.04663442 0.04489756 0.04346778\n",
            " 0.04598062 0.04533672 0.04752926 0.04738067 0.04457726 0.04167148\n",
            " 0.04208424 0.0410507  0.0408856  0.04313097 0.04516832 0.04348099\n",
            " 0.04315409 0.04328287 0.04216018 0.0410408  0.04074692 0.04233188\n",
            " 0.04294936 0.04396309 0.04426026 0.04694151 0.04274464 0.0426753\n",
            " 0.0425102  0.04139742 0.03979593 0.03660619 0.03760669 0.03864353\n",
            " 0.0374515  0.03616041 0.03735244 0.03623636 0.03525566 0.03315227\n",
            " 0.03272962 0.03335039 0.03335039 0.03786426 0.03807228 0.03730952\n",
            " 0.040562   0.04058842 0.03994452 0.04011953 0.04002708 0.04160544\n",
            " 0.04046295 0.04014265 0.03724678 0.03641467 0.03692648 0.03751094\n",
            " 0.03954168 0.03866995 0.04026152 0.04194885 0.04001387 0.04140402\n",
            " 0.04129505 0.04067097 0.04119269 0.04191913 0.04327296 0.04293285\n",
            " 0.04373854 0.04432631 0.04351401 0.04158563 0.04210735 0.04203801\n",
            " 0.0403936  0.04063465 0.04154601 0.04245736 0.04313758 0.04279417\n",
            " 0.04099787 0.03868976 0.03919827 0.03808549 0.03831993 0.03721376\n",
            " 0.03609107 0.03694629 0.03582361 0.03488253 0.03146494 0.03209563\n",
            " 0.03298387 0.03253479 0.034166   0.03245554 0.03335039 0.03289802\n",
            " 0.0331919  0.03211214 0.02688834 0.02581849 0.02571612 0.02491374\n",
            " 0.02642606 0.02642606 0.02758837 0.0307418  0.02870776 0.02944081\n",
            " 0.03048754 0.03162344 0.03324803 0.03290132 0.03230696 0.02833793\n",
            " 0.02838416 0.02855916 0.02932854 0.03088709 0.02980403 0.02911721\n",
            " 0.02824217 0.030405   0.03225742 0.03161353 0.03054368 0.02993611\n",
            " 0.03040829 0.02880682 0.02851954 0.02806717 0.02593736 0.02643927\n",
            " 0.0264888  0.02549159 0.02320989 0.01972626 0.019614   0.02026119\n",
            " 0.01985835 0.01988476 0.01861348 0.02168436 0.02151926 0.02192871\n",
            " 0.02281695 0.0201192  0.01953475 0.01952814 0.02022817 0.02206739\n",
            " 0.02058149 0.01935314 0.01915502 0.01857056 0.01818092 0.0184781\n",
            " 0.01857056 0.01930361 0.02149614 0.0215853  0.02193861 0.02094141\n",
            " 0.02148624 0.01987155 0.01922105 0.01673794 0.01532797 0.01688983\n",
            " 0.0158563  0.01660585 0.01659925 0.01687992 0.0158596  0.0158695\n",
            " 0.01654312 0.01525203 0.01484258 0.01488881 0.015044   0.01480625\n",
            " 0.01690634 0.01656293 0.0176559  0.0178243  0.01796298 0.01972296\n",
            " 0.01994089 0.01996731 0.0181446  0.01751721 0.01852763 0.0191319\n",
            " 0.01823705 0.01728607 0.01772854 0.01949512 0.02276082 0.02315706\n",
            " 0.02589444 0.02587132 0.02605954 0.02391653 0.02506233 0.02512506\n",
            " 0.02547508 0.0251746  0.0251812  0.0266506  0.0276313  0.02713269\n",
            " 0.02736384 0.02753223 0.02731761 0.02690815 0.02586802 0.02751243\n",
            " 0.02738695 0.02721194 0.02737374 0.02559065 0.02507884 0.024851\n",
            " 0.02335188 0.02406842 0.02511846 0.02409814 0.02390992 0.0220773\n",
            " 0.02347075 0.02310093 0.0233849  0.02430617 0.02494015 0.02614869\n",
            " 0.0261553  0.02570952 0.02587462 0.02522743 0.0242005  0.02479156\n",
            " 0.02549489 0.02313064 0.02284667 0.02383728 0.02250656 0.02189569\n",
            " 0.01890406 0.01853093 0.02008619 0.01844508 0.01980551 0.01856065\n",
            " 0.01735541 0.01640113 0.01642424 0.01754363 0.01891067 0.01873566\n",
            " 0.0186465  0.01902624 0.01862339 0.01785402 0.01966352 0.02020506\n",
            " 0.019789   0.01938286 0.01837244 0.01862669 0.01811158 0.01846819\n",
            " 0.01859697 0.01790685 0.01822054 0.01795968 0.01688653 0.01641764\n",
            " 0.0165167  0.0109495  0.01086364 0.01100893 0.01040466 0.01040797\n",
            " 0.0106292  0.01085044 0.01116413 0.01088676 0.01098252 0.01019994\n",
            " 0.00744275 0.00764087 0.00728095 0.00595684 0.00541531 0.00550117\n",
            " 0.00505209 0.00567287 0.00591392 0.00601958 0.00603609 0.00619459\n",
            " 0.00689792 0.00841685 0.00841355 0.00839704 0.00799749 0.00869422\n",
            " 0.00814278 0.00823194 0.00823854 0.00593373 0.00502237 0.00463604\n",
            " 0.00456669 0.0053988  0.00542192 0.00580495 0.00638941 0.00689792\n",
            " 0.00667338 0.00573891 0.0068649  0.00861167 0.00857204 0.00835741\n",
            " 0.00814938 0.00816589 0.00794466 0.00769371 0.00657102 0.00650828\n",
            " 0.00732058 0.00700689 0.00699698 0.00761776 0.00748898 0.00595024\n",
            " 0.0062144  0.00651158 0.00601958 0.00660074 0.00633327 0.00600637\n",
            " 0.00582146 0.00582476 0.00582476 0.00469217 0.00477142 0.00453367\n",
            " 0.0040912  0.00260529 0.00255907 0.00259208 0.00247652 0.00197461\n",
            " 0.0024567  0.00188215 0.00317654 0.00238406 0.00172365 0.0006505\n",
            " 0.00059436 0.00021133 0.00019152 0.0001684  0.00037313 0.00084201\n",
            " 0.         0.00106655 0.00050851 0.00265152 0.00271756 0.00508841\n",
            " 0.005062   0.00552758 0.00726114 0.00675593 0.00602619 0.00443791\n",
            " 0.00499596 0.00465585 0.00504548 0.00508181 0.00558371 0.00797108\n",
            " 0.01030891 0.0093282  0.01016031 0.00998201 0.01001172 0.00952963\n",
            " 0.00779607 0.0076838  0.00864799 0.01032211 0.0119434  0.01143819\n",
            " 0.01356469 0.01427793 0.01543034 0.01260711 0.01433737 0.01313213\n",
            " 0.01522561 0.01489541 0.01575393 0.01735541 0.01836253 0.01664878\n",
            " 0.01738183 0.01734551 0.0158662  0.01311892 0.01284485 0.01118724\n",
            " 0.01186746 0.01443973 0.01547987 0.0153709  0.01495815 0.01511665\n",
            " 0.0147237  0.01675775 0.01892717 0.01835922 0.01840215 0.01725635\n",
            " 0.01863659 0.01867292 0.01759646 0.01762288 0.01892057 0.01882151\n",
            " 0.01516617 0.01453879 0.01480295 0.01489871 0.01370008 0.01387839\n",
            " 0.01383546 0.01383876 0.01382225 0.01391801 0.01386188 0.01205567\n",
            " 0.01234625 0.01201935 0.0096485  0.0086579  0.01064571 0.01033202\n",
            " 0.01107497 0.01149433 0.01137216 0.0116165  0.01173208 0.01137876\n",
            " 0.01123017 0.01069524 0.01189057 0.01150093 0.01138206 0.01190048\n",
            " 0.0116165  0.01118394 0.01124337 0.011775   0.01136885 0.01149763\n",
            " 0.01121696 0.01136555 0.01239909 0.01479635 0.0124463  0.012232\n",
            " 0.01177434 0.01235549 0.01227922 0.01239182 0.01282042 0.01284221\n",
            " 0.01314732 0.01242814 0.01208671 0.01201407 0.01231554 0.01518499\n",
            " 0.01665241 0.01692847 0.01663062 0.01925672 0.01925672 0.02006307\n",
            " 0.02031369 0.02018293 0.02031006 0.02044445 0.01928577 0.01835956\n",
            " 0.01899883 0.01998316 0.02049894 0.0211709  0.02010666 0.01911869\n",
            " 0.01967805 0.02001585 0.01964173 0.01980518 0.01943106 0.01946012\n",
            " 0.01880995 0.01842131 0.0196272  0.01888986 0.01863561 0.01844673\n",
            " 0.01807261 0.01758226 0.01745514 0.01825786 0.01833777 0.01983061\n",
            " 0.02065149 0.02073866 0.02162856 0.0203827  0.02032096 0.01961994\n",
            " 0.01979066 0.01868646 0.01797817 0.01825786 0.01862834 0.01920949\n",
            " 0.0177893  0.01798544 0.01896977 0.01969621 0.0197398  0.01979792\n",
            " 0.01967442 0.01916591 0.01890439 0.0185448  0.01748419 0.01705196\n",
            " 0.01792733 0.01792733 0.01831234 0.01778203 0.0183414  0.0185448\n",
            " 0.0185557  0.01849395 0.01799271 0.0184431  0.01828328 0.0172372\n",
            " 0.01769486 0.01729531 0.01577342 0.01387013 0.01423335 0.01455662\n",
            " 0.01663788 0.01648533 0.01631825 0.01584243 0.01791643 0.01891892\n",
            " 0.01732074 0.01638363 0.01551553 0.01640542 0.01670326 0.01695389\n",
            " 0.01742971 0.01769486 0.01738976 0.01892255 0.01931483 0.02065512\n",
            " 0.02403309 0.02286715 0.02361175 0.02357179 0.02613614 0.02467236\n",
            " 0.02492661 0.02763262 0.02639403 0.0258274  0.02592547 0.02646304\n",
            " 0.02765441 0.02938335 0.02727666 0.02828278 0.02891479 0.02742922\n",
            " 0.02864964 0.0296594  0.03434496 0.03264145 0.03086529 0.03043669\n",
            " 0.02991002 0.02850072 0.02793772 0.02732024 0.02836996 0.02838449\n",
            " 0.02452343 0.02546782 0.0270224  0.02661196 0.02653568 0.02718223\n",
            " 0.02620515 0.02524625 0.0247668  0.02514091 0.02428371 0.02557315\n",
            " 0.02516634 0.02400403 0.0242038  0.02772706 0.02721128 0.02730935\n",
            " 0.0274619  0.02706962 0.02736746 0.02697155 0.02760356 0.028577\n",
            " 0.03017881 0.03006258 0.02832637 0.02877677 0.02817019 0.02748007\n",
            " 0.03036405 0.02900923 0.0305166  0.03079628 0.02976473 0.03116313\n",
            " 0.03225644 0.03322987 0.03171523 0.03094157 0.03164259 0.03186415\n",
            " 0.03080718 0.0329066  0.03145008 0.03225644 0.03196222 0.03173703\n",
            " 0.03146098 0.03227096 0.033673   0.03506414 0.03342964 0.03350955\n",
            " 0.03484621 0.03560897 0.03550001 0.04297149 0.04525616 0.04579009\n",
            " 0.05428949 0.0566359  0.05378461 0.0546745  0.0536938  0.05082435\n",
            " 0.05151084 0.05240074 0.05339596 0.04830359 0.04893196 0.04974921\n",
            " 0.05310538 0.05429312 0.05319619 0.05391537 0.05210289 0.04983639\n",
            " 0.0483726  0.05160528 0.05302547 0.05471083 0.06098367 0.06496822\n",
            " 0.06449966 0.06136142 0.05562615 0.05661411 0.05938549 0.0576275\n",
            " 0.05623636 0.0545728  0.05298552 0.05690832 0.05487064 0.05560435\n",
            " 0.05524476]\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 24, 1)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,009\n",
            "Trainable params: 19,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "16/16 [==============================] - 5s 102ms/step - loss: 2.6198e-04 - val_loss: 0.0046\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 7.1922e-05 - val_loss: 0.0029\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 4.7141e-05 - val_loss: 0.0017\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 3.7671e-05 - val_loss: 0.0011\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 3.4643e-05 - val_loss: 6.5767e-04\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 3.4365e-05 - val_loss: 5.0834e-04\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 3.1824e-05 - val_loss: 4.7884e-04\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 3.3182e-05 - val_loss: 6.0575e-04\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 3.3974e-05 - val_loss: 4.7362e-04\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 3.1588e-05 - val_loss: 5.4517e-04\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 3.0047e-05 - val_loss: 4.8800e-04\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.8048e-05 - val_loss: 4.0553e-04\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.9435e-05 - val_loss: 5.8541e-04\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 2.8805e-05 - val_loss: 6.3788e-04\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 2.7061e-05 - val_loss: 5.9824e-04\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 2.7000e-05 - val_loss: 5.7239e-04\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 2.5697e-05 - val_loss: 4.9809e-04\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.5361e-05 - val_loss: 5.5963e-04\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 3.1088e-05 - val_loss: 6.5114e-04\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 3.4162e-05 - val_loss: 5.8800e-04\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 2.6860e-05 - val_loss: 4.9040e-04\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.4012e-05 - val_loss: 3.5615e-04\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 2.7804e-05 - val_loss: 4.3551e-04\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 2.5582e-05 - val_loss: 5.5616e-04\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 2.3868e-05 - val_loss: 3.8653e-04\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.7478e-05 - val_loss: 4.6817e-04\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.4190e-05 - val_loss: 3.0038e-04\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.3260e-05 - val_loss: 3.1750e-04\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 2.1469e-05 - val_loss: 3.7110e-04\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 2.5304e-05 - val_loss: 3.5910e-04\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.4577e-05 - val_loss: 4.1072e-04\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.5292e-05 - val_loss: 6.1235e-04\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 2.4758e-05 - val_loss: 4.9408e-04\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.5204e-05 - val_loss: 4.0732e-04\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.4814e-05 - val_loss: 3.9839e-04\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.4471e-05 - val_loss: 2.9057e-04\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 2.5843e-05 - val_loss: 3.3599e-04\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 2.5025e-05 - val_loss: 2.7416e-04\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 2.5851e-05 - val_loss: 3.8379e-04\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 2.3965e-05 - val_loss: 3.6206e-04\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.3787e-05 - val_loss: 3.4613e-04\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.7195e-05 - val_loss: 3.5022e-04\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.6479e-05 - val_loss: 3.6748e-04\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 2.5277e-05 - val_loss: 2.2617e-04\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.5332e-05 - val_loss: 4.1016e-04\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.6482e-05 - val_loss: 4.6839e-04\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.3379e-05 - val_loss: 4.1218e-04\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.1954e-05 - val_loss: 3.5045e-04\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.2798e-05 - val_loss: 2.2848e-04\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.5326e-05 - val_loss: 2.8256e-04\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.3579e-05 - val_loss: 2.9297e-04\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 2.7255e-05 - val_loss: 1.6374e-04\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.6425e-05 - val_loss: 2.0450e-04\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.2190e-05 - val_loss: 2.1770e-04\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 2.5630e-05 - val_loss: 3.4426e-04\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.4074e-05 - val_loss: 3.0019e-04\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.6274e-05 - val_loss: 4.3903e-04\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.4504e-05 - val_loss: 2.7106e-04\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.5568e-05 - val_loss: 2.2734e-04\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.2641e-05 - val_loss: 4.8149e-04\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.6172e-05 - val_loss: 3.8013e-04\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 2.5504e-05 - val_loss: 4.0501e-04\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.3500e-05 - val_loss: 3.6818e-04\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.4063e-05 - val_loss: 5.6603e-04\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.4360e-05 - val_loss: 4.5875e-04\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 2.5977e-05 - val_loss: 3.7629e-04\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.8022e-05 - val_loss: 2.5835e-04\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 2.5486e-05 - val_loss: 5.0834e-04\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 2.3721e-05 - val_loss: 6.7509e-04\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 2.4547e-05 - val_loss: 3.9104e-04\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.2200e-05 - val_loss: 2.3016e-04\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 2.5010e-05 - val_loss: 3.1459e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnoU1HgjXv9y",
        "outputId": "3fc29a18-764a-4700-85f5-d334b1c155a8"
      },
      "source": [
        "test_price = raw_data[train_len:] \n",
        "test_price['Predicted'] = predicted_price\n",
        "test_price['Predicted_std'] = predicted_price_std\n",
        "test_price[['Predicted','Predicted_std']].to_csv('/content/drive/My Drive/lstm_stock_predictions/BTC-USD_1_Month_Predicted.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "07p5iHGKXv9y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}